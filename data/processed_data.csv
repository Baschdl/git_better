,repository,label,owner,name,watchers,description,mentionableUsers,closed_pull_requests,closed_issues,open_issues,forks,merged_pull_requests,stargazers,open_pull_requests,projects,size,readme,LANGUAGE_Python,isOwnerHomepage,hasHomepage,commitsCount,branchesCount,tagsCount,releasesCount,LANGUAGE_Shell,LANGUAGE_Makefile,LANGUAGE_Ruby,LANGUAGE_JavaScript,LANGUAGE_C,LANGUAGE_C++,LANGUAGE_HTML,LANGUAGE_PHP,LANGUAGE_CSS,LANGUAGE_Perl,LANGUAGE_R,LANGUAGE_Julia,LANGUAGE_TeX,LANGUAGE_Go,LANGUAGE_FORTRAN,LANGUAGE_Matlab,LANGUAGE_Groovy,LANGUAGE_Java,LANGUAGE_FreeMarker,LANGUAGE_XSLT,LANGUAGE_SQLPL,LANGUAGE_Smarty,LANGUAGE_Batchfile,LANGUAGE_Objective-C,LANGUAGE_TypeScript,LANGUAGE_CoffeeScript,LANGUAGE_Common Lisp,LANGUAGE_PostScript,LANGUAGE_APL,LANGUAGE_Jupyter Notebook,LANGUAGE_Swift,LANGUAGE_Smalltalk
0,briantemple/homeworkr,DEV,briantemple,homeworkr,1.0,A simple rails app to handle homework assignment submission and grading,1.0,0.0,0.0,0.0,2.0,0.0,6.0,0.0,0.0,226.0, HomeworkrHomeworkr is a simple rails app to handle assignment submission and grading Installation Install Homeworkr gem dependenciesbundle install Create the database using the commandrake db:schema:load RAILSENVproduction Define an administrator userModify the db/seedsrb file and change at least the email and password Add the administrator user to the databaserake db:seed RAILSENVproduction Start the serverrails s --environmentproduction Log in and create courses and assignmentshttp://localhost:3000 ContactProject contact: Brian Temple brianbriantemplecom LicenseHomeworkr is released under the MIT license  Check the LICENSE file for details,,False,True,30.0,2.0,0.0,0.0,,,0.885716925351,0.114283074649,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,spring-projects/spring-boot,DEV,spring-projects,spring-boot,1129.0,Spring Boot,298.0,1344.0,5246.0,629.0,7758.0,29.0,8112.0,73.0,0.0,55554.0, Spring Boot image:https://buildspringio/plugins/servlet/buildStatusImage/BOOT-PUBBuild Status linkhttps://buildspringio/browse/BOOT-PUB image:https://badgesgitterim/Join ChatsvgChatlinkhttps://gitterim/spring-projects/spring-bootutmsourcebadgeutmmediumbadgeutmcampaignpr-badgeutmcontentbadge:docs: http://docsspringio/spring-boot/docs/current-SNAPSHOT/referenceSpring Boot makes it easy to create Spring-powered production-grade applications andservices with absolute minimum fuss It takes an opinionated view of the Spring platformso that new and existing users can quickly get to the bits they needYou can use Spring Boot to create stand-alone Java applications that can be started usingjava -jar or more traditional WAR deployments We also provide a command line toolthat runs spring scriptsOur primary goals are: Provide a radically faster and widely accessible getting started experience for allSpring development Be opinionated out of the box but get out of the way quickly as requirements start todiverge from the defaults Provide a range of non-functional features that are common to large classes of projectseg embedded servers security metrics health checks externalized configuration Absolutely no code generation and no requirement for XML configuration Installation and Getting StartedThe docs/htmlsingle/reference documentation includes detaileddocs/htmlsingle/getting-started-installing-spring-bootinstallation instructionsas well as a comprehensive docs/htmlsingle/getting-started-first-applicationgettingstarted guide Documentation is published in docs/htmlsingle/HTMLdocs/pdf/spring-boot-referencepdfPDF and docs/epub/spring-boot-referenceepubEPUBformatsHere is a quick teaser of a complete Spring Boot application in Java:sourcejavaindent0----import orgspringframeworkbootimport orgspringframeworkbootautoconfigureimport orgspringframeworkwebbindannotationRestControllerSpringBootApplicationpublic class Example RequestMapping/String home return Hello Worldpublic static void mainString args throws Exception SpringApplicationrunExampleclass args---- Getting helpHaving trouble with Spring Boot Wed like to help Check the docs/htmlsingle/reference documentation especially the  docs/htmlsingle/howtoHow-tos -- they provide solutions to the most common  questions Learn the Spring basics -- Spring Boot builds on many other Spring projects check  the http://springiospringio web-site for a wealth of reference documentation If  you are just starting out with Spring try one of the http://springio/guidesguides Ask a question - we monitor http://stackoverflowcomstackoverflowcom for questions  tagged with http://stackoverflowcom/tags/spring-bootspring-boot Report bugs with Spring Boot at https://githubcom/spring-projects/spring-boot/issuesgithubcom/spring-projects/spring-boot/issues Reporting IssuesSpring Boot uses GitHubs integrated issue tracking system to record bugs and featurerequests If you want to raise an issue please follow the recommendations below: Before you log a bug please https://githubcom/spring-projects/spring-boot/searchtypeIssuessearch the issue tracker  to see if someone has already reported the problem If the issue doesnt already exist https://githubcom/spring-projects/spring-boot/issues/newcreate a new issue Please provide as much information as possible with the issue report we like to know  the version of Spring Boot that you are using as well as your Operating System and  JVM version If you need to paste code or include a stack trace use Markdown  escapes  before and after your text If possible try to create a test-case or project that replicates the issue You can  submit sample projects as pull-requests against the  https://githubcom/spring-projects/spring-boot-issuesspring-boot-issues GitHub  project Use the issue number for the name of your project Building from SourceYou dont need to build from source to use Spring Boot binaries inhttp://repospringiorepospringio but if you want to try out the latest andgreatest Spring Boot can be easily built with thehttps://githubcom/takari/maven-wrappermaven wrapper You also need JDK 18 althoughBoot applications can run on Java 16indent0---- /mvnw clean install----If you want to build with the regular mvn command you will needhttp://mavenapacheorg/run-maven/indexhtmlMaven v321 or aboveNOTE: You may need to increase the amount of memory available to Maven by settinga MAVENOPTS environment variable with the value -Xmx512m Rememberto set the corresponding property in your IDE as well if you are building and runningtests there eg in Eclipse go to Preferences-Java-Installed JREs and edit theJRE definition so that all processes are launched with those arguments This propertyis automatically set if you use the maven wrapperAlso see link:CONTRIBUTINGadocCONTRIBUTINGadoc if you wish to submit pull requestsand in particular please fill out thehttps://supportspringsourcecom/springcommittersignupContributors Agreementbefore your first change however trivial Or if you filed such an agreement already foranother project just mention that in your pull request Building reference documentationThe reference documentation requires the documentation of the Maven plugin to beavailable so you need to build that first since its not generated by defaultindent0---- /mvnw clean install -pl spring-boot-tools/spring-boot-maven-plugin -Pdefaultfull----The documentation also includes auto-generated information about the starters Toallow this information to be collected the starter projects must be built first:indent0---- /mvnw clean install -f spring-boot-starters----Once this is done you can build the reference documentation with the command below:indent0---- /mvnw clean prepare-package -pl spring-boot-docs -Pdefaultfull----TIP: The generated documentation is available from spring-boot-docs/target/contents/reference ModulesThere are a number of modules in Spring Boot here is a quick overview: spring-bootThe main library providing features that support the other parts of Spring Bootthese include: The SpringApplication class providing static convenience methods that make it easyto write a stand-alone Spring Application Its sole job is to create and refresh anappropriate Spring ApplicationContext Embedded web applications with a choice of container Tomcat or Jetty for now First class externalized configuration support Convenience ApplicationContext initializers including support for sensible loggingdefaults spring-boot-autoconfigureSpring Boot can configure large parts of common applications based on the contentof their classpath A single EnableAutoConfiguration annotation triggersauto-configuration of the Spring contextAuto-configuration attempts to deduce which beans a user might need For example IfHSQLDB is on the classpath and the user has not configured any database connectionsthen they probably want an in-memory database to be defined Auto-configuration willalways back away as the user starts to define their own beans spring-boot-startersStarters are a set of convenient dependency descriptors that you can include inyour application You get a one-stop-shop for all the Spring and related technologythat you need without having to hunt through sample code and copy paste loads ofdependency descriptors For example if you want to get started using Spring and JPA fordatabase access just include the spring-boot-starter-data-jpa dependency in yourproject and you are good to go spring-boot-cliThe Spring command line application compiles and runs Groovy source making it supereasy to write the absolute minimum of code to get an application running Spring CLIcan also watch files automatically recompiling and restarting when they change spring-boot-actuatorSpring Boot Actuator provides additional auto-configuration to decorate your applicationwith features that make it instantly deployable and supportable in production  Forinstance if you are writing a JSON web service then it will provide a server securitylogging externalized configuration management endpoints an audit abstraction andmore If you want to switch off the built in features or extend or replace them itmakes that really easy as well spring-boot-loaderSpring Boot Loader provides the secret sauce that allows you to build a single jar filethat can be launched using java -jar Generally you will not need to usespring-boot-loader directly but instead work with thelink:spring-boot-tools/spring-boot-gradle-pluginGradle orlink:spring-boot-tools/spring-boot-maven-pluginMaven plugin SamplesGroovy samples for use with the command line application are available inlink:spring-boot-cli/samplesspring-boot-cli/samples To run the CLI samples typespring run samplegroovy from samples directoryJava samples are available in link:spring-boot-samplesspring-boot-samples and shouldbe built with maven and run by invoking java -jar target/samplejar GuidesThe http://springio/springio site contains several guides that show how to use SpringBoot step-by-step: http://springio/guides/gs/spring-boot/Building an Application with Spring Boot is a  very basic guide that shows you how to create a simple application run it and add some  management services http://springio/guides/gs/actuator-service/Building a RESTful Web Service with Spring  Boot Actuator is a guide to creating a REST web service and also shows how the server  can be configured http://springio/guides/gs/convert-jar-to-war/Converting a Spring Boot JAR Application  to a WAR shows you how to run applications in a web server as a WAR file LicenseSpring Boot is Open Source software released under thehttp://wwwapacheorg/licenses/LICENSE-20htmlApache 20 license,,False,True,9241.0,9.0,65.0,0.0,0.00211365281363,,0.000128795945145,0.00372384848591,,,0.00730175451217,,0.000568495644638,,,,,,,,0.00467863342279,0.970967896108,0.000210291160627,0.00336081538574,0.00593771972051,0.00032282747995,0.000685269320993,,,,,,,,,
2,facebook/react,DEV,facebook,react,3709.0,"A declarative, efficient, and flexible JavaScript library for building user interfaces.",858.0,1246.0,3334.0,579.0,9074.0,2917.0,52760.0,95.0,0.0,143322.0, Reacthttps://facebookgithubio/react/ Build Statushttps://imgshieldsio/travis/facebook/react/mastersvgstyleflathttps://travis-ciorg/facebook/react Coverage Statushttps://imgshieldsio/coveralls/facebook/react/mastersvgstyleflathttps://coverallsio/github/facebook/reactbranchmaster npm versionhttps://imgshieldsio/npm/v/reactsvgstyleflathttps://wwwnpmjscom/package/react PRs Welcomehttps://imgshieldsio/badge/PRs-welcome-brightgreensvgCONTRIBUTINGmdpull-requestsReact is a JavaScript library for building user interfaces Declarative: React makes it painless to create interactive UIs Design simple views for each state in your application and React will efficiently update and render just the right components when your data changes Declarative views make your code more predictable simpler to understand and easier to debug Component-Based: Build encapsulated components that manage their own state then compose them to make complex UIs Since component logic is written in JavaScript instead of templates you can easily pass rich data through your app and keep state out of the DOM Learn Once Write Anywhere: We dont make assumptions about the rest of your technology stack so you can develop new features in React without rewriting existing code React can also render on the server using Node and power mobile apps using React Nativehttps://facebookgithubio/react-native/Learn how to use React in your own projecthttps://facebookgithubio/react/docs/getting-startedhtml ExamplesWe have several examples on the websitehttps://facebookgithubio/react/ Here is the first one to get you started:jsxclass HelloMessage extends ReactComponent   render     return divHello thispropsname/div  ReactDOMrender  HelloMessage nameJohn /  documentgetElementByIdcontainerThis example will render Hello John into a container on the pageYoull notice that we used an HTML-like syntax we call it JSXhttps://facebookgithubio/react/docs/jsx-in-depthhtml JSX is not required to use React but it makes code more readable and writing it feels like writing HTML A simple transform is included with React that allows converting JSX into native JavaScript for browsers to digest InstallationThe fastest way to get started is to serve JavaScript from a CDN Were using unpkghttps://unpkgcom/ below but React is also available on cdnjshttps://cdnjscom/libraries/react and jsdelivrhttps://wwwjsdelivrcom/projects/react:html-- The core React library --script srchttps://unpkgcom/react1532/dist/reactjs/script-- The ReactDOM Library --script srchttps://unpkgcom/react-dom1532/dist/react-domjs/scriptWeve also built a starter kithttps://facebookgithubio/react/downloads/react-1532zip which might be useful if this is your first time using React It includes a webpage with an example of using React with live codeIf youd like to use bowerhttp://bowerio its as easy as:shbower install --save reactAnd its just as easy with npmhttp://npmjscom:shnpm i --save react ContributingThe main purpose of this repository is to continue to evolve React core making it faster and easier to use Development of React happens in the open on GitHub and we are grateful to the community for contributing bugfixes and improvements Read below to learn how you can take part in improving React Code of Conducthttps://codefacebookcom/codeofconductFacebook has adopted a Code of Conduct that we expect project participants to adhere to Please read the full texthttps://codefacebookcom/codeofconduct so that you can understand what actions will and will not be tolerated Contributing GuideRead our contributing guidehttps://facebookgithubio/react/contributing/how-to-contributehtml to learn about our development process how to propose bugfixes and improvements and how to build and test your changes to React Good First BugTo help you get your feet wet and get you familiar with our contribution process we have a list of good first bugshttps://githubcom/facebook/react/labels/good20first20bug that contain bugs which are fairly easy to fix This is a great place to get started LicenseReact is BSD licensed/LICENSE We also provide an additional patent grant/PATENTSReact documentation is Creative Commons licensed/LICENSE-docsExamples provided in this repository and in the documentation are separately licensed/LICENSE-examples TroubleshootingSee the Troubleshooting Guidehttps://githubcom/facebook/react/wiki/Troubleshooting,0.00320399982653,False,True,7407.0,31.0,52.0,45.0,0.000179271012355,6.45375644479e-05,,0.970204133341,0.0018237837657,0.0153572085898,,,,,,,,,,,,,,,,,,,0.00514251704014,0.00402454886023,,,,,,
3,nodegit/nodegit,DEV,nodegit,nodegit,61.0,Native Node bindings to Git.,101.0,60.0,463.0,134.0,338.0,497.0,2205.0,16.0,0.0,29623.0,NodeGit------- Node bindings to the libgit2http://libgit2githubcom/ projecttable  thead    tr      thLinux/th      thOS X/th      thWindows/th      thCoverage/th      thDependencies/th    /tr  /thead  tbody    tr      td colspan2 aligncenter        a hrefhttps://travis-ciorg/nodegit/nodegitimg srchttps://apitravis-ciorg/nodegit/nodegitsvgbranchmaster/a      /td      td aligncenter        a hrefhttps://ciappveyorcom/project/timbranyen/nodegitimg srchttps://ciappveyorcom/api/projects/status/e5a5q75l9yfhnfv2svgtrue/a      /td      td aligncenter        a hrefhttps://coverallsio/r/nodegit/nodegitimg srchttps://coverallsio/repos/nodegit/nodegit/badgesvg altCoverage Status/a      /td      td aligncenter        a hrefhttps://david-dmorg/nodegit/nodegitimg srchttps://david-dmorg/nodegit/nodegitsvg/a      /td    /tr  /tbody/tableStable libgit2master: 0160Stable libgit2024: 0141 Have a problem Come chat with us https://libgit2slackcom/ Maintained by Tim Branyen tbranyenhttp://twittercom/tbranyenJohn Haley johnhaley81http://twittercom/johnhaley81 andMax Korp maxkorphttp://twittercom/MaximilianoKorp with help from tons ofawesome contributorshttps://githubcom/nodegit/nodegit/contributors Alumni Maintainers Steve Smith orderedlisthttps://twittercom/orderedlistMichael Robinson codeofinteresthttp://twittercom/codeofinterest andNick Kallen nkhttp://twittercom/nk API Documentation http://wwwnodegitorg/http://wwwnodegitorg/ Getting started NodeGit will work on most systems out-of-the-box without any nativedependencies bashnpm install nodegitIf you receive errors about libstdc which are commonly experienced whenbuilding on Travis-CI you can fix this by upgrading to the latestlibstdc-49In Ubuntu: shsudo add-apt-repository ppa:ubuntu-toolchain-r/testsudo apt-get updatesudo apt-get install libstdc-49-devIn Travis: yamladdons:  apt:    sources:      - ubuntu-toolchain-r-test    packages:      - libstdc-49-devIn CircleCI: yaml  dependencies:    pre:      - sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test      - sudo apt-get update      - sudo apt-get install -y libstdc-49-devIf you are still encountering problems while installing you should try theBuilding from sourcehttp://wwwnodegitorg/guides/install/from-source/instructions API examples  Cloning a repository and reading a file:  javascriptvar Git  requirenodegit// Clone a given repository into the /tmp folderGitClonehttps://githubcom/nodegit/nodegit /tmp  // Look up this known commit  thenfunctionrepo     // Use a known commit sha from this repository    return repogetCommit59b20b8d5c6ff8d09518454d4dd8b7b30f095ab5    // Look up a specific file within that commit  thenfunctioncommit     return commitgetEntryREADMEmd    // Get the blob contents from the file  thenfunctionentry     // Patch the blob to contain a reference to the entry    return entrygetBlobthenfunctionblob       blobentry  entry      return blob        // Display information about the blob  thenfunctionblob     // Show the path sha and filesize in bytes    consolelogblobentrypath  blobentrysha  blobrawsize  b    // Show a spacer    consolelogArray72join  nn    // Show the entire file    consolelogStringblob    catchfunctionerr  consolelogerr  Emulating git log:  javascriptvar Git  requirenodegit// Open the repository directoryGitRepositoryopentmp  // Open the master branch  thenfunctionrepo     return repogetMasterCommit    // Display information about commits on master  thenfunctionfirstCommitOnMaster     // Create a new history event emitter    var history  firstCommitOnMasterhistory    // Create a counter to only show up to 9 entries    var count  0    // Listen for commit events from the history    historyoncommit functioncommit       // Disregard commits past 9      if count  9         return            // Show the commit sha      consolelogcommit   commitsha      // Store the author object      var author  commitauthor      // Display author information      consolelogAuthor:t  authorname     authoremail        // Show the commit date      consolelogDate:t  commitdate      // Give some space and show the message      consolelogn      commitmessage        // Start emitting events    historystart  For more examples check the examples/ folder Unit tests You will need to build locally before running the tests  See above bashnpm test,0.00414980205751,False,False,2860.0,11.0,63.0,42.0,0.00147306038525,,,0.76020656944,0.002364739299,0.231805828818,,,,,,,,,,,,,,,,,,,,,,,,,,
4,scipy/scipy,DEV,scipy,scipy,229.0,Scipy library main repository,427.0,678.0,3012.0,932.0,1530.0,2114.0,2663.0,143.0,0.0,79636.0, image:: https://travis-ciorg/scipy/scipypngbranchmaster   :target: https://travis-ciorg/scipy/scipy/SciPy contents::What is SciPy--------------SciPy pronounced Sigh Pie is open-source software for mathematicsscience and engineering  It includes modules for statistics optimizationintegration linear algebra Fourier transforms signal and image processingODE solvers and more  It is also the name of a very popular conference onscientific programming with PythonThe SciPy library depends on NumPy which provides convenient and fastN-dimensional array manipulation The SciPy library is built to work withNumPy arrays and provides many user-friendly and efficient numerical routinessuch as routines for numerical integration and optimization Together theyrun on all popular operating systems are quick to install and are free ofcharge NumPy and SciPy are easy to use but powerful enough to be dependedupon by some of the worlds leading scientists and engineers If you need tomanipulate numbers on a computer and display or publish the results giveSciPy a tryInstallation------------For installation instructions see INSTALLrsttxtDocumentation-------------Scipy documentation is available on the web:    https://docsscipyorgHow to generate the HTML documentation see doc/READMEtxtWeb sites---------The users site is:    https://wwwscipyorg/Mailing Lists-------------Please see the developers list here:    http://projectsscipyorg/mailman/listinfo/scipy-devLatest source code------------------The latest development version of Scipys sources are always available at:    https://githubcom/scipy/scipyThey can be downloaded as a zip file or using the Git clientBug reports-----------To search for bugs or report them please use the Scipy Bug Tracker at:    https://githubcom/scipy/scipy/issuesDeveloper information---------------------If you would like to take part in SciPy development take a lookat the file CONTRIBUTINGLicense information-------------------See the file LICENSEtxt for information on the history of thissoftware terms  conditions for usage and a DISCLAIMER OF ALLWARRANTIES,0.517697383829,False,False,16265.0,15.0,88.0,13.0,0.000104416148725,3.66256824652e-05,,,0.193926915757,0.0231482786988,,,,,,,0.00245297919092,,0.262428805299,0.000204595393308,,,,,,,,,,,,,,,,
5,spez/RottenTomatoes,HW,spez,RottenTomatoes,1.0,CodePath week 1 homework,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,2064.0, RottenTomatoes Box Office DemoTime spent: 10 hours totalCompleted user stories:  x Required:User can view a list of movies from Rotten Tomatoes  Poster images must be loading asynchronously  x Required: User can view movie details by tapping on a cell  x Required: User sees loading state while waiting for movies API  x Required: User sees error message when theres a networking error  x Required: User can pull to refresh the movie list  x Optional: Add a tab bar for Box Office and DVDNotes:Walkthrough of all user stories:Video WalkthroughdemogifGIF created with LiceCaphttp://wwwcockoscom/licecap/,,False,False,18.0,1.0,0.0,0.0,0.00742510614014,,,,0.0200427696148,,,,,,,,,,,,,,,,,,,0.972532124245,,,,,,,,
6,m2mtech/calculator-2015,HW,m2mtech,calculator-2015,25.0,Calculator of the cs193p lecture (Winter 2015),1.0,2.0,1.0,1.0,28.0,0.0,70.0,1.0,0.0,518.0, Calculator of the cs193p lecture Winter 2015written in Xcode 631 for iOS83 various versions are available via branches and tags: Project 3 Assignment 3 Extra Task 6http://cs193pm2mat/cs193p-project-3-assignment-3-extra-task-6-winter-2015/ - project3assignment3extratask6https://githubcom/m2mtech/calculator-2015/tree/project3assignment3extratask6 Project 3 Assignment 3 Extra Task 5http://cs193pm2mat/cs193p-project-3-assignment-3-extra-task-5-winter-2015/ - project3assignment3extratask5https://githubcom/m2mtech/calculator-2015/tree/project3assignment3extratask5 Project 3 Assignment 3 Extra Task 4http://cs193pm2mat/cs193p-project-3-assignment-3-extra-task-4-winter-2015/ - project3assignment3extratask4https://githubcom/m2mtech/calculator-2015/tree/project3assignment3extratask4 Project 3 Assignment 3 Extra Task 3http://cs193pm2mat/cs193p-project-3-assignment-3-extra-task-3-winter-2015/ - project3assignment3extratask3https://githubcom/m2mtech/calculator-2015/tree/project3assignment3extratask3 Project 3 Assignment 3 Extra Task 2http://cs193pm2mat/cs193p-project-3-assignment-3-extra-task-2-winter-2015/ - project3assignment3extratask2https://githubcom/m2mtech/calculator-2015/tree/project3assignment3extratask2 Project 3 Assignment 3 Task 11http://cs193pm2mat/cs193p-project-3-assignment-3-task-11-winter-2015/ - project3assignment3task11https://githubcom/m2mtech/calculator-2015/tree/project3assignment3task11 Project 3 Assignment 3 Task 10http://cs193pm2mat/cs193p-project-3-assignment-3-task-10-winter-2015/ - project3assignment3task10https://githubcom/m2mtech/calculator-2015/tree/project3assignment3task10 Project 3 Assignment 3 Task 9http://cs193pm2mat/cs193p-project-3-assignment-3-task-9-winter-2015/ - project3assignment3task9https://githubcom/m2mtech/calculator-2015/tree/project3assignment3task9 Project 3 Assignment 3 Task 8http://cs193pm2mat/cs193p-project-3-assignment-3-task-8-winter-2015/ - project3assignment3task8https://githubcom/m2mtech/calculator-2015/tree/project3assignment3task8 Project 3 Assignment 3 Task 7http://cs193pm2mat/cs193p-project-3-assignment-3-task-7-winter-2015/ - project3assignment3task7https://githubcom/m2mtech/calculator-2015/tree/project3assignment3task7 Project 3 Assignment 3 Task 6http://cs193pm2mat/cs193p-project-3-assignment-3-task-6-winter-2015/ - project3assignment3task6https://githubcom/m2mtech/calculator-2015/tree/project3assignment3task6 Project 3 Assignment 3 Task 5http://cs193pm2mat/cs193p-project-3-assignment-3-task-5-winter-2015/ - project3assignment3task5https://githubcom/m2mtech/calculator-2015/tree/project3assignment3task5 Project 3 Assignment 3 Task 4http://cs193pm2mat/cs193p-project-3-assignment-3-task-4-winter-2015/ - project3assignment3task4https://githubcom/m2mtech/calculator-2015/tree/project3assignment3task4 Project 3 Assignment 3 Task 3http://cs193pm2mat/cs193p-project-3-assignment-3-task-3-winter-2015/ - project3assignment3task3https://githubcom/m2mtech/calculator-2015/tree/project3assignment3task3 Project 3 Assignment 3 Task 2http://cs193pm2mat/cs193p-project-3-assignment-3-task-2-winter-2015/ - project3assignment3task2https://githubcom/m2mtech/calculator-2015/tree/project3assignment3task2 Project 2 Assignment 2 Extra Task 3http://cs193pm2mat/cs193p-project-2-assignment-2-extra-task-3-winter-2015/ - project2assignment2extratask3https://githubcom/m2mtech/calculator-2015/tree/project2assignment2extratask3 Project 2 Assignment 2 Extra Task 2http://cs193pm2mat/cs193p-project-2-assignment-2-extra-task-2-winter-2015/ - project2assignment2extratask2https://githubcom/m2mtech/calculator-2015/tree/project2assignment2extratask2 Project 2 Assignment 2 Extra Task 1http://cs193pm2mat/cs193p-project-2-assignment-2-extra-task-1-winter-2015/ - project2assignment2extratask1https://githubcom/m2mtech/calculator-2015/tree/project2assignment2extratask1 Project 2 Assignment 2 Task 9http://cs193pm2mat/cs193p-project-2-assignment-2-task-9-winter-2015/ - project2assignment2task9https://githubcom/m2mtech/calculator-2015/tree/project2assignment2task9 Project 2 Assignment 2 Task 8http://cs193pm2mat/cs193p-project-2-assignment-2-task-8-winter-2015/ - project2assignment2task8https://githubcom/m2mtech/calculator-2015/tree/project2assignment2task8 Project 2 Assignment 2 Task 7http://cs193pm2mat/cs193p-project-2-assignment-2-task-7-winter-2015/ - project2assignment2task7https://githubcom/m2mtech/calculator-2015/tree/project2assignment2task7 Project 2 Assignment 2 Task 6http://cs193pm2mat/cs193p-project-2-assignment-2-task-6-winter-2015/ - project2assignment2task6https://githubcom/m2mtech/calculator-2015/tree/project2assignment2task6 Project 2 Assignment 2 Task 5http://cs193pm2mat/cs193p-project-2-assignment-2-task-5-winter-2015/ - project2assignment2task5https://githubcom/m2mtech/calculator-2015/tree/project2assignment2task5 Project 2 Assignment 2 Task 4http://cs193pm2mat/cs193p-project-2-assignment-2-task-4-winter-2015/ - project2assignment2task4https://githubcom/m2mtech/calculator-2015/tree/project2assignment2task4End of Lecture 5http://cs193pm2mat/cs193p-lecture-5-objective-c-compatibility-property-list-views-winter-2015/ - EndOfLecture5https://githubcom/m2mtech/calculator-2015/tree/EndOfLecture5 Project 1 Assignment 1 Internationalizationhttp://cs193pm2mat/cs193p-project-1-assignment-1-internationalization-winter-2015/ - project1assignment1internationalizationhttps://githubcom/m2mtech/calculator-2015/tree/project1assignment1internationalization Project 1 Assignment 1 Extra Task 4http://cs193pm2mat/cs193p-project-1-assignment-1-extra-task-4-winter-2015/ - project1assignment1extratask4correctedhttps://githubcom/m2mtech/calculator-2015/tree/project1assignment1extratask4corrected Project 1 Assignment 1 Extra Task 3http://cs193pm2mat/cs193p-project-1-assignment-1-extra-task-3-winter-2015/ - project1assignment1extratask3https://githubcom/m2mtech/calculator-2015/tree/project1assignment1extratask3 Project 1 Assignment 1 Extra Task 2http://cs193pm2mat/cs193p-project-1-assignment-1-extra-task-2-winter-2015/ - project1assignment1extratask2https://githubcom/m2mtech/calculator-2015/tree/project1assignment1extratask2 Project 1 Assignment 1 Extra Task 1http://cs193pm2mat/cs193p-project-1-assignment-1-extra-task-1-winter-2015/ - project1assignment1extratask1https://githubcom/m2mtech/calculator-2015/tree/project1assignment1extratask1 Project 1 Assignment 1 Task 5http://cs193pm2mat/cs193p-project-1-assignment-1-task-5-winter-2015/ - project1assignment1task5https://githubcom/m2mtech/calculator-2015/tree/project1assignment1task5 Project 1 Assignment 1 Task 4http://cs193pm2mat/cs193p-project-1-assignment-1-task-4-winter-2015/ - project1assignment1task4https://githubcom/m2mtech/calculator-2015/tree/project1assignment1task4 Project 1 Assignment 1 Task 3http://cs193pm2mat/cs193p-project-1-assignment-1-task-3-winter-2015/ - project1assignment1task3https://githubcom/m2mtech/calculator-2015/tree/project1assignment1task3 Project 1 Assignment 1 Task 2http://cs193pm2mat/cs193p-project-1-assignment-1-task-2-winter-2015/ - project1assignment1task2https://githubcom/m2mtech/calculator-2015/tree/project1assignment1task2End of Lecture 3http://cs193pm2mat/cs193p-lecture-3-applying-mvc-winter-2015/ - EndOfLecture3https://githubcom/m2mtech/calculator-2015/tree/EndOfLecture3End of Lecture 2http://cs193pm2mat/cs193p-lecture-2-more-xcode-and-swift-mvc-winter-2015/ - EndOfLecture2https://githubcom/m2mtech/calculator-2015/tree/EndOfLecture2End of Lecture 1http://cs193pm2mat/cs193p-lecture-1-logistics-ios8-overview-winter-2015/ - EndOfLecture1https://githubcom/m2mtech/calculator-2015/tree/EndOfLecture1,,False,False,45.0,11.0,34.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,
7,bcaffo/751and2,HW,bcaffo,751and2,7.0,Class github repository for 751 and 2; doctoral classes in the Department of Biostatistics at Johns Hopkins,1.0,0.0,0.0,2.0,23.0,0.0,7.0,2.0,0.0,16773.0,751 and 2 Instructor:     Brian Caffo PhD      Professor     Department of Biostatistics     Bloomberg School of Public Health     Johns Hopkins University Class github repository for 751 and 2 a doctoral classes in the Department of Biostatistics at Johns Hopkins for first year PhD students  Feel free to use the repository however youd like with attribution Please do not post solutions to the homeworks,,False,False,33.0,2.0,0.0,0.0,0.000184274313578,,,,,,0.733992940876,,,,,,0.26582278481,,,,,,,,,,,,,,,,,,,
8,HPI-SWA-Teaching/SWT16-Project-08,HW,HPI-SWA-Teaching,SWT16-Project-08,9.0,,17.0,1.0,3.0,0.0,5.0,2.0,0.0,0.0,0.0,328.0, PrettyPrettyPrint Build Statushttps://travis-ciorg/HPI-SWA-Teaching/PrettyPrettyPrintsvgbranchmasterhttps://travis-ciorg/HPI-SWA-Teaching/PrettyPrettyPrintInstallation Guide Via Github RepositoryStep 1Clone the repositoryStep 2Pull the package the package into your Squeak Image by adding it as a Monitcello filetree repositoryStep 3Change the method BehaviorprettyPrinterClass as follows:BehaviorprettyPrinterClass  PPPPrinter Via MetacelloStep 1Make sure you have metacello-workhttps://githubcom/dalehenrich/metacello-work installedStep 2Load the project by running the following in your workspace:Metacello new  baseline: PrettyPrettyPrint  repository: github://HPI-SWA-Teaching/PrettyPrettyPrint:master/packages   onConflict: :ex  ex allow  loadStep 3Change the method BehaviorprettyPrinterClass as follows:BehaviorprettyPrinterClass  PPPPrinterHow to UseTo pretty pretty print an entire package with the default settings execute the following command:PPPPrinter formatPackage: name of packageTo pretty pretty print an entire package with your userProfile execute the following command:PPPPrinter userFormatPackage: name of packageImplementation DetailsThe project contains four classes that aggregate most logic and a set of classes used to represent the nodes in the abstract syntax tree AST of a method The PPPTokenizerThe tokenizer implements the stream interface It operates on a string and returns instances of PPPToken The token types are identified via symbolic constants but have a number of test methods for a more finely grained check on their contents eg isOpeningCurlyBrace isIdentifier  Calling its next method repeatedly as defined by the Stream interface will yield new tokens until an EOF token is returned The PPPParserThe parser takes a stream of tokens so for us directly the PPPTokenizer and builds the AST based on those To facilitate the understanding of the parsing process and to give the methods a degree of isolation self nextToken always points at the first token of the node that is to be parsed upon entry of any parse method this contract is also the reason why self nextNextToken had to be created for assignmentsRough code flow when parsing a method is as follows: The method header is parsed parseMethod then either one of parseBinaryMessageDeclaration parseNamedMessageDeclaration parseUnaryMessageDeclaration The body of the method is parsed into a PPPSequenceNode parseSequence To parse the sequence parseStatement: is called repeatedly until the end of the method is reached parseStatement differentiates between assignments return statements and message sends message sends are further broken up into its three different types and special cases like cascades Any value blocks numbers literals  is regarded as receiver parseReceiver if its just an argument it will later not be wrapped in a PPPMessageNodeMethods responsible for parsing message sends carry a PPPParserState with them This is required for keeping the parse methods isolated while still maintaining the knowledge of whether we are currently parsing a multi part named message or a cascade The PPPPrinterThe printer is implemented as a visitor over the AST Each visit method returns a string so that the resulting length of a subexpression can be determined before printing it The indent is kept within the object and can be incremented or decremented upon encountering nodes that require such a change newLineIndentOn: can then be used to directly print a newline and the current indent on a given bufferDifferent methods can be used for pretty pretty printing more on preferences can be found in the next section: Calling format: will use the default set of preferences format:preferences: allows tweaking the default settings before they are used userProfileFormat: will use the current global profile format:in:notifying and format:in:notifying:decorated: are called by the CodeHolders to get pretty printed text In practice only the supplied string prove to be relevant for us so we are ignoring all other parameters The PPPPSettingsProfileThe printer has a PPPSettingsProfile that can be tweaked or overriden Its settings are used during the printing processOn its class side all options are duplicated This is done to provide user settings inside the Squeak Preference Browser Having the duplicated options allows providing the preferences in the browser while also being able to override them eg in tests or later on on a per project basis Having a single global set of options on the other hand prove impractical for both the user and testingWhen an option on the class side is changed all CodeHolder subinstaces are asked to force refresh their contents resulting in a live preview of the settings change To suppress this behavior eg when loading a set of preferences call freezeCodeHolderRefreshThe class also allows the import and export of the profile to the filesystem via importUserProfileFromFileNamed: and exportUserProfileFromFileNamed:,,False,False,100.0,1.0,1.0,1.0,,,,,,,0.0344100076823,,,,,,,,,,,,,,,,,,,,,,,,,0.965589992318
9,uwhpsc-2016/example-python-homework,HW,uwhpsc-2016,example-python-homework,2.0,An example homework assignment using Python.,4.0,0.0,0.0,4.0,7.0,2.0,0.0,2.0,0.0,7.0, Example Python HomeworkAn example homework assignment in Python for demonstrating how homework is donein the courseIn this example assignment we will learn some basic Python In particular wewill learn about basic Python arithmetic list handling and how to createPython modules as well as an introduction to writing tests using Pythonsunittest module ObjectiveProvide definitions to the functions square and cube defined in the Pythonsubmodules examplehomeworksquaring and examplehomeworkcubingrespectivelypythondef squarex:     return the square of x    def cubex:     return the cube of xThe provided example test suite can be executed using python /testexamplehomeworkpyAs always you are welcome and encouraged to add your own tests to the testsuite to ensure that your code is robust Most of all make sure that thesupplied tests pass so that the grading software can import and use yourfunction as expected GradingWhen the homework deadline is reached your implementation of square and cubewill be run against the following tests: 1/5 the square and cube of zero is zero already in the provided test suite 1/5 the square and cube of two is four and eight respectively already in  the provided test suite 1/5 square and cube should behave appropriately with complex numbers as  input eg 10 - 20j 2/5 these functions should also be able to act on Python lists of numbers  without the use of the Python function map that is if the input is of type  list then the output should also be of type list containing appropriate  corresponding valuesIt is important that the function names and locations DO NOT CHANGE Otherwisethe test suite used for grading may not be able to import your code If itsimportable in the test suite provided to you it should be importable in thegrading test suite,1.0,False,False,12.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
10,DataScienceSpecialization/courses,EDU,DataScienceSpecialization,courses,763.0,Course materials for the Data Science Specialization: https://www.coursera.org/specialization/jhudatascience/1,13.0,28.0,2.0,88.0,6482.0,38.0,2295.0,67.0,0.0,1083379.0, Data Science SpecializationThese are the course materials for the Johns Hopkins Data Science Specialization on Courserahttps://wwwcourseraorg/specialization/jhudatascience/1Materials are under development and subject to change  Contributors Brian Caffo Jeff Leek Roger Peng Nick Carchedi  Sean Kross LicenseThese course materials are available under the Creative Commons Attribution NonCommercial ShareAlike CC-NC-SA license http://wwwtldrlegalcom/l/CC-NC-SA ,,False,False,261.0,4.0,0.0,0.0,6.47077106683e-05,0.000623657788805,,0.358551922658,,,0.554802828296,,0.0774073434317,,0.00527300156057,,0.00327653855442,,,,,,,,,,,,,,,,,,,
11,githubteacher/intro-november-2015,EDU,githubteacher,intro-november-2015,35.0,Introduction to GitHub (November 2015),88.0,5.0,26.0,45.0,22.0,20.0,13.0,23.0,0.0,999.0, Introduction to GitHub Redesigned Theese changes introduce a new Design So you signed up for GitHub Now what Whether youre new to version control or just need an explanation of Git and GitHub this one hour class will help you understand the concepts of distributed version control and get started using GitHub Get to know basic Git concepts and GitHub workflows through step-by-step lessons Teachers- Allen Smith loranallensmith- Shikha Thakkar shikhathakkar Class Goals- Understand the concepts of distributed version control- Get started using GitHub- Basic Git concepts- GitHub workflows Resources- Mastering Markdownhttps://guidesgithubcom/features/mastering-markdown/- Understanding the GitHub Flowhttps://guidesgithubcom/introduction/flow/,,False,False,52.0,42.0,0.0,0.0,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
12,alex/what-happens-when,EDU,alex,what-happens-when,609.0,"An attempt to answer the age old interview question ""What happens when you type google.com into your browser and press enter?""",60.0,19.0,13.0,86.0,844.0,95.0,12335.0,27.0,0.0,531.0,What happens whenThis repository is an attempt to answer the age old interview question Whathappens when you type googlecom into your browsers address box and pressenterExcept instead of the usual story were going to try to answer this questionin as much detail as possible No skipping out on anythingThis is a collaborative process so dig in and try to help out Theres tons ofdetails missing just waiting for you to add them So send us a pull requestpleaseThis is all licensed under the terms of the Creative Commons Zero licenseRead this in  simplified Chinese NOTE: this has not been reviewedby the alex/what-happens-when maintainersTable of Contents contents::   :backlinks: none   :local:The g key is pressed----------------------The following sections explains all about the physical keyboardand the OS interrupts But a whole lot happens after that whichisnt explained When you just press g the browser receives theevent and the entire auto-complete machinery kicks into high gearDepending on your browsers algorithm and if you are inprivate/incognito mode or not various suggestions will be presentedto you in the dropbox below the URL bar Most of these algorithmsprioritize results based on search history and bookmarks You aregoing to type googlecom so none of it matters but a lot of codewill run before you get there and the suggestions will be refinedwith each key press It may even suggest googlecom before you type itThe enter key bottoms out---------------------------To pick a zero point lets choose the Enter key on the keyboard hitting thebottom of its range At this point an electrical circuit specific to the enterkey is closed either directly or capacitively This allows a small amount ofcurrent to flow into the logic circuitry of the keyboard which scans the stateof each key switch debounces the electrical noise of the rapid intermittentclosure of the switch and converts it to a keycode integer in this case 13The keyboard controller then encodes the keycode for transport to the computerThis is now almost universally over a Universal Serial Bus USB or Bluetoothconnection but historically has been over PS/2 or ADB connectionsIn the case of the USB keyboard:- The USB circuitry of the keyboard is powered by the 5V supply provided over  pin 1 from the computers USB host controller- The keycode generated is stored by internal keyboard circuitry memory in a  register called endpoint- The host USB controller polls that endpoint every 10ms minimum value  declared by the keyboard so it gets the keycode value stored on it- This value goes to the USB SIE Serial Interface Engine to be converted in  one or more USB packets that follows the low level USB protocol- Those packets are sent by a differential electrical signal over D and D-  pins the middle 2 at a maximum speed of 15 Mb/s as an HID  Human Interface Device device is always declared to be a low speed device  USB 20 compliance- This serial signal is then decoded at the computers host USB controller and  interpreted by the computers Human Interface Device HID universal keyboard  device driver  The value of the key is then passed into the operating  systems hardware abstraction layerIn the case of Virtual Keyboard as in touch screen devices:- When the user puts their finger on a modern capacitive touch screen a  tiny amount of current gets transferred to the finger This completes the  circuit through the electrostatic field of the conductive layer and  creates a voltage drop at that point on the screen The  screen controller then raises an interrupt reporting the coordinate of  the key press- Then the mobile OS notifies the current focused application of a press event  in one of its GUI elements which now is the virtual keyboard application  buttons- The virtual keyboard can now raise a software interrupt for sending a  key pressed message back to the OS- This interrupt notifies the current focused application of a key pressed  eventInterrupt fires NOT for USB keyboards---------------------------------------The keyboard sends signals on its interrupt request line IRQ which is mappedto an interrupt vector integer by the interrupt controller The CPU usesthe Interrupt Descriptor Table IDT to map the interrupt vectors tofunctions interrupt handlers which are supplied by the kernel When aninterrupt arrives the CPU indexes the IDT with the interrupt vector and runsthe appropriate handler Thus the kernel is enteredOn Windows A WMKEYDOWN message is sent to the app--------------------------------------------------------The HID transport passes the key down event to the KBDHIDsys driver whichconverts the HID usage into a scancode In this case the scan code isVKRETURN 0x0D The KBDHIDsys driver interfaces with theKBDCLASSsys keyboard class driver This driver is responsible forhandling all keyboard and keypad input in a secure manner It then calls intoWin32Ksys after potentially passing the message through 3rd partykeyboard filters that are installed This all happens in kernel modeWin32Ksys figures out what window is the active window through theGetForegroundWindow API This API provides the window handle of thebrowsers address box The main Windows message pump then callsSendMessagehWnd WMKEYDOWN VKRETURN lParam lParam is a bitmaskthat indicates further information about the keypress: repeat count 0 in thiscase the actual scan code can be OEM dependent but generally wouldnt befor VKRETURN whether extended keys eg alt shift ctrl were alsopressed they werent and some other stateThe Windows SendMessage API is a straightforward function thatadds the message to a queue for the particular window handle hWndLater the main message processing function called a WindowProc assignedto the hWnd is called in order to process each message in the queueThe window hWnd that is active is actually an edit control and theWindowProc in this case has a message handler for WMKEYDOWN messagesThis code looks within the 3rd parameter that was passed to SendMessagewParam and because it is VKRETURN knows the user has hit the ENTERkeyOn OS X A KeyDown NSEvent is sent to the app--------------------------------------------------The interrupt signal triggers an interrupt event in the I/O Kit kext keyboarddriver The driver translates the signal into a key code which is passed to theOS X WindowServer process Resultantly the WindowServer dispatches anevent to any appropriate eg active or listening applications through theirMach port where it is placed into an event queue Events can then be read fromthis queue by threads with sufficient privileges calling themachipcdispatch function This most commonly occurs through and ishandled by an NSApplication main event loop via an NSEvent ofNSEventType KeyDownOn GNU/Linux the Xorg server listens for keycodes---------------------------------------------------When a graphical X server is used X will use the generic eventdriver evdev to acquire the keypress A re-mapping of keycodes to scancodesis made with X server specific keymaps and rulesWhen the scancode mapping of the key pressed is complete the X serversends the character to the window manager DWM metacity i3 etc so thewindow manager in turn sends the character to the focused windowThe graphical API of the window  that receives the character prints theappropriate font symbol in the appropriate focused fieldParse URL--------- The browser now has the following information contained in the URL Uniform  Resource Locator:    - Protocol  http        Use Hyper Text Transfer Protocol    - Resource  /        Retrieve main index pageIs it a URL or a search term-----------------------------When no protocol or valid domain name is given the browser proceeds to feedthe text given in the address box to the browsers default web search engineIn many cases the url has a special piece of text appended to it to tell thesearch engine that it came from a particular browsers url barCheck HSTS list--------------- The browser checks its preloaded HSTS HTTP Strict Transport Security  list This is a list of websites that have requested to be contacted via  HTTPS only If the website is in the list the browser sends its request via HTTPS  instead of HTTP Otherwise the initial request is sent via HTTP  Note that a website can still use the HSTS policy without being in the  HSTS list  The first HTTP request to the website by a user will receive a  response requesting that the user only send HTTPS requests  However this  single HTTP request could potentially leave the user vulnerable to a  downgrade attack which is why the HSTS list is included in modern web  browsersConvert non-ASCII Unicode characters in hostname------------------------------------------------ The browser checks the hostname for characters that are not in a-z  A-Z 0-9 - or  Since the hostname is googlecom there wont be any but if there were  the browser would apply Punycode encoding to the hostname portion of the  URLDNS lookup---------- Browser checks if the domain is in its cache to see the DNS Cache in  Chrome go to chrome://net-internals/dns chrome://net-internals/dns If not found the browser calls gethostbyname library function varies by  OS to do the lookup gethostbyname checks if the hostname can be resolved by reference in the  local hosts file whose location varies by OS before trying to  resolve the hostname through DNS If gethostbyname does not have it cached nor can find it in the hosts  file then it makes a request to the DNS server configured in the network  stack This is typically the local router or the ISPs caching DNS server If the DNS server is on the same subnet the network library follows the  ARP process below for the DNS server If the DNS server is on a different subnet the network library follows  the ARP process below for the default gateway IPARP process-----------In order to send an ARP Address Resolution Protocol broadcast the networkstack library needs the target IP address to look up It also needs to know theMAC address of the interface it will use to send out the ARP broadcastThe ARP cache is first checked for an ARP entry for our target IP If it is inthe cache the library function returns the result: Target IP  MACIf the entry is not in the ARP cache: The route table is looked up to see if the Target IP address is on any of  the subnets on the local route table If it is the library uses the  interface associated with that subnet If it is not the library uses the  interface that has the subnet of our default gateway The MAC address of the selected network interface is looked up The network library sends a Layer 2 data link layer of the OSI model  ARP request:ARP Request::    Sender MAC: interface:mac:address:here    Sender IP: interfaceipgoeshere    Target MAC: FF:FF:FF:FF:FF:FF Broadcast    Target IP: targetipgoeshereDepending on what type of hardware is between the computer and the router:Directly connected: If the computer is directly connected to the router the router responds  with an ARP Reply see belowHub: If the computer is connected to a hub the hub will broadcast the ARP  request out all other ports If the router is connected on the same wire  it will respond with an ARP Reply see belowSwitch: If the computer is connected to a switch the switch will check its local  CAM/MAC table to see which port has the MAC address we are looking for If  the switch has no entry for the MAC address it will rebroadcast the ARP  request to all other ports If the switch has an entry in the MAC/CAM table it will send the ARP request  to the port that has the MAC address we are looking for If the router is on the same wire it will respond with an ARP Reply  see belowARP Reply::    Sender MAC: target:mac:address:here    Sender IP: targetipgoeshere    Target MAC: interface:mac:address:here    Target IP: interfaceipgoeshereNow that the network library has the IP address of either our DNS server orthe default gateway it can resume its DNS process: Port 53 is opened to send a UDP request to DNS server if the response size  is too large TCP will be used instead If the local/ISP DNS server does not have it then a recursive search is  requested and that flows up the list of DNS servers until the SOA is reached  and if found an answer is returnedOpening of a socket-------------------Once the browser receives the IP address of the destination server it takesthat and the given port number from the URL the HTTP protocol defaults to port80 and HTTPS to port 443 and makes a call to the system library functionnamed socket and requests a TCP socket stream - AFINET/AFINET6 andSOCKSTREAM This request is first passed to the Transport Layer where a TCP segment is  crafted The destination port is added to the header and a source port is  chosen from within the kernels dynamic port range iplocalportrange in  Linux This segment is sent to the Network Layer which wraps an additional IP  header The IP address of the destination server as well as that of the  current machine is inserted to form a packet The packet next arrives at the Link Layer A frame header is added that  includes the MAC address of the machines NIC as well as the MAC address of  the gateway local router As before if the kernel does not know the MAC  address of the gateway it must broadcast an ARP query to find itAt this point the packet is ready to be transmitted through either: Ethernet WiFi Cellular data networkFor most home or small business Internet connections the packet will pass fromyour computer possibly through a local network and then through a modemMOdulator/DEModulator which converts digital 1s and 0s into an analogsignal suitable for transmission over telephone cable or wireless telephonyconnections On the other end of the connection is another modem which convertsthe analog signal back into digital data to be processed by the next networknode where the from and to addresses would be analyzed furtherMost larger businesses and some newer residential connections will have fiberor direct Ethernet connections in which case the data remains digital andis passed directly to the next network node for processingEventually the packet will reach the router managing the local subnet Fromthere it will continue to travel to the ASs border routers other ASes andfinally to the destination server Each router along the way extracts thedestination address from the IP header and routes it to the appropriate nexthop The TTL field in the IP header is decremented by one for each router thatpasses The packet will be dropped if the TTL field reaches zero or if thecurrent router has no space in its queue perhaps due to network congestionThis send and receive happens multiple times following the TCP connection flow: Client chooses an initial sequence number ISN and sends the packet to the  server with the SYN bit set to indicate it is setting the ISN Server receives SYN and if its in an agreeable mood:    Server chooses its own initial sequence number    Server sets SYN to indicate it is choosing its ISN    Server copies the client ISN 1 to its ACK field and adds the ACK flag     to indicate it is acknowledging receipt of the first packet Client acknowledges the connection by sending a packet:    Increases its own sequence number    Increases the receiver acknowledgment number    Sets ACK field Data is transferred as follows:    As one side sends N data bytes it increases its SEQ by that number    When the other side acknowledges receipt of that packet or a string of     packets it sends an ACK packet with the ACK value equal to the last     received sequence from the other To close the connection:    The closer sends a FIN packet    The other sides ACKs the FIN packet and sends its own FIN    The closer acknowledges the other sides FIN with an ACKTLS handshake------------- The client computer sends a ClientHello message to the server with its  TLS version list of cipher algorithms and compression methods available The server replies with a ServerHello message to the client with the  TLS version selected cipher selected compression methods and the servers  public certificate signed by a CA Certificate Authority The certificate  contains a public key that will be used by the client to encrypt the rest of  the handshake until a symmetric key can be agreed upon The client verifies the server digital certificate against its list of  trusted CAs If trust can be established based on the CA the client  generates a string of pseudo-random bytes and encrypts this with the servers  public key These random bytes can be used to determine the symmetric key The server decrypts the random bytes using its private key and uses these  bytes to generate its own copy of the symmetric master key The client sends a Finished message to the server encrypting a hash of  the transmission up to this point with the symmetric key The server generates its own hash and then decrypts the client-sent hash  to verify that it matches If it does it sends its own Finished message  to the client also encrypted with the symmetric key From now on the TLS session transmits the application HTTP data encrypted  with the agreed symmetric keyHTTP protocol-------------If the web browser used was written by Google instead of sending an HTTPrequest to retrieve the page it will send a request to try and negotiate withthe server an upgrade from HTTP to the SPDY protocolIf the client is using the HTTP protocol and does not support SPDY it sends arequest to the server of the form::    GET / HTTP/11    Host: googlecom    Connection: close    other headerswhere other headers refers to a series of colon-separated key-value pairsformatted as per the HTTP specification and separated by single new linesThis assumes the web browser being used doesnt have any bugs violating theHTTP spec This also assumes that the web browser is using HTTP/11otherwise it may not include the Host header in the request and the versionspecified in the GET request will either be HTTP/10 or HTTP/09HTTP/11 defines the close connection option for the sender to signal thatthe connection will be closed after completion of the response For example    Connection: closeHTTP/11 applications that do not support persistent connections MUST includethe close connection option in every messageAfter sending the request and headers the web browser sends a single blanknewline to the server indicating that the content of the request is doneThe server responds with a response code denoting the status of the request andresponds with a response of the form::    200 OK    response headersFollowed by a single newline and then sends a payload of the HTML content ofwwwgooglecom The server may then either close the connection or ifheaders sent by the client requested it keep the connection open to be reusedfor further requestsIf the HTTP headers sent by the web browser included sufficient information forthe web server to determine if the version of the file cached by the webbrowser has been unmodified since the last retrieval ie if the web browserincluded an ETag header it may instead respond with a request ofthe form::    304 Not Modified    response headersand no payload and the web browser instead retrieves the HTML from its cacheAfter parsing the HTML the web browser and server repeats this processfor every resource image CSS faviconico etc referenced by the HTML pageexcept instead of GET / HTTP/11 the request will beGET /URL relative to wwwgooglecom HTTP/11If the HTML referenced a resource on a different domain thanwwwgooglecom the web browser goes back to the steps involved inresolving the other domain and follows all steps up to this point for thatdomain The Host header in the request will be set to the appropriateserver name instead of googlecomHTTP Server Request Handle--------------------------The HTTPD HTTP Daemon server is the one handling the requests/responses onthe server side The most common HTTPD servers are Apache or nginx for Linuxand IIS for Windows The HTTPD HTTP Daemon receives the request The server breaks down the request to the following parameters:    HTTP Request Method either GET HEAD POST PUT     DELETE CONNECT OPTIONS or TRACE In the case of a URL     entered directly into the address bar this will be GET    Domain in this case - googlecom    Requested path/page in this case - / as no specific path/page was     requested / is the default path The server verifies that there is a Virtual Host configured on the server  that corresponds with googlecom The server verifies that googlecom can accept GET requests The server verifies that the client is allowed to use this method  by IP authentication etc If the server has a rewrite module installed like modrewrite for Apache or  URL Rewrite for IIS it tries to match the request against one of the  configured rules If a matching rule is found the server uses that rule to  rewrite the request The server goes to pull the content that corresponds with the request  in our case it will fall back to the index file as / is the main file  some cases can override this but this is the most common method The server parses the file according to the handler If Google  is running on PHP the server uses PHP to interpret the index file and  streams the output to the clientBehind the scenes of the Browser----------------------------------Once the server supplies the resources HTML CSS JS images etcto the browser it undergoes the below process: Parsing - HTML CSS JS Rendering - Construct DOM Tree  Render Tree  Layout of Render Tree   Painting the render treeBrowser-------The browsers functionality is to present the web resource you choose byrequesting it from the server and displaying it in the browser windowThe resource is usually an HTML document but may also be a PDFimage or some other type of content The location of the resource isspecified by the user using a URI Uniform Resource IdentifierThe way the browser interprets and displays HTML files is specifiedin the HTML and CSS specifications These specifications are maintainedby the W3C World Wide Web Consortium organization which is thestandards organization for the webBrowser user interfaces have a lot in common with each other Among thecommon user interface elements are: An address bar for inserting a URI Back and forward buttons Bookmarking options Refresh and stop buttons for refreshing or stopping the loading of  current documents Home button that takes you to your home pageBrowser High Level StructureThe components of the browsers are: User interface: The user interface includes the address bar  back/forward button bookmarking menu etc Every part of the browser  display except the window where you see the requested page Browser engine: The browser engine marshals actions between the UI  and the rendering engine Rendering engine: The rendering engine is responsible for displaying  requested content For example if the requested content is HTML the  rendering engine parses HTML and CSS and displays the parsed content on  the screen Networking: The networking handles network calls such as HTTP requests  using different implementations for different platforms behind a  platform-independent interface UI backend: The UI backend is used for drawing basic widgets like combo  boxes and windows This backend exposes a generic interface that is not  platform specific  Underneath it uses operating system user interface methods JavaScript engine: The JavaScript engine is used to parse and  execute JavaScript code Data storage: The data storage is a persistence layer The browser may  need to save all sorts of data locally such as cookies Browsers also  support storage mechanisms such as localStorage IndexedDB WebSQL and  FileSystemHTML parsing------------The rendering engine starts getting the contents of the requesteddocument from the networking layer This will usually be done in 8kB chunksThe primary job of HTML parser to parse the HTML markup into a parse treeThe output tree the parse tree is a tree of DOM element and attributenodes DOM is short for Document Object Model It is the object presentationof the HTML document and the interface of HTML elements to the outside worldlike JavaScript The root of the tree is the Document object Prior ofany manipulation via scripting the DOM has an almost one-to-one relation tothe markupThe parsing algorithmHTML cannot be parsed using the regular top-down or bottom-up parsersThe reasons are: The forgiving nature of the language The fact that browsers have traditional error tolerance to support well  known cases of invalid HTML The parsing process is reentrant For other languages the source doesnt  change during parsing but in HTML dynamic code such as script elements  containing documentwrite calls can add extra tokens so the parsing  process actually modifies the inputUnable to use the regular parsing techniques the browser utilizes a customparser for parsing HTML The parsing algorithm is described indetail by the HTML5 specificationThe algorithm consists of two stages: tokenization and tree constructionActions when the parsing is finishedThe browser begins fetching external resources linked to the page CSS imagesJavaScript files etcAt this stage the browser marks the document as interactive and startsparsing scripts that are in deferred mode: those that should beexecuted after the document is parsed The document state isset to complete and a load event is firedNote there is never an Invalid Syntax error on an HTML page Browsers fixany invalid content and go onCSS interpretation------------------ Parse CSS files style tag contents and style attribute  values using CSS lexical and syntax grammar Each CSS file is parsed into a StyleSheet object where each object  contains CSS rules with selectors and objects corresponding CSS grammar A CSS parser can be top-down or bottom-up when a specific parser generator  is usedPage Rendering-------------- Create a Frame Tree or Render Tree by traversing the DOM nodes and  calculating the CSS style values for each node Calculate the preferred width of each node in the Frame Tree bottom up  by summing the preferred width of the child nodes and the nodes  horizontal margins borders and padding Calculate the actual width of each node top-down by allocating each nodes  available width to its children Calculate the height of each node bottom-up by applying text wrapping and  summing the child node heights and the nodes margins borders and padding Calculate the coordinates of each node using the information calculated  above More complicated steps are taken when elements are floated  positioned absolutely or relatively or other complex features  are used See  http://devw3org/csswg/css2/ and http://wwww3org/Style/CSS/current-work  for more details Create layers to describe which parts of the page can be animated as a group  without being re-rasterized Each frame/render object is assigned to a layer Textures are allocated for each layer of the page The frame/render objects for each layer are traversed and drawing commands  are executed for their respective layer This may be rasterized by the CPU  or drawn on the GPU directly using D2D/SkiaGL All of the above steps may reuse calculated values from the last time the  webpage was rendered so that incremental changes require less work The page layers are sent to the compositing process where they are combined  with layers for other visible content like the browser chrome iframes  and addon panels Final layer positions are computed and the composite commands are issued  via Direct3D/OpenGL The GPU command buffers are flushed to the GPU for  asynchronous rendering and the frame is sent to the window serverGPU Rendering------------- During the rendering process the graphical computing layers can use general  purpose CPU or the graphical processor GPU as well When using GPU for graphical rendering computations the graphical  software layers split the task into multiple pieces so it can take advantage  of GPU massive parallelism for float point calculations required for  the rendering processWindow Server-------------Post-rendering and user-induced execution-----------------------------------------After rendering has completed the browser executes JavaScript code as a resultof some timing mechanism such as a Google Doodle animation or userinteraction typing a query into the search box and receiving suggestionsPlugins such as Flash or Java may execute as well although not at this time onthe Google homepage Scripts can cause additional network requests to beperformed as well as modify the page or its layout causing another round ofpage rendering and painting Creative Commons Zero: https://creativecommonsorg/publicdomain/zero/10/ CSS lexical and syntax grammar: http://wwww3org/TR/CSS2/grammarhtml Punycode: https://enwikipediaorg/wiki/Punycode Ethernet: http://enwikipediaorg/wiki/IEEE8023 WiFi: https://enwikipediaorg/wiki/IEEE80211 Cellular data network: https://enwikipediaorg/wiki/Cellulardatacommunicationprotocol analog-to-digital converter: https://enwikipediaorg/wiki/Analog-to-digitalconverter network node: https://enwikipediaorg/wiki/ComputernetworkNetworknodes varies by OS : https://enwikipediaorg/wiki/Hosts28file29Locationinthefilesystem : https://githubcom/skyline75489/what-happens-when-zhCN downgrade attack: http://enwikipediaorg/wiki/SSLstripping OSI Model: https://enwikipediaorg/wiki/OSImodel,,False,False,274.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
13,MostlyAdequate/mostly-adequate-guide,EDU,MostlyAdequate,mostly-adequate-guide,443.0,Mostly adequate guide to FP (in javascript),101.0,32.0,94.0,33.0,688.0,155.0,9433.0,6.0,0.0,4435.0,coverimages/coverpngSUMMARYmd About this bookThis is a book on the functional paradigm in general Well use the worlds most popular functional programming language: JavaScript Some may feel this is a poor choice as its against the grain of the current culture which at the moment feels predominately imperative However I believe it is the best way to learn FP for several reasons:  You likely use it every day at work    This makes it possible to practice and apply your acquired knowledge each day on real world programs rather than pet projects on nights and weekends in an esoteric FP language  We dont have to learn everything up front to start writing programs    In a pure functional language you cannot log a variable or read a DOM node without using monads Here we can cheat a little as we learn to purify our codebase Its also easier to get started in this language since its mixed paradigm and you can fall back on your current practices while there are gaps in your knowledge  The language is fully capable of writing top notch functional code    We have all the features we need to mimic a language like Scala or Haskell with the help of a tiny library or two Object-oriented programming currently dominates the industry but its clearly awkward in JavaScript Its akin to camping off of a highway or tap dancing in galoshes We have to bind all over the place lest this change out from under us we dont have classes yet we have various work arounds for the quirky behavior when the new keyword is forgotten private members are only available via closures To a lot of us FP feels more natural anywaysThat said typed functional languages will without a doubt be the best place to code in the style presented by this book JavaScript will be our means of learning a paradigm where you apply it is up to you Luckily the interfaces are mathematical and as such ubiquitous Youll find yourself at home with swiftz scalaz haskell purescript and other mathematically inclined environments Gitbook for a better reading experience Read it onlinehttps://drbooleangitbooksio/mostly-adequate-guide/content/ Download EPUBhttps://wwwgitbookcom/download/epub/book/drboolean/mostly-adequate-guide Download Mobi Kindlehttps://wwwgitbookcom/download/mobi/book/drboolean/mostly-adequate-guide Do it yourselfgit clone https://githubcom/DrBoolean/mostly-adequate-guidegitcd mostly-adequate-guide/npm install gitbook-cli -ggitbook initbrew updatebrew install Caskroom/cask/calibregitbook mobi  /functionalmobi Table of ContentsSee SUMMARYmdSUMMARYmd ContributingSee CONTRIBUTINGmdCONTRIBUTINGmd TranslationsSee TRANSLATIONSmdTRANSLATIONSmd FAQSee FAQmdFAQmd Plans for the future Part 1 currently chapters 1-7 is a guide to the basics Im updating as I find errors since this is the initial draft Feel free to help Part 2 currently chapters 8 will address type classes like functors and monads all the way through to traversable I hope to squeeze in transformers and a pure application Part 3 will start to dance the fine line between practical programming and academic absurdity Well look at comonads f-algebras free monads yoneda and other categorical constructs,,False,False,436.0,6.0,0.0,0.0,,,,0.993649149586,,,0.0063508504143,,,,,,,,,,,,,,,,,,,,,,,,,
14,AllThingsSmitty/jquery-tips-everyone-should-know,EDU,AllThingsSmitty,jquery-tips-everyone-should-know,223.0,A collection of tips to help up your jQuery game,13.0,16.0,16.0,3.0,378.0,12.0,3789.0,2.0,0.0,252.0, jQuery Tips Everyone Should Know Awesomehttps://cdnrawgitcom/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badgesvghttps://githubcom/sindresorhus/awesomeA collection of simple tips to help up your jQuery game For other great lists check out sindresorhushttps://githubcom/sindresorhus/s curated list of awesome listshttps://githubcom/sindresorhus/awesome/ Table of Contents Tipstips Supportsupport Translationstranslations Contribution GuidelinesCONTRIBUTINGmd Tips1 Checking If jQuery Loadedchecking-if-jquery-loaded1 Use on Binding Instead of clickuse-on-binding-instead-of-click1 Back to Top Buttonback-to-top-button1 Preload Imagespreload-images1 Checking If Images Are Loadedchecking-if-images-are-loaded1 Fix Broken Images Automaticallyfix-broken-images-automatically1 Post a Form with AJAXpost-a-form-with-ajax1 Toggle Classes on Hovertoggle-classes-on-hover1 Disabling Input Fieldsdisabling-input-fields1 Stop the Loading of Linksstop-the-loading-of-links1 Cache jQuery Selectorscache-jquery-selectors1 Toggle Fade/Slidetoggle-fadeslide1 Simple Accordionsimple-accordion1 Make Two Divs the Same Heightmake-two-divs-the-same-height1 Open External Links in New Tab/Windowopen-external-links-in-new-tabwindow1 Find Element By Textfind-element-by-text1 Trigger on Visibility Changetrigger-on-visibility-change1 Ajax Call Error Handlingajax-call-error-handling1 Chain Plugin Callschain-plugin-calls1 Sort List Items Alphabeticallysort-list-items-alphabetically Checking If jQuery LoadedBefore you can do anything with jQuery you first need to make certain it has loaded:javascriptif typeof jQuery  undefined   consolelogjQuery hasnt loaded else   consolelogjQuery has loadedNow youre offsupback to table of contentstable-of-contents/sup Use on Binding Instead of clickUsing on gives you several advantages over using click such as the ability to add multiple eventsjavascriptonclick tap hovera binding applies to dynamically created elements as well theres no need to manually bind every single element dynamically added to a DOM elementand the possibility to set a namespace:javascriptonclickmenuOpeningNamespaces give you the power to unbind a specific event eg offclickmenuOpeningsupback to table of contentstable-of-contents/sup Back to Top ButtonBy using the animate and scrollTop methods in jQuery you dont need a plugin to create a simple scroll-to-top animation:javascript// Back to topcontaineronclick back-to-top function e   epreventDefault  html bodyanimatescrollTop: 0 800html-- Create an anchor tag --div classcontainer  a href classback-to-topBack to top/a/divChanging the scrollTop value changes where you wants the scrollbar to land All youre really doing is animating the body of the document throughout the course of 800 milliseconds until it scrolls to the top of the documentNote: Watch for some buggy behaviorhttps://githubcom/jquery/apijquerycom/issues/417 with scrollTopsupback to table of contentstable-of-contents/sup Preload ImagesIf your web page uses a lot of images that arent visible initially eg on hover it makes sense to preload them:javascriptpreloadImages  function    for var i  0 i  argumentslength i     imgattrsrc argumentsi  preloadImagesimg/hover-onpng img/hover-offpngsupback to table of contentstable-of-contents/sup Checking If Images Are LoadedSometimes you might need to check if your images have fully loaded in order to continue on with your scripts:javascriptimgonload function    consolelogimage load successfulYou can also check if one particular image has loaded by replacing the img tag with an ID or classsupback to table of contentstable-of-contents/sup Fix Broken Images AutomaticallyIf you happen to find broken image links on your site replacing them one by one can be a pain This simple piece of code can save a lot of headaches:javascriptimgonerror function    ifthishasClassbroken-image     thispropsrc img/brokenpngaddClassbroken-image  Alternatively if you wish to simply hide broken images this snippet will take care of that for:javascriptimgonerror function    thishidesupback to table of contentstable-of-contents/sup Post a Form with AJAXjQuery AJAX methods are a common way to request text HTML XML or JSON If you wanted to send a form via AJAX you could collect the user inputs via the val method:javascriptpostsignupphp   username: inputnameusernameval  email:     inputnameemailval  password:  inputnamepasswordvalHowever all of those val calls are expensive A better way of collecting the user inputs is using the serialize function which collects the user inputs as a string:javascriptpostsignup sign-up-formserializesupback to table of contentstable-of-contents/sup Toggle Classes on HoverLets say you want to change the visual of a clickable element on your page when a user hovers over it You can add a class to your element when the user is hovering when the user stops hovering removes the class:javascriptbtnonhover function    thisaddClasshover function    thisremoveClasshoverYou just need to add the necessary CSS If you want an even simpler way use the toggleClass method:javascriptbtnonhover function    thistoggleClasshoverNote: CSS may be a faster solution in this case but its still worthwhile to know thissupback to table of contentstable-of-contents/sup Disabling Input FieldsAt times you may want the submit button of a form or one of its text inputs to be disabled until the user has performed a certain action eg checking the Ive read the terms checkbox Add the disabled attribute to your input so you can enable it when you want:javascriptinputtypesubmitpropdisabled trueAll you need to do is run the prop method again on the input but set the value of disabled to false:javascriptinputtypesubmitpropdisabled falsesupback to table of contentstable-of-contents/sup Stop the Loading of LinksSometimes you dont want links to go to a certain web page nor reload the page you might want them to do something else like trigger some other script This will do the trick of preventing the default action:javascriptano-linkonclick function e   epreventDefaultsupback to table of contentstable-of-contents/sup Cache jQuery SelectorsThink of how many times you write the same selector over and over again in any project Every element selector has to search the entire DOM each time regardless if that selector had previously run Instead run the selector once and store the results in a variable:javascriptvar blocks  blocksfindliNow you can use the blocks variable wherever you want without having to search the DOM every time:javascripthideBlocksonclick function    blocksfadeOutshowBlocksonclick function    blocksfadeInCaching jQuery selectors are an easy performance gainsupback to table of contentstable-of-contents/sup Toggle Fade/SlideSliding and fading are something we use plenty in our animations with jQuery You might just want to show an element when a user clicks something which makes the fadeIn and slideDown methods perfect But if you want that element to appear on the first click and then disappear on the second this will work just fine:javascript// Fadebtnonclick function    elementfadeToggleslow// Togglebtnonclick function    elementslideToggleslowsupback to table of contentstable-of-contents/sup Simple AccordionThis is a simple method for a quick accordion:javascript// Close all panelsaccordionfindcontenthide// Accordionaccordionfindaccordion-headeronclick function    var next  thisnext  nextslideTogglefast  contentnotnextslideUpfast  return falseBy adding this script all you really needs to do on your web page is the necessary HTML go get this workingsupback to table of contentstable-of-contents/sup Make Two Divs the Same HeightSometimes youll want two divs to have the same height no matter what content they have in them:javascriptdivcssmin-height main-divheightThis example sets the min-height which means that it can be bigger than the main div but never smaller However a more flexible method would be to loop over a set of elements and set the height to the height of the tallest element:javascriptvar columns  columnvar height  0columnseachfunction    if thisheight  height     height  thisheight  columnsheightheightIf you want all columns to have the same height:javascriptvar rows  same-height-columnsrowseachfunction    thisfindcolumnheightthisheightNote: This can be done several ways in CSShttp://codepenio/AllThingsSmitty/pen/KMPqoO but depending on what your needs are knowing how to do this in jQuery is still worthwhilesupback to table of contentstable-of-contents/sup Open External Links in New Tab/WindowOpen external links in a new browser tab or window and ensure links on the same origin open in the same tab or window:javascriptahrefhttpattrtarget blankahref//attrtarget blankahref  windowlocationorigin  attrtarget selfNote: windowlocationorigin doesnt work in IE10 This fixhttp://tosbourncom/a-fix-for-window-location-origin-in-internet-explorer/ takes care of the issuesupback to table of contentstable-of-contents/sup Find Element By TextBy using the contains selector in jQuery you can find text in content of an element If text doesnt exists that element will be hidden:javascriptvar search  searchvaldiv:not:contains  search  hidesupback to table of contentstable-of-contents/sup Trigger on Visibility ChangeTrigger JavaScript when the user is no longer focusing on a tab or refocuses on a tab:javascriptdocumentonvisibilitychange function e   if etargetvisibilityState  visible     consolelogTab is now in view   else if etargetvisibilityState  hidden     consolelogTab is now hidden  supback to table of contentstable-of-contents/sup Ajax Call Error HandlingWhen an Ajax call returns a 404 or 500 error the error handler will be executed If the handler isnt defined other jQuery code might not work anymore Define a global Ajax error handler:javascriptdocumentonajaxError function e xhr settings error   consolelogerrorsupback to table of contentstable-of-contents/sup Chain Plugin CallsjQuery allows for the chaining of plugin method calls to mitigate the process of repeatedly querying the DOM and creating multiple jQuery objects Lets say the following snippet represents your plugin method calls:javascriptelemshowelemhtmlblaelemotherStuffThis could be vastly improved by using chaining:javascriptelem  show  htmlbla  otherStuffAn alternative is to cache the element in a variable prefixed with :javascriptvar elem  elemelemhideelemhtmlblaelemotherStuffBoth chaining and cachingcache-jquery-selectors methods in jQuery are best practices that lead to shorter and faster codesupback to table of contentstable-of-contents/sup Sort List Items AlphabeticallyLets say you end up with too many items in a list Maybe the content is produced by a CMS and you want to order them alphabetically:javascriptvar ul  listlis  li ulgetlissortfunction a b   return atexttoUpperCase  btexttoUpperCase  -1 : 1ulappendlisThere you gosupback to table of contentstable-of-contents/sup SupportCurrent versions of Chrome Firefox Safari Opera Edge and IE11 Translations Espaolhttps://githubcom/AllThingsSmitty/jquery-tips-everyone-should-know/tree/master/translations/es-ES Franaishttps://githubcom/AllThingsSmitty/jquery-tips-everyone-should-know/tree/master/translations/fr-FR Phttps://githubcom/AllThingsSmitty/jquery-tips-everyone-should-know/tree/master/translations/ru-RU https://githubcom/AllThingsSmitty/jquery-tips-everyone-should-know/tree/master/translations/zh-CN https://githubcom/AllThingsSmitty/jquery-tips-everyone-should-know/tree/master/translations/zh-TW,,False,False,130.0,2.0,0.0,0.0,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,
15,CMSgov/HealthCare.gov-Styleguide,DOCS,CMSgov,HealthCare.gov-Styleguide,26.0,CMS Developer Site,19.0,4.0,12.0,5.0,18.0,172.0,29.0,3.0,0.0,40862.0, styleguidehealthcaregovhttps://styleguidehealthcaregovTo get started with the HealthCaregov assets library youll need to use the required HTML grid system framework JavaScript and CSSMore detail info can be found at styleguidehealthcaregovhttps://styleguidehealthcaregov Table of contents- Quick startquick-start- Whats includedwhats-included- Bugs and feature requestsbugs-and-feature-requests- Documentationdocumentation- Running documentation locallyrunning-documentation-locally- Contributingcontributing- Copyright and licensecopyright-and-license Quick startA couple of quick start options are available:- Download the latest releasehttps://githubcom/CMSgov/HealthCaregov-Styleguide/archive/masterzip- Clone the repo: git clone https://githubcom/CMSgov/HealthCaregov-StyleguidegitRead the Assets landing pagehttps://styleguidehealthcaregov/assets/ for information on the framework contents templates and examples and more Whats includedWithin the download youll find the following directories and files logically grouping common assets Youll see something like this:assets-components/ css/    bootstrap/    cards/    components/    forms/    layouts/    allless    stylecss fonts/     Bitter-Boldeot     Bitter-Italiceot     Bitter-Regulareot     glyphicons-halflings-regulareot     OpenSans-Bold-webfonteot     OpenSans-Italic-webfonteot     OpenSans-Regular-webfonteot     OpenSans-Semibold-webfonteotWe provide compiled CSS stylecss as well as the CSS Less source Glyphicon fonts are also included Since this styleguides functionality is built directly on top of Bootstrap you will need to include references to our jQuery and Bootstrap code bases in your html file:- https://assetshealthcaregov/resources/libs/jquery/111/js/jqueryminjs- https://assetshealthcaregov/resources/libs/bootstrap/311/js/bootstrapminjsNote: Assetshealthcaregovhttps://assetshealthcaregov gives you Section 508 compliant cross-browser compatible UI components that you can use in your accessible web site or web application Assets is an accessible responsive and modern framework Bugs and feature requestsHave a bug to report or a feature to request Please  read our contribution policyhttps://githubcom/CMSgov/HealthCaregov-Styleguide/blob/master/CONTRIBUTINGmd and search for existing and closed issues If your problem or idea is not addressed yet you can open a new issuehttps://githubcom/CMSgov/HealthCaregov-Styleguide/issues/new DocumentationHealthCaregovs Styleguide documentation included in this repo in the gh-pages branch root directory is built with Jekyllhttp://jekyllrbcom and publicly hosted on GitHub Pages at https://styleguidehealthcaregov/ The docs may also be run locally Running documentation locally1 If necessary install Jekyllhttp://jekyllrbcom/docs/installation requires version 25x  - Windows users: Read this unofficial guidehttp://jekyll-windowsjuthilocom/ to get Jekyll up and running without problems2 From the gh-pages branch root directory run jekyll serve in the command line3 Open http://localhost:9001 in your browser and you should see the entire Styleguide documentation run locally ContributingPlease read through our contribution guidelineshttps://githubcom/CMSgov/HealthCaregov-Styleguide/blob/master/CONTRIBUTINGmd Included are directions for opening issues coding standards and notes on development Copyright and licenseAs a work of the United States Government this project is in the public domain within the United StatesFull license can be found herehttps://githubcom/CMSgov/HealthCaregov-Styleguide/blob/master/LICENSEmd,,False,True,73.0,5.0,0.0,0.0,,,,0.00730583677332,,,0.230685291114,,0.762008872113,,,,,,,,,,,,,,,,,,,,,,,
16,github/maturity-model,DOCS,github,maturity-model,9.0,A maturity model for adopting open source,611.0,1.0,0.0,1.0,7.0,2.0,16.0,0.0,0.0,1623.0, A maturity model for embracing open sourceA maturity modelhttp://martinfowlercom/bliki/MaturityModelhtml is a tool to assess the effectiveness of behaviors practices and processes in producing the desired outcomes The model defines a set of structured levels that lead an organization down a path of more systematically organized and mature processesEmbracing open source software is not a single act but a series of steps varying in complexity that require unique knowledge and processes at each step A maturity model for embracing open source software will guide an organization through the process of successfully adopting open source ObjectivesAn organization applying the maturity model aims to:- Produce higher quality products and services built on open source software components- Create value by using open source as a force multiplier shifting limited resources from low-value work to high-value work focusing on core competencies and benefiting from the expertise of the community- Gain industry-wide recognition that serves as advertising recruiting or general leadership ActorsThere are several roles in an organization that face unique benefits and challenges with adopting open source- Developers interact directly with the code and witness the material benefits of open source They experience the difference between writing custom code and finding high-quality reusable components on the internet- Technical leadership benefits from the increase in quality and efficiency of their teams but has to be aware of the long-term consequences of the adopted technologies- Security benefits from software that is open for inspection and has been potentially reviewed and hardened by the community but has to continuously monitor for un-vetted code as well as vulnerabilities and exposures- Operations benefit from reduced costs for software procurement and licensing- Legal benefits from standardized software licenses but has to monitor for intellectual property concerns- Business leadership benefits from increased efficiency and quality the reduction of unnecessary overhead and the opportunity for alternate business models but has to navigate the risk of disrupting core business value StructureThis maturity model is inspired by the Capability Maturity Modelhttps://enwikipediaorg/wiki/CapabilityMaturityModel The model involves six components:resources/structurepng- Dimensions: aspects that require maturity in different Key Process Areas- Maturity Levels: a continuum of five level levels that indicate the ability for processes to produce the desired results- Key Process Areas: a cluster of related activities that when performed together achieve a set of goals considered important- Goals: The goals signify the scope boundaries and intent of each key process area and the extent to which the goals have been accomplished is an indicator of capability at that maturity level- Common Features: practices that implement and institutionalize a key process area There are five types of common features: commitment to perform ability to perform activities performed measurement and analysis and verifying implementation- Key Practices: elements of infrastructure and practice that contribute most effectively to the implementation and institutionalization of the area DimensionsThere are three dimensions to embracing open source:1 Consuming open source software2 Contributing back to the open source projects you consume3 Producing your own open source software Levels1 Ad-hoc - a new or undocumented process is uncontrolled reactive and unpredictable typically driven by individuals without coordination or communication Success depends on individual heroics2 Managed - a process is partially documented possibly leading to consistent results Success depends on discipline3 Defined - a process is documented standardized and integrated into other processes Success depends on automation4 Measured - the process is quantitatively managed Success depends on measuring metrics against business goals5 Optimized - the process is continually and reliably improving through both incremental and innovative changes Success depends on reducing the risk of change Potential applications of the Maturity ModelThe maturity model is being developed with two primary goals in mind:- Evaluating how GitHub products programs services and resources are helping customers develop more mature practices around open source- Creating a comprehensive starter kit that includes all the resources needed to use contribute to release and manage open source projects on GitHub Current StatusThe maturity model is currently a very early concept and actively being developed Sticky Notes for brainstorming the activities involved in open sourcehttps://stickiesio/boards/564eda3fefefba0b2fe8a0721 Bookmarks primary sources and notes are being gathered in an Evernote notebookhttps://wwwevernotecom/pub/bkeepers/maturitymodel Credits- Wikipedia: Capability Maturity Modelhttps://enwikipediaorg/wiki/CapabilityMaturityModel- Martin Fowler: MaturityModelhttp://martinfowlercom/bliki/MaturityModelhtml LicenseCopyright  2016 GitHub Inc and Contributors This work is licensed under a Creative Commons Attribution 40 International Licensehttp://creativecommonsorg/licenses/by/40/,,False,False,18.0,3.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
17,raspberrypi/documentation,DOCS,raspberrypi,documentation,213.0,Official documentation for the Raspberry Pi,161.0,61.0,142.0,95.0,612.0,148.0,1106.0,37.0,0.0,51404.0, Raspberry Pi DocumentationBuild Statushttps://travis-ciorg/raspberrypi/documentationsvgbranchmasterhttps://travis-ciorg/raspberrypi/documentationThis is the official documentation for the Raspberry Pi written by the Raspberry Pi Foundationhttps://wwwraspberrypiorg/ with community contributions Contents- Setup / Quickstartsetup/READMEmd    - Getting started with your Raspberry Pi including what you need and how to get it booted- Installationinstallation/READMEmd    - Installing an operating system on your Raspberry Pi- Usage Guideusage/READMEmd    - Explore the desktop and try out all the main applications- Configurationconfiguration/READMEmd    - Configuring the Pis settings to suit your needs- Remote Accessremote-access/READMEmd    - Accessing your Pi remotely via SSH VNC or over the web- Linuxlinux/READMEmd    - Fundamental Linux usage for beginners and more advanced information for power users- Raspbianraspbian/READMEmd    - Information about the recommended operating system for Raspberry Pi- Hardwarehardware/READMEmd    - Technical specifications about the Raspberry Pi hardware and the camera module ContributionsIf you have anything to fix or details to add first file an issuehttp://githubcom/raspberrypi/documentation/issues on GitHub to see if it is likely to be accepted then file a pull request with your change one PR per issueThis is not intended to be an open wiki we want to keep it concise and minimal but will accept fixes and suitable additionsSee our contributing policyCONTRIBUTINGmd LicenceUnless otherwise specified everything in this repository is covered by the following licence:Creative Commons Attribution-ShareAlike 40 Internationalhttps://licensebuttonsnet/l/by-sa/40/88x31pnghttp://creativecommonsorg/licenses/by-sa/40/Raspberry Pi Documentation by the Raspberry Pi Foundationhttps://wwwraspberrypiorg/ is licensed under a Creative Commons Attribution 40 International Licencehttp://creativecommonsorg/licenses/by-sa/40/Based on a work at https://githubcom/raspberrypi/documentation,0.660540636988,False,False,1453.0,1.0,0.0,0.0,0.247390489785,,0.0920688732269,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
18,bundestag/gesetze,DOCS,bundestag,gesetze,209.0,Bundesgesetze und -verordnungen,10.0,8.0,3.0,38.0,135.0,6.0,1323.0,14.0,0.0,185337.0,Deutsche Bundesgesetze und -verordnungenDieses Git Repository enthlt alle Deutschen Bundesgesetze und -verordnungenim Markdown-Formathttp://daringfireballnet/projects/markdown/ Als Quelledienen die XML-Versionen der Gesetze vonwwwgesetze-im-internetdehttp://wwwgesetze-im-internetde/Warum Git----------Jeder Brger kann den aktuellen Stand von Gesetzen sehr einfach online findenAllerdings ist die Entstehung die historische Entwicklung und dieAktualisierung von Gesetzen nicht einfach und frei nachvollziehbar Das liegtdaran dass Gesetze nur in ihrer aktuellsten Version prsentiert werden undnderungen an diesen Gesetzen nicht maschinenlesbar vorliegen Dies soll hiergendert werden: die aktuellste Version eines Gesetzes wird hier mit Gitversioniert gespeichert Das erlaubt es die Mchtigkeit von Git auf Gesetzeund auf den Gesetzgebungsprozess anzuwenden Das Einpflegen der komplettendeutschen Gesetzesvergangenheit in Git ist das ferne ZielWarum Markdown---------------Gesetze sind Prosa sie enthalten keine maschinenlesbare Semantik EineAuszeichnungssprache wie XML verringert die Menschenlesbarkeit erschwert diemaschinelle Erkennung von Unterschieden und beinhaltet viel berflssigeSyntaxMarkdown ist eine intuitive Formatierung von Text die ohne zustzlicheProgramme fr Menschen les- und schreibbar ist Das passt zu Gesetzestextendie nur minimale Formatierung bentigen Weiterhin lsst sich Markdown inandere Formate wie HTML konvertieren und ist damit maschinen-formatierbarPull Requests-------------Pull Requests knnen gerne geffnet werden Natrlich werden nur solchegemergt die tatschlich vom Bundestag verabschiedet wurden und Gesetzgeworden sindDennoch sind nderungsvorschlge an Gesetzen von Parteien oder aus derZivilgesellschaft als Pull Request ntzlich Die nderungen lassen sicheinfacher im Kontext verstehen knnen direkt am Gesetz diskutiert undnachvollziehbar verndert werdenOffizielle Gesetzesentwrfe wenn ffentlich verfgbar werden vom Fork derBundesregierunghttps://githubcom/bundesregierung/ als Pull Request andieses Repository gestelltFehler und Bitte um Mithilfe----------------------------Es wird kein Anspruch auf Korrektheit erhoben Bitte verlassen Sie sich nurauf offizielle QuellenDie XML-Quelle ist nicht fehlerfrei und die Konvertierung von XML nachMarkdown ist es auch nicht Das liegt daran dass die Gesetze im XML-Formatdas Markup auch fr stilistische Auszeichnungen statt nur fr semantischeAuszeichnungen nutzen Dies erschwert eine Konvertierung und fhrt zufehlerhaftem Markdown Da fehlerhaftes Markdown immer noch gut lesbar istfhrt dies erst bei einer Weiterverarbeitung zu ProblemenCommits richten sich nach Mglichkeit nach den Verffentlichungen imBundesgesetzblatt und im Amtlichen Teil des Bundesanzeigers Das funktioniertnicht immer problemlos und erfordert menschliche UntersttzungWerkzeuge die die Aktualisierung vereinfachen finden sich imgesetze-tools repositoryhttps://githubcom/bundestag/gesetze-toolsMithilfe ist erwnschtUm die Fhigkeiten von Git optimal zu nutzen wird es ntig sein Commits dieGesetzesnderungen einbringen von Commits die zB Korrekturen an der Syntaxvornehmen oder die README verndern zu unterscheiden Hier wird um Mithilfebei der Ausarbeitung eines Git-Workflowshttps://githubcom/bundestag/gesetze/wiki/Git-Workflowfr dieses Repostiory gebetenRechtliches-----------Gesetze sind amtliche Werke und unterliegen nicht dem UrheberrechtKontakt-------Twitter: bundesgithttps://twittercom/bundesgit--------english versionGerman Federal Laws and RegulationsThis Git repository contains all German federal laws and regulations inMarkdown formathttp://daringfireballnet/projects/markdown/ The sourceis the XML version of the laws fromwwwgesetze-im-internetdehttp://wwwgesetze-im-internetde/Why Git----------All German citizens can easily find an up-to-date version of their laws onlineHowever the legislation process the historic evolution and the updates to lawsare not easily and freely trackable The reason is that laws are only publishedin their most recent version and changes to laws are not available in amachine-readable formatThis should change: the current state of laws will be stored in this repositoryunder Git version control This allows the power of Git to be applied to thelegislation process Integrating the whole history of German law changes in Gitis the ambitious goalWhy Markdown-------------Laws are prose they do not contain machine-readable semanticsA complex markup language like XML reduces the human-readabilitymakes detection of differences harder and contains lots ofunnecessary syntaxMarkdown is an intuitive formatting of text that is readable andwritable by humans without the need of additional tools That fitsthe nature of laws that only need minimal formatting FurthermoreMarkdown is machine-formattable and can be converted to other formatslike HTMLPull Requests-------------You are encouraged to open pull request Of course only valid legislationvoted on by the Bundestag will be mergedHowever law change proposals as pull requests coming from parties orNGOs can be useful to understand context discuss changes directly wherethey will happen and keep changes accountableOfficial change proposals from our government will be opened as pullrequests from the fork of the Bundesregierunghttps://githubcom/bundesregierung/as they become publicy availableMistakes and call for help--------------------------There is no guarantee on correctness Please only trust official sourcesThe source XML is not without mistakes and neither is the conversion toMarkdown Thats because the source XML uses markup for style and not onlyfor semantics This makes conversion harder and comes down to faultyMarkdown However faulty Markdown is still very readable and will onlycause problems when processed furtherCommits will be based on published changes Bundesgesetzblatt and BundesanzeigerThat doesnt work without problems and requires human interactionTools that make updates easier can be found in thegesetze-tools repositoryhttps://githubcom/bundestag/gesetze-toolsHelp neededIn order to make the most out of Git we need to distinguish between law changecommits and commits that fix eg syntax mistakesPlease help shape a Git Workflowhttps://githubcom/bundestag/gesetze/wiki/Git-Workflowfor this repositoryLegal Stuff-----------All laws are offical works and are not under copyright lawContact-------Twitter: bundesgithttps://twittercom/bundesgit,,False,True,510.0,77.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
19,fsr-itse/docs,DOCS,fsr-itse,docs,11.0,Dokumente der Fachschaft IT-Systems Engineering am Hasso-Plattner-Institut an der Universität Potsdam,4.0,5.0,0.0,2.0,7.0,7.0,14.0,2.0,0.0,39.0, Dokumente der Fachschaft IT-Systems Engineering am Hasso-Plattner-Institut an der Universitt PotsdamDieses Git Repository enthlt die Satzung und die Wahlordnung der Fachschaft IT-Systems Engineering im Markdown-Format Hier lassen sich bisherige Versionen ansehen und nderungen nachverfolgen Pull requests sind sehr herzlich willkommenBevor eine nderung in der Satzung erscheint muss sie jedoch von der Vollversammlung der Fachschaft angenommen werdennderungen an der Wahlordnung bedrfen eines Beschlusses des Fachschaftsrates RichtlinienDamit die nderungen an den Dateien minimiert werden und leicht verfolgbar sind gibt es folgende Vorgaben: nderungen die keinen Beschluss erfordern sind in der Commit message mit nicht inhaltlich zu kennzeichnen Als Line endings ist der Unix style zu nutzen Alle Dateien sind UTF-8 encoded,,False,False,35.0,2.0,12.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
20,BloombergMedia/whatiscode,WEB,BloombergMedia,whatiscode,105.0,Paul Ford’s “What Is Code?”,102.0,11.0,44.0,58.0,211.0,28.0,2739.0,19.0,0.0,52036.0, What Is Codehttp://wwwbloombergcom/whatiscodeBusinessweek June 11 2015  by Paul Fordhttps://twittercom/ftrain  contributorshttps://makerbase/p/15js4s/whatiscodeReport an issuehttps://githubcom/BloombergMedia/whatiscode/issues or suggest changes by submitting a pull requesthttps://githubcom/BloombergMedia/whatiscode/pulls Issues and pull requests labeled texthttps://githubcom/BloombergMedia/whatiscode/labels/text will be reviewed by an editor though we make no guarantees about timeliness Changes merged into master may take a day or so to push live to production especially on weekends LICENSE---This repository contains a variety of content some is owned by Bloomberg Finance LP and some is from third-parties various Javascript librariesThe third-party content is distributed under the license provided by those partiesThe Javascript content owned by Bloomberg Finance LP is distributed under the Apache 2 license the text of this license can be found in the LICENSEhttps://githubcom/BloombergMedia/whatiscode/blob/master/LICENSE fileThe article text contained in the indexhtmlhttps://githubcom/BloombergMedia/whatiscode/blob/master/indexhtml file is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 40 International license For the full text of the license please see the Creative Commons sitehttps://creativecommonsorg/licenses/by-nc-nd/40/,0.00987784167224,False,False,675.0,2.0,0.0,0.0,,,0.00179731643241,0.460619533495,0.000166186319906,,0.314400613751,0.000144559333069,0.0753700491274,,,,,,0.00035399962665,,,,,,,,,,,,0.000116102771441,0.137134447009,1.93504619069e-05,,,
21,JaceRobinson8/jacerobinson8.github.io,WEB,JaceRobinson8,jacerobinson8.github.io,1.0,Webpage to display the results of data mining project of Twitter for class CS-3250-01 Computational Data Analysis taught by Dr. Doran at Wright State University.,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4611.0, jacerobinson8githubioWebpage to display the results of data mining project of Twitter for class CS-3250-01 Computational Data Analysis taught by Dr Doran at Wright State University Start Bootstraphttp://startbootstrapcom/ - Agencyhttp://startbootstrapcom/template-overviews/agency/Agencyhttp://startbootstrapcom/template-overviews/agency/ is a one page agency portfolio theme for Bootstraphttp://getbootstrapcom/ created by Start Bootstraphttp://startbootstrapcom/ This theme features several content sections a responsive portfolio grid with hover effects full page portfolio item modals a responsive timeline and a working PHP contact form,,True,True,23.0,1.0,0.0,0.0,,,,0.224894037565,,,0.191588538088,,0.583517424347,,,,,,,,,,,,,,,,,,,,,,,
22,rubymonstas-zurich/rubymonstas-zurich.github.io,WEB,rubymonstas-zurich,rubymonstas-zurich.github.io,5.0,The website of Ruby Monstas Zurich,12.0,1.0,0.0,0.0,2.0,6.0,0.0,0.0,0.0,33981.0, rubymonstas-zurichThe website of Ruby Monstas Zurich Add a memberAdd a yml object in data/membersyml example:yml- gender: m  name: Fabian Mettler  twitterusername: maveonair  role: Organizer  Coach Add a sessionAdd a yml object in data/beginnersessionsyml or data/advancedsessionsyml example:yml- number: 13  date: 08082016  description:    - a href/materials/beginners/session13/session13-exercisespdfExercises: Arrays Hashes Method extraction Repetition/a  location: simplificatorNOTE: - make sure to quote  the description in case it contains : otherwise YML will handle it as key/value- possible locations are: simplificator tamedia localsearch Add a holiday or general warningAdd a yml object in data/beginnersessionsyml or data/advancedsessionsyml example:yml- date: 01082016  warning: No session because of holiday Swiss national holiday,,True,True,137.0,2.0,0.0,0.0,,,0.297210176906,,,,0.557811120918,,0.144978702176,,,,,,,,,,,,,,,,,,,,,,,
23,ianli/elbowpatched-boilerplate,WEB,ianli,elbowpatched-boilerplate,1.0,Create an academic personal website on Jekyll and GitHub Pages,2.0,0.0,0.0,0.0,5.0,1.0,10.0,0.0,0.0,1784.0, Elbowpatched Boilerplatehttp://elbowpatchedcomElbowpatched Boilerplate is a template to make it easier to create an academic personal websiteIt is built using Jekyllhttp://jekyllrbcom/ a simple blog-aware static site generatorSince this template is built on Jekyll you can publish your website on GitHub Pageshttps://pagesgithubcom/ for free Source: https://githubcom/ianli/elbowpatched-boilerplatehttps://githubcom/ianli/elbowpatched-boilerplate Homepage: http://elbowpatchedcomhttp://elbowpatchedcom Twitter: elbowpatchedhttp://twittercom/elbowpatched WhyAs a scholar having an academic personal website can be a good way for you to publicize your researchYour website can have descriptions of your research projects a list of your published papers and links to your slides and video presentationsHowever creating an academic personal website takes a lot of timeTime that you also have to spend reading papers conducting studies analyzing data and writing papersElbowpatched Boilerplate is here to helpIt has the following features that make it easier to create an academic personal website Fill out simple files with information about yourself your publications projects and presentations Use the provided templates or create your own to change the presentation of your content Publish your website on GitHub Pages for free Quick start Clone the git repo - git clone https://githubcom/ianli/elbowpatched-boilerplategit Setup and run Jekyllhttp://jekyllrbcom/ Edit the contents of the YAMLhttp://enwikipediaorg/wiki/YAML files in the folder data   personalyml - Your personal information   publicationsyml - Bibliography of your publications   projectsyml - Descriptions of your projects with pictures   presentationsyml - Your presentations with links to slides Preview your website at indexhtml LayoutsElbowpatched Boilerplate currently only has one template that you can use: Albertinehttps://githubcom/ianli/elbowpatched-boilerplate/blob/gh-pages/layouts/albertinehtmlFeel free to modify it to your needsI will add more layouts as this project progressesIf you want to create a new template take a look at Albertinehttps://githubcom/ianli/elbowpatched-boilerplate/blob/gh-pages/layouts/albertinehtml for inspiration The Templates documentationhttp://jekyllrbcom/docs/templates/ on the Jekyll site andLiquid Basicshttp://docsshopifycom/themes/liquid-documentation/basics are good introductions to Liquid the template language of Jekyll Publishing optionsWhen youre ready to publish your website you have two options:1 Publish on GitHub Pages - instructionshttps://pagesgithubcom/2 Publish on your own webserver - instructionshttp://jekyllrbcom/docs/deployment-methods/ LicenseSee LICENSEhttps://githubcom/ianli/elbowpatched-boilerplate/blob/gh-pages/LICENSE,,False,True,16.0,1.0,0.0,0.0,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,
24,whoisjuan/whoisjuan.github.io,WEB,whoisjuan,whoisjuan.github.io,2.0,[whoisjuan] portfolio,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,59344.0,,,True,True,100.0,1.0,0.0,0.0,,,,0.0329494766486,,,0.681521214687,,0.285529308664,,,,,,,,,,,,,,,,,,,,,,,
25,ericfischer/housing-inventory,DATA,ericfischer,housing-inventory,8.0,San Francisco housing construction history and associated data,2.0,0.0,0.0,0.0,16.0,1.0,105.0,0.0,0.0,9465.0,,,False,False,47.0,1.0,0.0,0.0,0.476038801216,,,,,,,,,0.523961198784,,,,,,,,,,,,,,,,,,,,,,
26,GSA/data,DATA,GSA,data,64.0,Assorted data from the General Services Administration.,43.0,3.0,8.0,9.0,55.0,16.0,125.0,0.0,0.0,2277.0, GSA DataA home for miscellaneous data published by the General Services Administrationhttp://gsagov If you use any of this data for something please do let us know by opening an issuehttps://githubcom/gsa/data/issues and telling us about it Datasets gov domainsdotgov-domains/readme GSA Enterprise Architectureenterprise-architecture/,,False,True,54.0,1.0,0.0,0.0,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,
27,OpenExoplanetCatalogue/open_exoplanet_catalogue,DATA,OpenExoplanetCatalogue,open_exoplanet_catalogue,62.0,The Open Exoplanet Catalogue,24.0,75.0,295.0,99.0,116.0,485.0,362.0,1.0,0.0,27637.0,Open Exoplanet CatalogueStatus update--------------As you might have notices the Open Exoplanet Catalogue has been in a a dorment state for a few months recieving only few updates This is mainly due to a lack of contributors In the fall we plan to have about 100 undegraduates in computer science work on the OEC Their main goal will be to implement an automated way to gather data from various sources on the internet We will keep the data fully referenced so that it is easy to find out where the data is coming from We will also allow for manual edits of the accumulated data as it has been in the past All of these things together should make the OEC the most complete and most up-to-date exoplanet catalogue out there In the meantime please keep your pull request coming -- Hanno Rein -- June 2016 About the Open Exoplanet Catalogue--------------Travishttp://imgshieldsio/travis/OpenExoplanetCatalogue/openexoplanetcatalogue/mastersvgstyleflathttps://travis-ciorg/OpenExoplanetCatalogue/openexoplanetcatalogue/MIThttp://imgshieldsio/badge/license-MIT-greensvgstyleflathttp://opensourceorg/licenses/MITarXivhttp://imgshieldsio/badge/arXiv-12117121-orangesvgstyleflathttp://arxivorg/abs/12117121The Open Exoplanet Catalogue is a database of all discovered extra-solar planets New planets are usually added within 24 hours of their announcementThe database is licensed under an MIT license see below which basically says you can do everything with it If you use it for a scientific publication please include a reference to the Open Exoplanet Catalogue on githubhttps://githubcom/OpenExoplanetCatalogue/openexoplanetcatalogue or to this arXiv paperhttp://arxivorg/abs/12117121  The catalogue is a community project Please send corrections and additions via pull request or emailmailto:exoplanethanno-reinde If you have questions or comments about git or the database please do not hesitate to contact of the contributors directlyIf you are looking for a simple comma/tab separated table you might want to check out this repositoryhttps://githubcom/OpenExoplanetCatalogue/oectables/How to access the catalogue using Python --------------It is very easy to access the Open Exoplanet Catalogue using python Here is a short snippethttps://gistgithubcom/hannorein/2a069763cf114f66641c to print out some basic planet data No download no installation and no external libraries are requiredpython python 2ximport xmletreeElementTree as ET urllib gzip iourl  https://githubcom/OpenExoplanetCatalogue/oecgzip/raw/master/systemsxmlgzoec  ETparsegzipGzipFilefileobjioBytesIOurlliburlopenurlread  Output mass and radius of all planets for planet in oecfindall//planet:    print planetfindtextmass planetfindtextradius  Find all circumbinary planets for planet in oecfindall//binary/planet:    print planetfindtextname  Output distance to planetary system in pc if known and number of planets in systemfor system in oecfindall//system:    print systemfindtextdistance lensystemfindall//planetIf you are using python 3 replace the first three lines by pythonimport xmletreeElementTree as ET urllibrequest gzip iourl  https://githubcom/OpenExoplanetCatalogue/oecgzip/raw/master/systemsxmlgzoec  ETparsegzipGzipFilefileobjioBytesIOurllibrequesturlopenurlreadData Structure-------------The following table shows all the possible tags in the Open Exoplanet Catalogue  Tag       Can be child of  Description  Unit  --------  ---------------  -----------  ----  system                   This is the root container for an entire planetary system     planet  system binary star  This is the container for a single planet The planet is a free floating orphan planet if this tag is a child of system   star   system binary  This is the container for a single star A star can be host to one or more planets circum-stellar planets   binary  system binary  A binary consists of either two stars one star and one binary or two binaries In addition a binary can be host to one or more planets circum-binary planets      declination system  Declination  /- dd mm ss    rightascension system  Right ascension  hh mm ss    distance system  Distance from the Sun  parsec    name system binary star planet  Name of this object This tag can be used multiple times if the object has multiple Names     semimajoraxis  binary planet  Semi-major axis of a planet heliocentric coordinates if child of planet Semi-major axis of the binary if child of binary   AU  separation  binary planet  Projected separation of planet from its host or if child of binary the projected separation from one component to the other This tag can occur multiple times with different units It is different from the tag semimajoraxis as it does not imply a specific orbital configuration   AU arcsec  positionangle  binary  Position angle  degree  eccentricity  binary planet  Eccentricity    periastron  binary planet  Longitude of periastron  degree   longitude  binary planet  Mean longitude at a given Epoch same for all planets in one system  degree   meananomaly binary planet  Mean anomaly at a given Epoch same for all planets in one system  degree   ascendingnode  binary planet  Longitude of the ascending node  degree   inclination  binary planet  Inclination of the orbit  degree   impactparameter planet  Impact parameter of transit   epoch  system  Epoch for the orbital elements  BJD  period  binary planet  Orbital period    day   transittime  binary planet  Time of the center of a transit  BJD  periastrontime  binary planet  Time of periastron  BJD  maximumrvtime  binary planet  Time of maximum radial velocity  BJD  mass planet star Mass or m sini for radial velocity planets  Jupiter masses planet Solar masses star   radius planet star Physical radius  Jupiter radii planet Solar radii star   temperature planet star Temperature surface or equilibrium  Kelvin   age planet star Age  Gyr   metallicity star  Stellar metallicity   log relative to solar   spectraltype star planet  Spectral type      magB binary star planet  B magnitude     magV binary star planet  Visual magnitude     magR binary star planet  R magnitude     magI binary star planet  I magnitude     magJ binary star planet  J magnitude     magH binary star planet  H magnitude     magK binary star planet  K magnitude         discoverymethod  planet  Discovery method of the planet For example: timing RV transit imaging      istransiting  planet  Whether the planet is transiting 1 or not 0      description  planet  Short description of the planet      discoveryyear planet  Year of the planets discovery  yyyy   lastupdate planet  Date of the last non-trivial update  yy/mm/dd    spinorbitalignment  planet  Rossiter-McLaughlin Effect  degree Errors-------------Uncertainties can be added to values using the following attributes of the tag We assume that these uncertainties represent the standard error of the measurement 682 confidence level However keep in mind that it is often not possible to collapse an entire posterior distribution to a single numberThe syntax for error bars is: mass errorminus01 errorplus0110/massThe syntax for upper/lower limits is: mass upperlimit10 /Constants-------------There are several constant used in defining the units in the Open Exoplanet Catalogue The following table can be used to convert them into SI units Constant used in catalogue  Definition in SI units  --------  ---------------  Jupiter mass  18991766e27 kg  Solarmass  19891e30 kg  Jupiter radius  69911000 m  Solarradius  696e08 m Plots-------------Mass vs semi-major axishttps://rawgithubcom/OpenExoplanetCatalogue/oecplots/master/plotmassvssemimajoraxisdiscoverysvgpng PlotArchitecturehttps://rawgithubcom/OpenExoplanetCatalogue/oecplots/master/plotarchitecturesvgpng PlotDiscovery yearhttps://rawgithubcom/OpenExoplanetCatalogue/oecplots/master/plotdiscoveryyearsvgpng PlotPeriod ratioshttps://rawgithubcom/OpenExoplanetCatalogue/oecplots/master/plotperiodratiosvgpng PlotTo create custom plots please visit this repositoryhttps://githubcom/OpenExoplanetCatalogue/oecplots for example scriptsDownload ASCII tables--------------A few words of caution: Many planetary systems are part of binary star systems The architecture of these systems is correctly represented in the original XML files of the Open Exoplanet Catalogue In fact it is to my knowledge the only catalogue that can do that However you might prefer to work with a simpler comma or tab separated table instead of the hierarchical XML file format During the conversion process some information is inevitably lost Most importantly the architecture of the star system One cannot easily represent an arbitrary binary/triple/quadruple system in a simple table Additionally if planets have multiple identifiers only the first identifier is outputted Using the original XML file format and git you can use the git blame functionality to find references to scientific publications for every numeric value in the database This functionality is also lost in the conversion processIn a separate repositoryhttps://githubcom/OpenExoplanetCatalogue/oectables/ you will find a comma separatedhttps://githubcom/OpenExoplanetCatalogue/oectables/raw/master/commaseparated/openexoplanetcataloguetxt and a tab separatedhttps://githubcom/OpenExoplanetCatalogue/oectables/blob/master/tabseparated/openexoplanetcataloguetxt ASCII table of the Open Exoplanet Catalogue Documentation--------------This filehttps://rawgithubcom/OpenExoplanetCatalogue/openexoplanetcatalogue/master/oecpaperpdf describes the philosophy and data-format of the catalogue However everything should be rather self-explanatory The actual data is in the systems directory Each XML file corresponds to one planetary system If you are editing the file with vim have a look at the xmledit pluginhttp://wwwvimorg/scripts/scriptphpscriptid301 I found it very helpfulHow to include references to publications--------------It seems that the most elegant place to put references to publications is the commit messageThis allows one to trace back each individual value in the database to the source using git blame Furthermore it does not add any additional clutter to the text files themselvesSo when committing any changes please create one commit per publication and include the reference in the commit message from now onDerived products--------------The following list contains links to other catalogues websites and apps that are derived from or make use of the Open Exoplanet Catalogue  oecwebhttps://githubcom/OpenExoplanetCatalogue/oecweb: A suite of HTML pages acting as a front-end of the Open Exoplanet Catalogue It includes visualizations of orbits planet sizes and habitable zones It also includes a plotting tool to generate correlation diagrams The website is hosted at openexoplanetcataloguecomhttp://openexoplanetcataloguecom  oecplotshttps://githubcom/OpenExoplanetCatalogue/oecplots: Plots and example scripts that make use of the Open Exoplanet Catalogue  oecoutreachhttps://githubcom/hannorein/oecoutreach: A clone of the main repository with images and tags that are mainly used for outreach purposes  oeciphonehttps://githubcom/hannorein/oeciphone: Compressed files references to refereed publications resized images and legacy support for various versions of the mobile version are in the repository  ExoDatahttps://githubcom/ryanvarley/ExoData: A Python module for loading the catalogue into python for use with applications along with many exoplanet related equations and tools  iPhone Exoplanet Apphttp://exoplanetappcom: Popular iOS application with many visualizations of the entire catalogue Version 91 and later will fully support planets in multiple star systemsLicense--------------Copyright C 2012 Hanno ReinPermission is hereby granted free of charge to any person obtaining a copy of this database and associated scripts the Database to deal in the Database without restriction including without limitation the rights to use copy modify merge publish distribute sublicense and/or sell copies of the Database and to permit persons to whom the Database is furnished to do so subject to the following conditions:The above copyright notice and this permission notice shall be included in all copies or substantial portions of the DatabaseA reference to the Database shall be included in all scientific publications that make use of the DatabaseTHE DATABASE IS PROVIDED AS IS WITHOUT WARRANTY OF ANY KIND EXPRESS OR IMPLIED INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM DAMAGES OR OTHER LIABILITY WHETHER IN AN ACTION OF CONTRACT TORT OR OTHERWISE ARISING FROM OUT OF OR IN CONNECTION WITH THE DATABASE OR THE USE OR OTHER DEALINGS IN THE DATABASE,1.0,False,False,3496.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
28,Hipo/university-domains-list,DATA,Hipo,university-domains-list,10.0,University Domains and Names Data List & API,22.0,1.0,5.0,2.0,44.0,31.0,96.0,1.0,0.0,751.0, University Domains and Names Data List  APIDo you need a list of universities and their domain names You found it This package includes a JSON file that contains domains names and countries of most of the universities of the world - You can create a validation script that checks the email domain  - You can automatically generate a users country and university by looking at their emailsYou can use this data source in three ways: - Use the JSON file as your data source and do whatever you like with your favourite programming language - Use free hosted-API - Use the tiny Python app to serve a fast API that you can query data 1 - Using the Data SourceThe whole data source is located in the worlduniversitiesanddomainsjson file It is just a list of dictionaries in the following format:    alphatwocode: TR    country: Turkey    domain: sabanciunivedutr    name: Sabanci University    webpage: http://wwwsabanciunivedutr/NOTE: Some universities use a format like userdepartmentdomain but this list only contains the domain portion For example an email address might be studentcsuscedu and this list will contain uscedu the domain for the University of Southern California Take this into consideration if using this list for email address validation 2 - Using Hosted APIThis is the easiest method if youre making a small project or just want to discover the data without any hassleIt is sponsored by Hipohttp://wwwhipolabscom and free If you have a big project please host it on your own serverSome example searches: - http://universitieshipolabscom - http://universitieshipolabscom/searchnamemiddle - http://universitieshipolabscom/searchnamemiddlecountryturkeyThe hosted API uses university-domains-list-apihttps://githubcom/Hipo/university-domains-list-api package 3 - Using the built-in API on your serverYou can access the python API via university-domains-list-apihttps://githubcom/Hipo/university-domains-list-api ContributionPlease contribute to this list We need your support to keep this list up-to-dateDo not hesitate to fix any wrong data It is extremely easy Just open a PR or create an issue  Contributors - Yiit Gler - Tuna Varg - Patrick Michelberger - Barricadenick - Rasim Demirbay - Ryan White - Bilal Arslan - anwilli5 - Thomas Bauer - Emin Mastizada - Jai - Jimi Ford - Lars Schwegmann - Sedat Karanc - Charles Bedrosian - Harrison Lo - mattdfloyd - Ender Ahmet Yurt Created and maintained by Hipohttp://wwwhipolabscom,,False,False,85.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
29,minimaxir/big-list-of-naughty-strings,DATA,minimaxir,big-list-of-naughty-strings,347.0,The Big List of Naughty Strings is a list of strings which have a high probability of causing issues when used as user-input data.,41.0,17.0,15.0,15.0,486.0,50.0,12014.0,3.0,0.0,235.0, Big List of Naughty StringsThe Big List of Naughty Strings is an evolving list of strings which have a high probability of causing issues when used as user-input data This is intended for use in helping both automated and manual QA testing useful for whenever your QA engineer walks into a barhttp://wwwsempfnet/post/On-Testing1aspx Why Test Naughty StringsEven multi-billion dollar companies with huge amounts of automated testing cant find every bad input For example look at what happens when you try to Tweet a zero-width spacehttps://enwikipediaorg/wiki/Zero-widthspace U200B on Twitter:http://iimgurcom/HyDg2eVgifAlthough this is not a malicious error and typical users arent Tweeting weird unicode an internal server error for unexpected input is never a positive experience for the user and may in fact be a symptom of deeper string-validation issues The Big List of Naughty Strings is intended to help reveal such issues Usageblnstxt consists of newline-delimited strings and comments which are preceded with  The comments divide the strings into sections for easy manual reading and copy/pasting into input forms For those who want to access the strings programmatically a blnsjson file is provided containing an array with all the comments stripped out the scripts folder contains a Python script used to generate the blnsjson ContributionsFeel free to send a pull request to add more strings or additional sections However please do not send pull requests with very-long strings 255 characters as that makes the list much more difficult to viewLikewise please do not send pull requests which compromise manual usability of the file This includes the EICAR test stringhttps://enwikipediaorg/wiki/EICARtestfile which can cause the file to be flagged by antivirus scanners and files which alter the encoding of blnstxt Also do not send a null character U0000 string as it changes the file format on GitHub to binaryhttp://stackoverflowcom/a/19723302 and renders it unreadable in pull requests Finally when adding or removing a string please update all files when you perform a pull request DisclaimerThe Big List of Naughty Strings is intended to be used for software you own and manage Some of the Naughty Strings can indicate security vulnerabilities and as a result using such strings with third-party software may be a crime The maintainer is not responsible for any negative actions that result from the use of the list Maintainer Max Woolf minimaxirhttps://twittercom/minimaxir,0.534436890334,False,False,165.0,1.0,0.0,0.0,0.0582323381614,,,,,,,,,,,,,0.407330771505,,,,,,,,,,,,,,,,,,
30,cdcepi/zika,DATA,cdcepi,zika,36.0,Data repository of publicly available Zika data,17.0,6.0,18.0,2.0,65.0,98.0,104.0,0.0,0.0,524625.0, Zika Data RepositoryThis data repository will be used to share publicly available data related to the ongoing Zika epidemic It is being provided as a resource to the scientific community engaged in the public health response The data provided here is not official and should be considered provisional and non-exhaustive The data in reports may change over time reflecting delays in reporting or changes in classifications And while accurate representation of the reported data is the objective in the machine readable files shared here that accuracy is not guaranteed Before using any of these data it is advisable to review the original reports and sources which are provided whenever possibleIf you find the data useful support data sharing by referencing both the original source and this repository see DOI below UsersOriginal reports and data extracted from those reports are categorized by country For each country there is a README file with basic information about currently available datasets a data guide and a place names database Detailed information on formats can be found in the data dictionarydatadictionarymd If you find a mistake please create an issuehttps://helpgithubcom/articles/creating-an-issue/ or preferrably fix it and submit a pull requesthttps://helpgithubcom/articles/using-pull-requests/ ContributorsPlease see the data dictionarydatadictionarymd for information on standardization We are working on getting more countries online Pull requests will be accepted  How to contributeFollow the how to contributehowtocontributemd guide to contribute to the CDC zika repo from your fork or local git clone  Links to other data sourcesAdditional dataadditionaldatamd Citeable DOIDOIhttps://zenodoorg/badge/23625/cdcepi/zikasvghttps://zenodoorg/badge/latestdoi/23625/cdcepi/zika,,False,False,1165.0,1.0,9.0,9.0,,,,,,,0.974800658744,,,,0.0251993412556,,,,,,,,,,,,,,,,,,,,,
31,umpirsky/country-list,DATA,umpirsky,country-list,158.0,:globe_with_meridians: List of all countries with names and ISO 3166-1 codes in all languages and data formats.,3.0,4.0,38.0,7.0,782.0,9.0,2589.0,3.0,0.0,51430.0,h3 aligncenter    a hrefhttps://githubcom/umpirsky        img srchttps://farm2staticflickrcom/1709/25098526884ae4d50465fodpng /    /a/h3p aligncenter  a hrefhttps://githubcom/umpirsky/Symfony-Upgrade-Fixersymfony upgrade fixer/a bull  a hrefhttps://githubcom/umpirsky/Twig-Gettext-Extractortwig gettext extractor/a bull  a hrefhttps://githubcom/umpirsky/wisdomwisdom/a bull  a hrefhttps://githubcom/umpirsky/centipedecentipede/a bull  a hrefhttps://githubcom/umpirsky/PermissionsHandlerpermissions handler/a bull  a hrefhttps://githubcom/umpirsky/Extraloadextraload/a bull  a hrefhttps://githubcom/umpirsky/Gravatargravatar/a bull  a hrefhttps://githubcom/umpirsky/locurrolocurro/a bull  bcountry list/b bull  a hrefhttps://githubcom/umpirsky/Transliteratortransliterator/a/pCountry ListList of all countries with names and ISO 3166-1 codes in all languages and all data formatsFormats Available------------------ Text- JSON- YAML- XML- HTML- CSV- SQL     MySQL     PostgreSQL     SQLite- PHP- XLIFFMultilingual------------All formats are also available in multiple languages please find full language list herehttps://githubcom/umpirsky/country-list/tree/master/dataBuild-----Country list is available out of the box but if you want to submit patches add new formatsupdate data source or contribute in any other way you will probably want to rebuild the list:bash composer install /bin/buildOther Interesting Lists----------------------- Currency Listhttps://githubcom/umpirsky/currency-list Language Listhttps://githubcom/umpirsky/language-list Locale Listhttps://githubcom/umpirsky/locale-list TLD Listhttps://githubcom/umpirsky/tld-list,,False,False,91.0,5.0,5.0,0.0,,,,,,,0.613159276825,0.386840723175,,,,,,,,,,,,,,,,,,,,,,,,
32,mledoze/countries,DATA,mledoze,countries,123.0,"World countries in JSON, CSV, XML and Yaml. Any help is welcome!",48.0,27.0,72.0,18.0,507.0,76.0,2721.0,7.0,0.0,16497.0,World countries in JSON CSV XML and YAMLDownloadshttps://imgshieldsio/npm/dm/world-countriessvgstyleflathttps://wwwnpmjscom/package/world-countriesLatest Stable Versionhttps://imgshieldsio/npm/v/world-countriessvgstyleflathttps://wwwnpmjscom/package/world-countriesLatest Stable Versionhttps://imgshieldsio/packagist/v/mledoze/countriessvgstyleflathttps://packagistorg/packages/mledoze/countriesLicensehttps://imgshieldsio/packagist/l/mledoze/countriessvgstyleflathttp://opendatacommonsorg/licenses/odbl/10/ Countries dataThis repository contains lists of world countries in JSON CSV and XML Each line contains the country: - name  - common - common name in english  - official - official name in english  - native - list of all native names  - key: three-letter ISO 639-3 language code - value: name object  key: official - official name translation  key: common - common name translation - country code top-level domain tld - code ISO 3166-1 alpha-2 cca2 - code ISO 3166-1 numeric ccn3 - code ISO 3166-1 alpha-3 cca3 - code International Olympic Committee cioc - ISO 4217 currency codes currency - calling codes callingCode - capital city capital - alternative spellings altSpellings - region - subregion - list of official languages languages - key: three-letter ISO 639-3 language code - value: name of the language in english - list of name translations translations - key: three-letter ISO 639-3 language code - value: name object  key: official - official name translation  key: common - common name translation - latitude and longitude latlng - name of residents demonym - landlocked status landlocked - land borders borders - land area in km area Additional dataThe datahttps://githubcom/mledoze/countries/tree/master/data folder contains additional data such as the countriesGeoJSON outlines and flags in SVG formatExamplesJSONjsonname: common: Austriaofficial: Republic of Austrianative: bar: official: Republik sterreichcommon: sterreichtld: atcca2: ATccn3: 040cca3: AUTcioc: AUTcurrency: EURcallingCode: 43capital: ViennaaltSpellings: AT Osterreich Oesterreichregion: Europesubregion: Western Europelanguages: bar: Austro-Bavarian Germantranslations: cym: official: Republic of Austria common: Awstriadeu: official: Republik sterreich common: sterreichfra: official: Rpublique dAutriche common: Autrichehrv: official: Republika Austrija common: Austrijaita: official: Repubblica dAustria common: Austriajpn: official:  common: nld: official: Republiek Oostenrijk common: Oostenrijkpor: official: Repblica da ustria common: ustriarus: official:   common: spa: official: Repblica de Austria common: Austrialatlng: 4733333333 1333333333demonym: Austrianlandlocked: trueborders: CZE DEU HUN ITA LIE SVK SVN CHEarea: 83871GeoJSON outlineSee an example for Germanyhttps://githubcom/mledoze/countries/blob/bb61a1cddfefd09ad5c92ad0a1effbfceba39930/data/deugeojsonCSVcsvnametldcca2ccn3cca3currencycallingCodecapitalaltSpellingsregionsubregionlanguagestranslationslatlngdemonymlandlockedbordersareaArubaArubaArubaArubaArubaArubaawAW533ABWARUAWG297OranjestadAWAmericasCaribbeanDutchPapiamentoArubaArubaArubaArubaArubaArubaArubaArubaArubaArubaArubaArubaArubaAruba125-6996666666Aruban180AfghanistanIslamic Republic of Afghanistan     Owganystan Yslam RespublikasyOwganystanafAF004AFGAFGAFN93KabulAFAfnistnAsiaSouthern AsiaDariPashtoTurkmenIslamic Republic of AfghanistanAffganistanIslamischen Republik AfghanistanAfghanistanRpublique islamique dAfghanistanAfghanistanIslamska Republika AfganistanAfganistanRepubblica islamica dellAfghanistanAfghanistanIslamitische Republiek AfghanistanAfghanistanRepblica Islmica do AfeganistoAfeganisto  Repblica Islmica de AfganistnAfganistn3365Afghan1IRNPAKTKMUZBTJKCHN652230AngolaRepublic of AngolaRepblica de AngolaAngolaaoAO024AGOANGAOA244LuandaAORepblica de Angolapublika de anlaAfricaMiddle AfricaPortugueseRepublic of AngolaAngolaRepublik AngolaAngolaRpublique dAngolaAngolaRepublika AngolaAngolaRepubblica dellAngolaAngolaRepubliek AngolaAngolaRepblica de AngolaAngola Repblica de AngolaAngola-125185AngolanCOGCODZMBNAM1246700XMLxmlxml version10 encodingUTF-8countries  country nameArubaArubaArubaArubaArubaAruba tldaw cca2AW ccn3533 cca3ABW ciocARU currencyAWG callingCode297 capitalOranjestad altSpellingsAW regionAmericas subregionCaribbean languagesDutchPapiamento translationsArubaArubaArubaArubaArubaArubaArubaArubaArubaArubaArubaArubaArubaAruba latlng125-6996666666 demonymAruban landlocked borders area180/  country nameAfghanistanIslamic Republic of Afghanistan     Owganystan Yslam RespublikasyOwganystan tldaf cca2AF ccn3004 cca3AFG ciocAFG currencyAFN callingCode93 capitalKabul altSpellingsAFAfnistn regionAsia subregionSouthern Asia languagesDariPashtoTurkmen translationsIslamic Republic of AfghanistanAffganistanIslamischen Republik AfghanistanAfghanistanRpublique islamique dAfghanistanAfghanistanIslamska Republika AfganistanAfganistanRepubblica islamica dellAfghanistanAfghanistanIslamitische Republiek AfghanistanAfghanistanRepblica Islmica do AfeganistoAfeganisto  Repblica Islmica de AfganistnAfganistn latlng3365 demonymAfghan landlocked1 bordersIRNPAKTKMUZBTJKCHN area652230/  country nameAngolaRepublic of AngolaRepblica de AngolaAngola tldao cca2AO ccn3024 cca3AGO ciocANG currencyAOA callingCode244 capitalLuanda altSpellingsAORepblica de Angolapublika de anla regionAfrica subregionMiddle Africa languagesPortuguese translationsRepublic of AngolaAngolaRepublik AngolaAngolaRpublique dAngolaAngolaRepublika AngolaAngolaRepubblica dellAngolaAngolaRepubliek AngolaAngolaRepblica de AngolaAngola Repblica de AngolaAngola latlng-125185 demonymAngolan landlocked bordersCOGCODZMBNAM area1246700/  countriesYAMLyaml-  name:  common: Aruba official: Aruba native:  nld:  official: Aruba common: Aruba  pap:  official: Aruba common: Aruba    tld: aw cca2: AW ccn3: 533 cca3: ABW cioc: ARU currency: AWG callingCode: 297 capital: Oranjestad altSpellings: AW region: Americas subregion: Caribbean languages:  nld: Dutch pap: Papiamento  translations:  deu:  official: Aruba common: Aruba  fra:  official: Aruba common: Aruba  hrv:  official: Aruba common: Aruba  ita:  official: Aruba common: Aruba  jpn:  official:  common:   nld:  official: Aruba common: Aruba  por:  official: Aruba common: Aruba  rus:  official:  common:   spa:  official: Aruba common: Aruba   latlng: 125 -6996666666 demonym: Aruban landlocked: false borders:    area: 180 -  name:  common: Afghanistan official: Islamic Republic of Afghanistan native:  prs:  official:    common:   pus:  official:     common:   tuk:  official: Owganystan Yslam Respublikasy common: Owganystan    tld: af cca2: AF ccn3: 004 cca3: AFG cioc: AFG currency: AFN callingCode: 93 capital: Kabul altSpellings: AF Afnistn region: Asia subregion: Southern Asia languages:  prs: Dari pus: Pashto tuk: Turkmen  translations:  cym:  official: Islamic Republic of Afghanistan common: Affganistan  deu:  official: Islamischen Republik Afghanistan common: Afghanistan  fra:  official: Rpublique islamique dAfghanistan common: Afghanistan  hrv:  official: Islamska Republika Afganistan common: Afganistan  ita:  official: Repubblica islamica dellAfghanistan common: Afghanistan  jpn:  official:  common:   nld:  official: Islamitische Republiek Afghanistan common: Afghanistan  por:  official: Repblica Islmica do Afeganisto common: Afeganisto  rus:  official:    common:   spa:  official: Repblica Islmica de Afganistn common: Afganistn   latlng: 33 65 demonym: Afghan landlocked: true borders: IRN PAK TKM UZB TJK CHN area: 652230 -  name:  common: Angola official: Republic of Angola native:  por:  official: Repblica de Angola common: Angola    tld: ao cca2: AO ccn3: 024 cca3: AGO cioc: ANG currency: AOA callingCode: 244 capital: Luanda altSpellings: AO Repblica de Angola publika de anla region: Africa subregion: Middle Africa languages:  por: Portuguese  translations:  cym:  official: Republic of Angola common: Angola  deu:  official: Republik Angola common: Angola  fra:  official: Rpublique dAngola common: Angola  hrv:  official: Republika Angola common: Angola  ita:  official: Repubblica dellAngola common: Angola  jpn:  official:  common:   nld:  official: Republiek Angola common: Angola  por:  official: Repblica de Angola common: Angola  rus:  official:   common:   spa:  official: Repblica de Angola common: Angola   latlng: -125 185 demonym: Angolan landlocked: false borders: COG COD ZMB NAM area: 1246700  Customising the outputThe data files provided in the dist directory include all available fields but is also possible to build a custom version of the data with certain fields excludedTo do this you will first need a working PHP installation composerhttps://getcomposerorg and a local copy of this repository Once you have these open a terminal in your local version of this projects root directory and run this command to install the necessary dependencies:shcomposer installAfter this finishes run the following command here we will exclude the tld field from the output but you can exclude any field you want:shphp countriesphp convert --exclude-fieldtldYou can also exclude multiple fields:shphp countriesphp convert --exclude-fieldtld --exclude-fieldcca2 Or using the shorter -x syntax:php countriesphp convert -x tld -x cca2 ShowcaseProjects using this dataset:- REST Countrieshttp://restcountrieseu/- International Telephone Inputhttp://jackocnrcom/intl-tel-inputhtml- Telephone JShttps://githubcom/lukaswhite/telephones-js- Countries of the Worldhttp://countriespetethompsonnet/- Country Prefix Codes For Gohttps://githubcom/relops/prefixes- Ask the NSAhttp://askthensacom/- Country Info Mapper in Gohttps://githubcom/pirsquare/country-mapper- Visa requirements in JSONhttps://githubcom/herrniemand/visas How to contributePlease refer to CONTRIBUTINGhttps://githubcom/mledoze/countries/blob/master/CONTRIBUTINGmd To do - add the type of the country country sovereign state public body territory etc - add missing translations Sourceshttp://wwwcurrency-isoorg/ for currency codesRegion and subregion are taken from https://githubcom/hexorx/countriesGeoJSON outlines come from http://thematicmappingorg/downloads/worldbordersphpThe rest comes from Wikipedia CreditsThanks to: - Glazz for his help with country calling codes - hexorx for his work https://githubcom/hexorx/countries - frederik-jacques for the capital cities - fayer for the population geolocation demonym and area data - ancosen for his help with the borders data - herrjemand for country names and various fixes - all the contributors: https://githubcom/mledoze/countries/graphs/contributors LicenseSee LICENSEhttps://githubcom/mledoze/countries/blob/master/LICENSE,,False,True,437.0,2.0,19.0,19.0,,,,0.00419815281276,,,,0.995801847187,,,,,,,,,,,,,,,,,,,,,,,,
33,cooperhewitt/collection,DATA,cooperhewitt,collection,32.0,"Collection Data for Cooper Hewitt, Smithsonian Design Museum",13.0,0.0,2.0,5.0,31.0,0.0,148.0,1.0,0.0,889742.0,CollectionCooper Hewitt Smithsonian Design Museum is committed to making its collection data available for public access To date we have made public approximately 75 of the documented collectionhttp://collectioncooperhewittorg available online Whilst we have a web interface for searching the collection we are now also making the dataset available for free public download By being able to see everything at once new connections and understandings may be able to be made For more information please see our websitehttp://collectioncooperhewittorg/developersInstructionsPlease follow the instructions on our wikihttps://githubcom/cooperhewitt/collection/wikiUsage GuidelinesAre there any restrictionsIn order to reduce any uncertainty about the legitimate uses of this dataset Cooper Hewitt has licensed this release under a Creative Commons Zero CC0 license This license is the most permissive available and allows for all types of reuse It is explained in full in the accompanying license fileFollowing the lead of Europeana we have also released some guidelines for use which suggest that users: Give attribution to Cooper Hewitt Smithsonian Design Museum Contribute back any modifications or improvements Do not mislead others or misrepresent the Metadata or its sources Be responsible Understand that they use the data at their own riskPlease be aware that images are not included While we have provided a way to reference the images connected to the records these images themselves are not part of the dataset being released and are not covered by the same licensePlease see our wikihttps://githubcom/cooperhewitt/collection/wiki/Date-Usage-Guidelines for detailed usage guidelines Collections items as JSON filesThis departments exhibitions objects people periods roles and types folderscontain Cooper Hewitt collection data exported as individualJSONhttp://wwwjsonorg/ filesFile names and parent directory structures are generated using the unique ID ofthe object itself For example the full path for iRobots Roomba vacuumcleanerhttp://collectioncooperhewittorg/objects/18704235/ ID 18704235is: objects/187/042/35/18704235jsonblob/master/objects/187/042/35/18704235jsonPaths are generated by chopping numeric identifiers in to groups of three orless starting front to back A reference implementation can be found in theutilspyblob/master/bin/utilspy libraryObjects as JSON files in GitHubIt should be noted that the performance of Git and GitHub when dealing withvery large repositories is still less than ideal It appears to be a probleminherent to Git and its indexing processesWhich is to say: Everything still works but it can be slow In practice this hasthe side-effect of making some features of GitHub like pull requests nearlyimpossible because the web application is configured to time out before indexingof a very large repository has completedThere is a good thread about the problem and some potential solutions over here:http://threadgmaneorg/gmanecompversion-controlgit/189776See Anything WrongIf you notice a factual error in the data please let us know using this formhttps://cooperhewittzendeskcom/hc/en-us/requests/new Be sure to include the items ID or accession number in your description of the error As this repository represents a downstream export of our collections database we cannot accept pull requests regarding factual errors Licensing Creative Commons Legal Code CC0 10 Universal    CREATIVE COMMONS CORPORATION IS NOT A LAW FIRM AND DOES NOT PROVIDE    LEGAL SERVICES DISTRIBUTION OF THIS DOCUMENT DOES NOT CREATE AN    ATTORNEY-CLIENT RELATIONSHIP CREATIVE COMMONS PROVIDES THIS    INFORMATION ON AN AS-IS BASIS  CREATIVE COMMONS MAKES NO    WARRANTIES REGARDING THE USE OF THIS DOCUMENT OR THE INFORMATION OR    WORKS PROVIDED HEREUNDER AND DISCLAIMS LIABILITY FOR DAMAGES    RESULTING FROM THE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS    PROVIDED HEREUNDER Statement of PurposeThe laws of most jurisdictions throughout the world automatically conferexclusive Copyright and Related Rights defined below upon the creator andsubsequent owners each and all an owner of an original work of authorshipand/or a database each a WorkCertain owners wish to permanently relinquish those rights to a Work for thepurpose of contributing to a commons of creative cultural and scientific worksCommons that the public can reliably and without fear of later claims ofinfringement build upon modify incorporate in other works reuse andredistribute as freely as possible in any form whatsoever and for any purposesincluding without limitation commercial purposes These owners may contribute tothe Commons to promote the ideal of a free culture and the further production ofcreative cultural and scientific works or to gain reputation or greaterdistribution for their Work in part through the use and efforts of othersFor these and/or other purposes and motivations and without any expectation ofadditional consideration or compensation the person associating CC0 with a Workthe Affirmer to the extent that he or she is an owner of Copyright andRelated Rights in the Work voluntarily elects to apply CC0 to the Work andpublicly distribute the Work under its terms with knowledge of his or herCopyright and Related Rights in the Work and the meaning and intended legaleffect of CC0 on those rights1 Copyright and Related RightsA Work made available under CC0 may be protected by copyright and related orneighboring rights Copyright and Related Rights  Copyright and RelatedRights include but are not limited to the following:   the right to reproduce adapt distribute perform display    communicate and translate a Work   moral rights retained by the original authors and/or performers   publicity and privacy rights pertaining to a persons image or likeness    depicted in a Work   rights protecting against unfair competition in regards to a Work    subject to the limitations in paragraph 4a below   rights protecting the extraction dissemination use and reuse of data    in a Work   database rights such as those arising under Directive 96/9/EC of the    European Parliament and of the Council of 11 March 1996 on the legal    protection of databases and under any national implementation thereof    including any amended or successor version of such directive and   other similar equivalent or corresponding rights throughout the world    based on applicable law or treaty and any national implementations    thereof2 WaiverTo the greatest extent permitted by but not in contravention ofapplicable law Affirmer hereby overtly fully permanently irrevocablyand unconditionally waives abandons and surrenders all of AffirmersCopyright and Related Rights and associated claims and causes of actionwhether now known or unknown including existing as well as future claimsand causes of action in the Work i in all territories worldwide iifor the maximum duration provided by applicable law or treaty includingfuture time extensions iii in any current or future medium and for anynumber of copies and iv for any purpose whatsoever including withoutlimitation commercial advertising or promotional purposes the WaiverAffirmer makes the Waiver for the benefit of each member of the public atlarge and to the detriment of Affirmers heirs and successors fullyintending that such Waiver shall not be subject to revocation rescissioncancellation termination or any other legal or equitable action todisrupt the quiet enjoyment of the Work by the public as contemplated byAffirmers express Statement of Purpose3 Public License FallbackShould any part of the Waiver for any reason be judged legally invalid orineffective under applicable law then the Waiver shall be preserved to themaximum extent permitted taking into account Affirmers express Statementof Purpose In addition to the extent the Waiver is so judged Affirmerhereby grants to each affected person a royalty-free non transferable nonsublicensable non exclusive irrevocable and unconditional license toexercise Affirmers Copyright and Related Rights in the Work i in allterritories worldwide ii for the maximum duration provided by applicablelaw or treaty including future time extensions iii in any current orfuture medium and for any number of copies and iv for any purposewhatsoever including without limitation commercial advertising orpromotional purposes the License The License shall be deemed effectiveas of the date CC0 was applied by Affirmer to the Work Should any part ofthe License for any reason be judged legally invalid or ineffective underapplicable law such partial invalidity or ineffectiveness shall notinvalidate the remainder of the License and in such case Affirmer herebyaffirms that he or she will not i exercise any of his or her remainingCopyright and Related Rights in the Work or ii assert any associatedclaims and causes of action with respect to the Work in either casecontrary to Affirmers express Statement of Purpose4 Limitations and Disclaimers  No trademark or patent rights held by Affirmer are waived abandoned    surrendered licensed or otherwise affected by this document  Affirmer offers the Work as-is and makes no representations or    warranties of any kind concerning the Work express implied statutory    or otherwise including without limitation warranties of title    merchantability fitness for a particular purpose non infringement or    the absence of latent or other defects accuracy or the present or    absence of errors whether or not discoverable all to the greatest    extent permissible under applicable law  Affirmer disclaims responsibility for clearing rights of other persons    that may apply to the Work or any use thereof including without    limitation any persons Copyright and Related Rights in the Work    Further Affirmer disclaims responsibility for obtaining any necessary    consents permissions or other rights required for any use of the Work  Affirmer understands and acknowledges that Creative Commons is not a    party to this document and has no duty or obligation with respect to    this CC0 or use of the Work,,False,True,53.0,2.0,4.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
34,artsmia/collection,DATA,artsmia,collection,7.0,Mia collection metadata,8.0,0.0,1.0,3.0,4.0,2.0,35.0,1.0,0.0,236021.0,A collection of metadata associated with the collection of the Minneapolis Institute of Arthttp://artsmiaorg/Mias missionhttp://newartsmiaorg/about/museum-info/mission-and-history/ is to enrich the community by collecting preserving and making accessible outstanding works of art from the worlds diverse culturesTo increase access to Mias outstanding art weve published metadata for our artworks as JSON under a CC0cc0-by license WhyThis is the same data that we publish on our collectionswebsitehttps://collectionsartsmiaorg Having everything on its ownpage is a great way to browse but taken as a whole its much easier tosee the overall shape of the data For example if someone wantsto know how many artists have work at Miabash find objects -name json  xargs cat  jq -r artist  sort  uniq -ci  sort -nris a simple program that knowshttps://gistgithubcom/kjell/34439abc72d99d81f1e2 How many of those artists have the same name as you Save the output of the above command to a file called artsmia-artiststxt then cat artsmia-artiststxt  grep -i your name here  wc -l will tellOr maybe you want to use markovchainshttps://enwikipediaorg/wiki/Markovchain to make fakedescriptions of objects in official museum-speakbash find objects -name json  xargs cat  jq -r description title text  grep -v   descriptionstxt dadadodo -c 1 descriptionstxtBlack lines of concentric diamonds beard architectural African symbolsin the foot body and black plum blossom petalsFor these two examples youll need jqhttp://stedolangithubio/jq/and dadadodohttp://wwwjwzorg/dadadodo/ along with a sane commandline environmentHaving this raw data in an accessible format opens the doors toexperimentation that isnt possible with our collections website alone Use ObjectsMia identifies objects curatorially by accession number Computertorially we use numeric object ids beacuse theyre easier to deal withEach record lives at objects/bucket/idjson where bucket is object id / 1000 So 0/ holds records 0 through 999 1/ holds 1000-1999 etc Heres what objects/0/17json looks like:json  accessionnumber: 1359  artist: Walter Shirlaw  continent: North America  country: United States  creditline: Gift of Mrs Florence M Shirlaw  culture: null  dated: 19th century  description:   dimension: 3 1/4 x 7 1/2 in 826 x 1905 cm  id: http://apiartsmiaorg/objects/17  image: valid  imagecopyright:   imageheight: 2263  imagewidth: 3593  lifedate: American 1838 - 1909  marks: Signature Cheyenne W Shirlaw  medium: Graphite  nationality: American  provenance:   restricted: 0  role: Artist  room: Not on View  style: 19th century  text:   title: Sketch made on Indian Reservation Montanaobjects/0/17json: https://githubcom/artsmia/collection/blob/master/objects/0/17json ImagesImages arent included under the same license as this metadata Reference images are available under Mias Image Access  Usehttp://newartsmiaorg/visit/policies-guidelines/imageaccessanduse policyThere arent images of every object in the collection Of the objectsthat have been photographed some are restricted by copyright image: validinvalid: is there an image available for this object restricted: 01: is it usable 0 says that an image is not subject to any additional terms or restrictions such as copyright or a special request from the artist to limit display of an object 1 means the oppositeFeel free to use unrestricted images for limited non-commercial and educational purposes When the copyright owner of an artwork is known it will be in imagecopyright:  Commercial licensing is handled through Bridgeman Imageshttp://wwwbridgemanimagescom/en-GB/collections/collection/minneapolis-institute-of-arts/Image thumbnails are accessible by their object id in three sizes: http://apiartsmiaorg/images/id/smallmediumlargejpg Small images are 100px on the long side medium images 600px and large images 800px ExhibitionsAre organized in buckets just like objectsjson  exhibitionid: 734  exhibitiondepartment: Decorative Arts Textiles  Sculpture  exhibitiontitle: Warren MacKenzie: The Legacy of an American Potter  begin: 2007  end: 2007  displaydate: Saturday May 19 2007 - Sunday August 26 2007  objects:     62773    62774    62775    62776    62777    62778    62779    62789    62790  exhibitions/0/734json/exhibitions/0/734json CC0 BYThe Creative Commons Zero CC0 Public Domain Dedication allows this data to be reused free of restrictions BY suggests implied or ethical attributionCC0: http://creativecommonsorg/publicdomain/zero/10/BY: http://dpla/info/2013/12/04/cc0-by/Please use this data When you do Attribute Mia and mention artsmia/collectionhttps://githubcom/artsmia/collection Pull requesthttps://helpgithubcom/articles/creating-a-pull-request your changes or issuehttps://githubcom/artsmia/collection/issues ideas and discussion Obey the terms of this license and our image policy Enjoy ContributingWere happy to hear your thoughts on our data: what you think of it how youre using it and if theres anything youd like to see changed The best way to communicate in regards to this data is by using github issueshttps://githubcom/artsmia/collection/issues and pull requestshttps://githubcom/artsmia/collection/pullsHowever this repo is largely generated/Makefile from our upstream collection management software TMS Making enhancements to the generated json files is a fantastic way to point out better ways we can represent data or alert us to possible improvements Such pull requests wont be merged directly but instead factored into future improvements to our data pipelineTMS: http://jfkutechwikispacescom/TheMuseumSystemTMS UpdatesHundreds of records can change on any given day Updates are committed to this dataset approximately once per dayhttps://githubcom/artsmia/collection/commits See also Whats on view at Mia dot csvhttps://githubcom/miabot/galleriescsv Europeanahttp://wwweuropeanaeu/ Cooper-Hewitthttp://labscooperhewittorg/2012/releasing-collection-github/ cooperhewitt/collectionhttps://githubcom/cooperhewitt/collection/ DPLAhttp://dpla/info/2013/12/04/cc0-by/ Tatehttp://wwwtateorguk/context-comment/blogs/archives-access-project-open-data-brings-beauty-and-insight tategallery/collectionhttps://githubcom/tategallery/collection Museum APIshttp://museum-apipbworkscom/w/page/21933420/MuseumC2A0APIs and  open datahttp://wwwmuseum-idcom/idea-detailaspid387,,False,False,745.0,2.0,0.0,0.0,0.161247803163,0.838752196837,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
35,tategallery/collection,DATA,tategallery,collection,53.0,Tate Collection metadata,10.0,2.0,11.0,12.0,73.0,9.0,308.0,0.0,0.0,221119.0,The Tate CollectionHere we present the metadata for around 70000 artworks that Tatehttp://wwwtateorguk/ owns or jointly owns with the National Galleries of Scotlandhttp://wwwnationalgalleriesorg as part of ARTIST ROOMShttp://wwwtateorguk/artist-rooms Metadata for around 3500 associated artists is also includedThe metadata here is released under the Creative Commons Public Domain CC0http://creativecommonsorg/publicdomain/zero/10/ licence Please see the enclosed LICENCE file for more detailImages are not included and are not part of the dataset Use of Tate images is covered on theCopyright and permissionshttp://wwwtateorguk/about/who-we-are/policies-and-procedures/website-terms-use/copyright-and-permissions page You may also license imageshttp://tate-imagescom for commercial usePlease review the full usage guidelinesusage ExamplesHere are some examples of Tate data usage in the wild Please submit a pull request with your creation added to this list Tate Explorerhttp://shardcoreorg/tatedata/ by Shardcorehttp://wwwshardcoreorg Adding RDFa to Tate artwork pageshttp://commonsmachineryse/2013/11/tate-metadata-mashup/ by Peter Liljenberg at Commons Machineryhttp://commonsmachineryse/ Data visualisationshttp://researchkraeutlicom/indexphp/2013/11/the-tate-collection-on-github/ by Florian Krutlihttp://wwwkraeutlicom/ machine imagined arthttp://wwwshardcoreorg/cgi-bin/getArtworkplida9619f26b1ab2647901d36102d by Shardcorehttp://wwwshardcoreorg autoserotahttp://wwwshardcoreorg/autoserota/ by Shardcorehttp://wwwshardcoreorg The Dimensions of Arthttp://wwwifweassumecom/2013/11/the-dimensions-of-arthtml by Jim Davenporthttp://wwwifweassumecom Art as Data as Arthttp://blogironholdsorg/art-as-data-as-art/ and Part IIhttp://blogironholdsorg/art-as-data-as-art-part-ii/ by Oliver Keyeshttps://twittercom/quominus Tate Acquisition Datahttp://zenlancom/tate/rickshawhtml by Zenlanhttp://twittercom/zenlan Artist Roomshttp://goodlemonscom/artist-rooms/ by Jue Yanghttp://twittercom/jueyang As Statedhttp://noematanet/as/stated/ by noemata/Bjrn Magnhildenhttp://noematanet Cultural Heritage Website with Neo4jhttp://larkinio/indexphp/category/tate/ by Larkin Cunningham As Mutatedhttp://noematanet/as/mutated/ by noemata/Bjrn Magnhildenhttp://noematanet Tateletshttp://marcinignaccom/projects/tatelets/ by Marcin Ignac/Variablehttp://variableio/ Bettina Nissen and Kirill KulikovWe are also inviting you to create GitHub Issueshttps://githubcom/tategallery/collection/issues if you notice any bugs or have any ideas for improving the data Thanks for your help Repository ContentsWe offer two data formats:1 A richer dataset is provided in the JSON format which is organised by the directory structure of the Git repository JSON supports more hierarchical or nested information such as subjects2 We also provide CSVs of flattened data which is less comprehensive but perhaps easier to grok The CSVs provide a good introduction to overall contents of the Tate metadata and create opportunities for artistic pivot tables JSON ArtistsEach artist has his or her own JSON file They are found in the artists folder then filed away by first letter of the artists surname ArtworksArtworks are found in the artworks folder They are filed away by accession number This is the unique identifier given to artworks when they come into the Tate collection In many cases the format has significance For example the ar accession number prefix indicates that the artwork is part of ARTIST ROOMS collection The n prefix indicates works that once were part of the National Galleryhttp://wwwnationalgalleryorguk/ collection CSVThere is one CSV file for artists artistdatacsv and one very large for artworks artworkdatacsv which we may one day break up into more manageable chunks The CSV headings should be helpful Let us know if not Entrepreneurial hackers could use the CSVs as an index to the JSON collections if they wanted richer data NB CSV files are encoded as UTF-8 text on which older versions of Excel may choke We have inserted a UTF-8 BOM to help Excel detect the encoding which may or may not be a terrible mistake a nameusage/aUsage guidelines for open data  These usage guidelines are based on goodwill They are not a legal contract but Tate requests that you follow these guidelines if you use Metadata from our Collection datasetThe Metadata published by Tate is available free of restrictions under the Creative Commons Zero Public Domain Dedicationhttp://creativecommonsorg/publicdomain/zero/10/This means that you can use it for any purpose without having to give attribution However Tate requests that you actively acknowledge and give attribution to Tate wherever possible Attribution supports future efforts to release other data  It also reduces the amount of orphaned data helping retain links to authoritative sources Give attribution to TateMake sure that others are aware of the rights status of Tate and are aware of these guidelines by keeping intact links to the Creative Commons Zero Public Domain DedicationIf for technical or other reasons you cannot include all the links to all sources of the Metadata and rights information directly with the Metadata you should consider including them separately for example in a separate document that is distributed with the Metadata or datasetIf for technical or other reasons you cannot include all the links to all sources of the Metadata and rights information you may consider linking only to the Metadata source on Tates website where all available sources and rights information can be found including in machine readable formats Metadata is dynamicWhen working with Metadata obtained from Tate please be aware that this Metadata is not static It sometimes changes daily Tate continuously updates its Metadata in order to correct mistakes and include new and additional information Museum collections are under constant study and research and new information is frequently added to objects in the collection Mention your modifications of the Metadata and contribute your modified Metadata backWhenever you transform translate or otherwise modify the Metadata make it clear that the resulting Metadata has been modified by you If you enrich or otherwise modify Metadata consider publishing the derived Metadata without reuse restrictions preferably via the Creative Commons Zero Public Domain Dedication Be responsibleEnsure that you do not use the Metadata in a way that suggests any official status or that Tate endorses you or your use of the Metadata unless you have prior permission to do so Ensure that you do not mislead others or misrepresent the Metadata or its sourcesEnsure that your use of the Metadata does not breach any national legislation based thereon notably concerning but not limited to data protection defamation or copyrightPlease note that you use the Metadata at your own riskTate offers the Metadata as-is and makes no representations or warranties of any kind concerning any Metadata published by TateThe writers of these guidelines are deeply indebted to the Smithsonian Cooper-Hewitt National Design Museumhttp://wwwcooperhewittorg/ and Europeanahttp://wwweuropeanaeu/,0.732803720209,False,False,106.0,1.0,3.0,0.0,0.267196279791,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36,ParallelMazen/SaudiNewsNet,DATA,ParallelMazen,SaudiNewsNet,5.0,"This repo contains a set of Arabic newspaper articles alongwith metadata, extracted from various Saudi newspapers.",1.0,0.0,0.0,0.0,4.0,0.0,23.0,0.0,0.0,59346.0, Saudi Newspapers Corpus SaudiNewsNetThis repo contains a set of 31030 Arabic newspaper articles alongwith metadata extracted from various online Saudi newspapersFile Structure--------------The folder dataset contains a set of ZIP files where each file has the format YYYY-MM-DDzip and contains one JSON file with a corresponding name YYYY-MM-DDjson The JSON files are stored in UTF-8 encodingEach JSON file contains an array of articles the format of each article is explained in the next section and its file name reflects the date on which the contained articles were extractedArticle JSON Object Format--------------------------The JSON object for each article contains the following fields some fileds can have empty values in case the crawler failed to extract them: - source: A string identifief of the newspaper from which the article was extracted It can have one of the following values:     String Identifier   Newspaper      ------------------  ---------      aawsat  Al-Sharq Al-Awsathttp://aawsatcom/      aleqtisadiya  Al-Eqtisadiyahttp://aleqtcom/      aljazirah  Al-Jazirahhttp://al-jazirahcom/      almadina  Al-Madinahttp://wwwal-madinacom/      alriyadh  Al-Riyadhhttp://wwwalriyadhcom/      alwatan  Al-Watanhttp://alwatancomsa/      alweeam  Al-Weeamhttp://alweeamcomsa/      alyaum  Al-Yaumhttp://alyaumcom/       arreyadi  Arreyadihttp://wwwarreyadicomsa/      arreyadiyah  Arreyadihttp://wwwarreyadiyahcom/      okaz  Okazhttp://wwwokazcomsa/      sabq  Sabqhttp://sabqorg/      was  Saudi Press Agencyhttp://wwwspagovsa/      3alyoum  Ain Alyoumhttp://3alyoumcom/  - url: The full URL from which the article was extracted - dateextracted: The timestamp of the date on which the article was extracted It has the format YYYY-MM-DD hh:mm:ss Notice that this field does not necessarily represent the date on which the article was authored or made available online however for articles stamped with a date of extraction after August 1 2015 this field most probably represents the date of authoring - title: The title of the article Can be empty - author: The author of the article Can be empty - content: The content of the articleStatistics----------The dataset currently contains 31030 Arabic articles with a total number of 8758976 words The articles were extracted from the following Saudi newspapers sorted by number of articles: - Al-Riyadhhttp://wwwalriyadhcom/ 4852 articles - Al-Jazirahhttp://al-jazirahcom/ 3690 articles - Al-Yaumhttp://alyaumcom/ 3065 articles - Al-Eqtisadiyahttp://aleqtcom/ 2964 articles - Al-Sharq Al-Awsathttp://aawsatcom/ 2947 articles - Okazhttp://wwwokazcomsa/ 2846 articles - Al-Watanhttp://alwatancomsa/ 2279 articles - Al-Madinahttp://wwwal-madinacom/ 2252 articles - Al-Weeamhttp://alweeamcomsa/ 2090 articles - Ain Alyoumhttp://3alyoumcom/ 2080 articles - Sabqhttp://sabqorg/ 1411 articles - Saudi Press Agencyhttp://wwwspagovsa 369 articles - Arreyadihttp://wwwarreyadicomsa/ 133 articles - Arreyadiyahhttp://wwwarreyadiyahcom/ 52 articlesCiting this Work------------------If youd like to cite this work you may use one of the following You may also contact me mazen dot abdulaziz at gmail dot com so that I can include your research in the referring work section - APA: Alhagri M A 2015 Saudi Newspapers Arabic Corpus SaudiNewsNet http://githubcom/ParallelMazen/SaudiNewsNet - MLA: Alhagri Mazen A Saudi Newspapers Arabic Corpus SaudiNewsNet 2015 http://githubcom/ParallelMazen/SaudiNewsNet - BibTex:   mischagrima2015  author  M Alhagri  title  Saudi Newspapers Arabic Corpus SaudiNewsNet  year  2015  url  http://githubcom/ParallelMazen/SaudiNewsNet  Contacting the Maintainer-------------------------If youd like to cite this work have comments or thoughts to share or just feel like chatting then feel free to contact me on either: - My Twitter account UniqueLockhttps://twittercom/uniquelock - mazen dot abulaziz at gmail dot comChangelog--------- - Aug 06 2015:    - First batch of articles uploaded extracted within the period 21/07/2015 to 06/08/2015 - Aug 07 2015:   - Changed output format   - Included a second batch extracted in 07/08/2015 - Aug 11 2015:   - Tracking 2 more newspapers: Saudi Press Agency and Arriyadiyah   - Third batch of articles updloaded timespan: 08/08/2015 to 11/08/2015 LicenseCreative Commons Attribution-NonCommercial-ShareAlike 40 International Licensehttps://icreativecommonsorg/l/by-nc-sa/40/88x31pngThis work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 40 International License The dataset is shared for the sole purpose of aiding open scientific research in Arabic computing or linguistics and can only be used for that purpose The ownership of each article within the dataset belongs to the respective newspaper from which it was extracted and the maintainer of the repository does not claim ownership of any of the content within it If you think by any means that this dataset breaches any established copyrights please contact the repository maintainer,,False,False,20.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
37,quankiquanki/skytrax-reviews-dataset,DATA,quankiquanki,skytrax-reviews-dataset,1.0,An air travel dataset consisting of user reviews from Skytrax (www.airlinequality.com),1.0,0.0,0.0,0.0,9.0,0.0,12.0,0.0,0.0,16110.0, Skytrax User Reviews Dataset August 2nd 2015A scraped dataset created from all user reviews found on Skytrax wwwairlinequalitycom It is unknown under which license Skytrax published these reviews However the reviews are accessible by anyone with a browser and the robotstxt on their website did not specifically prohibit the scraping of themArticles showcasing this dataset:  - http://wwwquangncom/exploring-reviews-of-airline-services/  - http://priceonomicscom/what-are-the-worst-airports-in-the-world/ Dataset FormatThe reviews are divided into 4 csv files Each file contains reviews of one categoryIn total there are:  - 41396 Airline Reviews  - 17721 Airport Reviews  - 1258 Seat Reviews  - 2264 Lounge ReviewsAirline DatasetTotal Samples: 41396Number of Values per Column:- object airlinename: 41396- object link: 41396- object title: 41396- object author: 41396- object authorcountry: 39805- object date: 41396- object content: 41396- object aircraft: 1278- object typetraveller: 2378- object cabinflown: 38520- object route: 2341- float64 overallrating: 36861- float64 seatcomfortrating: 33706- float64 cabinstaffrating: 33708- float64 foodbeveragesrating: 33264- float64 inflightentertainmentrating: 31114- float64 groundservicerating: 2203- float64 wificonnectivityrating: 565- float64 valuemoneyrating: 39723- int64 recommended: 41396Airport DatasetTotal Samples: 17721Number of Values per Column:- object airportname: 17721- object link: 17721- object title: 17721- object author: 17721- object authorcountry: 12777- object date: 17721- object content: 17721- object experienceairport: 647- object datevisit: 593- object typetraveller: 646- float64 overallrating: 13796- float64 queuingrating: 12813- float64 terminalcleanlinessrating: 12815- float64 terminalseatingrating: 587- float64 terminalsignsrating: 27- float64 foodbeveragesrating: 630- float64 airportshoppingrating: 12676- float64 wificonnectivityrating: 412- float64 airportstaffrating: 26- int64 recommended: 17721Lounge DatasetTotal Samples: 2264Number of Values per Column:- object airlinename: 2264- object link: 2264- object title: 2264- object author: 2264- object authorcountry: 1783- object date: 2264- object content: 2264- object loungename: 2261- object airport: 2170- object loungetype: 1964- object datevisit: 99- object typetraveller: 119- float64 overallrating: 2259- int64 comfortrating: 2264- int64 cleanlinessrating: 2264- float64 barbeveragesrating: 2259- float64 cateringrating: 2261- float64 washroomsrating: 2238- float64 wificonnectivityrating: 2253- float64 staffservicerating: 2255- int64 recommended: 2264Seat DatasetTotal Samples: 1258Number of Values per Column:- object airlinename: 1258- object link: 1258- object title: 1258- object author: 1258- object authorcountry: 1250- object date: 1258- object content: 1258- object aircraft: 1258- object seatlayout: 1252- object dateflown: 113- object cabinflown: 1252- object typetraveller: 118- float64 overallrating: 1257- int64 seatlegroomrating: 1258- int64 seatreclinerating: 1258- int64 seatwidthrating: 1258- int64 aislespacerating: 1258- float64 viewingtvrating: 1229- float64 powersupplyrating: 62- float64 seatstoragerating: 113- int64 recommended: 1258,1.0,False,False,9.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
38,emorisse/FBI-Hate-Crime-Statistics,DATA,emorisse,FBI-Hate-Crime-Statistics,1.0,,1.0,0.0,0.0,0.0,7.0,0.0,0.0,0.0,0.0,268.0,,,False,False,2.0,1.0,0.0,0.0,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,
39,fivethirtyeight/uber-tlc-foil-response,DATA,fivethirtyeight,uber-tlc-foil-response,46.0,Uber trip data from a freedom of information request to NYC's Taxi & Limousine Commission,30.0,0.0,0.0,1.0,140.0,0.0,368.0,0.0,0.0,138207.0, Uber TLC FOIL ResponseThis directory contains data on over 45 million Uber pickups in New York City from April to September 2014 and 143 million more Uber pickups from January to June 2015 Trip-level data on 10 other for-hire vehicle FHV companies as well as aggregated data for 329 FHV companies is also included All the files are as they were received on August 3 Sept 15 and Sept 22 2015 FiveThirtyEight obtained the data from the NYC Taxi  Limousine Commission TLChttp://wwwnycgov/html/tlc/html/home/homeshtml by submitting a Freedom of Information Law request on July 20 2015 The TLC has sent us the data in batches as it continues to review trip data Uber and other HFV companies have submitted to it The TLCs correspondence with FiveThirtyEight is included in the files TLCletterpdf TLCletter2pdf and TLCletter3pdf TLC records requests can be made herehttp://wwwnycgov/html/tlc/html/passenger/recordsshtmlThis data was used for four FiveThirtyEight stories: Uber Is Serving New Yorks Outer Boroughs More Than Taxis Arehttp://fivethirtyeightcom/features/uber-is-serving-new-yorks-outer-boroughs-more-than-taxis-are/ Public Transit Should Be Ubers New Best Friendhttp://fivethirtyeightcom/features/public-transit-should-be-ubers-new-best-friend/ Uber Is Taking Millions Of Manhattan Rides Away From Taxishttp://fivethirtyeightcom/features/uber-is-taking-millions-of-manhattan-rides-away-from-taxis/ and Is Uber Making NYC Rush-Hour Traffic Worsehttp://fivethirtyeightcom/features/is-uber-making-nyc-rush-hour-traffic-worse/In the folder uber-trip-data there are six files of raw data on Uber pickups in New York City from April to September 2014 The files are separated by month and each has the following columns:Header  Definition------------Date/Time  The date and time of the Uber pickupLat  The latitude of the Uber pickupLon  The longitude of the Uber pickupBase  The TLC base companyhttp://wwwnycgov/html/tlc/html/industry/baseandbusinessshtml code affiliated with the Uber pickupAlso in the folder is the file uber-raw-data-janjune-15csvzip The unzipped file has the following columns:Header  Definition------------Dispatchingbasenum  The TLC base companyhttp://wwwnycgov/html/tlc/html/industry/baseandbusinessshtml code of the base that dispatched the UberPickupdate  The date and time of the Uber pickupAffiliatedbasenum  The TLC base companyhttp://wwwnycgov/html/tlc/html/industry/baseandbusinessshtml code affiliated with the Uber pickuplocationID  The pickup location ID affiliated with the Uber pickupThe Base codes are for the following Uber bases:Base Code  Base Name------------B02512  UnterB02598  HinterB02617  WeiterB02682  SchmeckenB02764  Danach-NYB02765  GrunB02835  DreistB02836  DrinnenThe file taxi-zone-lookupcsv shows the taxi Zone and Borough for each locationIDIn the folder other-FHV-data there are 10 files of raw data on pickups from 10 for-hire vehicle FHV companies The trip information varies by company but can include day of trip time of trip pickup location drivers for-hire license number and vehicles for-hire license numberThere is also a file other-FHV-data-jan-aug-2015csv containing daily pickup data for 329 FHV companies from January 2015 through August 2015The file AggregateFHVDataxlsx which contains aggregate analysis on taxi and FHV trips came directly from the TLCThe file Uber-Jan-Feb-FOILcsv contains aggregated daily Uber trip statistics in January and February 2015,,False,False,9.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
40,datasets/country-list,DATA,datasets,country-list,17.0,List of all countries in the world with their ISO 2 digit codes (ISO 3166-2) as CSV and JSON,25.0,0.0,2.0,2.0,24.0,2.0,60.0,1.0,0.0,146.0,ISO 3166-1-alpha-2 English country names and code elements This list statesthe country names official short names in English in alphabetical order asgiven in ISO 3166-1 and the corresponding ISO 3166-1-alpha-2 code elementsISO 3166-1: http://wwwisoorg/iso/home/standards/countrycodeshtmThis list is updated whenever a change to the official code list in ISO 3166-1is effected by the ISO 3166/MAIt lists 250 official short names and code elements as of Dec 2012 LicenseThis material is licensed by its maintainers under the Public Domain Dedicationand LicenseNevertheless it should be noted that this material is ultimately sourced fromISO and their rights and licensing policy is somewhat unclear As this is ashort simple database of facts there is a strong argument that no rights cansubsist in this collection However ISO state on theirsitehttp://wwwisoorg/iso/home/standards/countrycodeshtm:  ISO makes the list of alpha-2 country codes available for internal use and non-commercial purposes free of charge This carries the implication though not spelled out that other uses are notpermitted and that therefore there may be rights preventing further generaluse and reuse,,False,False,16.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
41,datasets/airport-codes,DATA,datasets,airport-codes,14.0,"List of Airport codes, locations and other information around the world",24.0,0.0,0.0,3.0,9.0,1.0,19.0,1.0,0.0,5295.0,The airport codes may refer to either IATAhttp://enwikipediaorg/wiki/InternationalAirTransportAssociationairportcodeairport code a three-letter code which is used in passenger reservation ticketing and baggage-handling systems or the ICAOhttp://enwikipediaorg/wiki/InternationalCivilAviationOrganizationairportcode airport code which is a four letter code used by ATC systems and for airports that do not have an IATA airport code from wikipediaAirport codes from around the world Downloaded from public domain source http://ourairportscom/data/ who compiled this data from multiple different sources This data is updated nightlyDataThere is one csv file airport-codes which contains the list of all airport codes the attributes are identified in datapackage description Some of the columns contain attributes identifying airport locations other codes IATA local if exist that are relevant to identification of an airportPreparationDownload and clean the csv file as is from the url http://ourairportscom/data/TODO: Add relationship to UNLOCODEs LicenseThe source specifies that the data can be used as is without any warranty Given size and factual nature of the data and its source from a US company would imagine this was public domain and as such have licensed the Data Package under the Public Domain Dedication and License PDDL,,False,False,23.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
42,datasets/bond-yields-gov-long-term,DATA,datasets,bond-yields-gov-long-term,6.0,Long term government bond yields,23.0,0.0,0.0,0.0,0.0,0.0,3.0,0.0,0.0,108.0,Long term government bond yields Data European UnionECB - Long-term interest rate statistics for EU Member States note this data is also the source for that provided by Eurostateurostat As stated on Eurostat site: Long term government bond yields are calculated as monthly averages non seasonally adjusted data They refer to central government bond yields on the secondary market gross of tax with a residual maturity of around 10 years The bond or the bonds of the basket have to be replaced regularly to avoid any maturity drift This definition is used in the convergence criteria of the Economic and Monetary Union for long-term interest rates as required under Article 121 of the Treaty of Amsterdam and the Protocol on the convergence criteria Data are presented in raw form Source: European Central Bank ECBecb: http://wwwecbint/stats/money/long/html/indexenhtmleurostat: http://eppeurostateceuropaeu/tgm/tabledotabtableplugin1languageenpcodeteimf050 USRelease H15 from the Federal Reserve - Selected Interest Rates Dailyfed specifically the 10 year US Treasury monthly csvfed-csvfed: http://wwwfederalreservegov/releases/h15/datahtmfed-csv: http://wwwfederalreservegov/datadownload/OutputaspxrelH15series0809abf197c17f1ff0b2180fe7015cc3lastObsfromtofiletypecsvlabelincludelayoutseriescolumn JapanJapan 10-year Government Benchmark bond yield - Yield average of observations through period - from ECBecb-jp-10ecb-jp-10: http://sdwecbeuropaeu/quickviewdoSERIESKEY143FMMJPJPYRTBBJP10YTRRYLDA LicenseLicensed under the Public Domain Dedication and Licensepddl assuming either no rights or public domain license in source datapddl: http://opendatacommonsorg/licenses/pddl/10/,,False,False,1.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
43,datasets/bond-yields-uk-10y,DATA,datasets,bond-yields-uk-10y,5.0,Long-term (10 year) UK Government Bond Yields,23.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,149.0,10 year nominal yields on UK government bonds from the bank of England The 10year government bond yield is considered a standard indicator of long-terminterest rates This is a direct extract from the Bank of England IUAAMNPYseries: Annual average yield from British Government Securities 10 yearNominal Par Yieldboeboe: http://wwwbankofenglandcouk/boeapps/iadb/indexaspTravelNIxIRxlevels1XNotesYCDUSG0Xtopx51G0Xtopy7XNotes2YNodesX41514X41515X41516X41517X55047X76909X4051X4052X4128X33880X4053X4058SectionRequiredIHideNums-1ExtraInfotrueBM DataData from Bank of England series IUAAMNPY Annual average yield from BritishGovernment Securities 10 year Nominal Par Yield with some minor processingsee scriptsFull information about the BoE Yields data may be found on the BoE website at:http://wwwbankofenglandcouk/statistics/Pages/iadb/notesiadb/YieldsaspxThere are several relevant series: 10y par yields Annual average - IUAAMNPY - Annual   http://wwwbankofenglandcouk/boeapps/iadb/indexaspTravelNIxIRxlevels1XNotesYG0Xtopx56G0Xtopy10CDUSXNotes2YNodesX41514X41515X41516X41517X55047X76909X4051X4052X4128X33880X4053X4058SectionRequiredIHideNums-1ExtraInfotrueBM   1984-present   Direct download URLs look like http://wwwbankofenglandcouk/boeapps/iadb/fromshowcolumnsaspcsvxyesSeriesCodesIUMAMNPYUsingCodesYCSVFTNDatefrom01/Jan/1963Dateto01/Jan/2015 There are also versions of this series at other granularities down to a day   Daily - IUDMNPY - Daily   Month average - IUMAMNPY - Monthly   End month - IUMMNPY - Monthly   Quarterly average - IUQAMNPY - Quarterly   End quarter - IUQMNPY - Quarterly   Annual average - IUAAMNPY - Annual   End year - IUAMNPY - Annual 10y par gross redemption yield Annual average - IUAAAJLW - Annual   1984-2007 not clear why this ends in 2007 PreparationDo the following:     scripts/downloadsh     scripts/extractshData will be in annualcsv LicenseThe Bank of England Terms of Usetou appear only to allow non-commercialuse: Statistical Interactive Database IADB Terms and Conditions  The content of the database is for general information only and is provided to users free of charge Commercial use for financial gain is not permitted without the express permission of the Bank of England  The Bank of England reserves the right to terminate or restrict user access if it determines that a user is acting in a manner contrary to the interests of other users of the database eg excessive usage retrieved 2013-04-07tou: http://wwwbankofenglandcouk/pages/disclaimeraspxStatisticsHowever the amounts of data provided in this dataset is so minimal as likely to fallbelow any threshold for Database Rights As such the maintainers feel warranted in putting the dataset out under thePublic Domain Dedication and License but that they can obviously only licenseor dedicate material they control or in which there are no rights,,False,False,9.0,1.0,0.0,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
44,datasets/bond-yields-us-10y,DATA,datasets,bond-yields-us-10y,5.0,10 year nominal yields on US government bonds from the Federal Reserve,23.0,0.0,0.0,0.0,1.0,0.0,5.0,0.0,0.0,168.0,10 year nominal yields on US government bonds from the Federal Reserve The 10year government bond yield is considered a standard indicator of long-terminterest rates DataData comes from the Release H15 from the Federal Reserve - Selected InterestRates Dailyfed specifically the 10 year US Treasury monthlycsvfed-csvfed: http://wwwfederalreservegov/releases/h15/datahtmfed-csv: http://wwwfederalreservegov/datadownload/OutputaspxrelH15series0809abf197c17f1ff0b2180fe7015cc3lastObsfromtofiletypecsvlabelincludelayoutseriescolumn PreparationRun the shell script:     scripts/processshNote we keep a copy of the raw data from the Federal Reserve pre-tidying inarchive LicenseLicensed under the Public Domain Dedication and Licensepddl assumingeither no rights or public domain license in source datapddl: http://opendatacommonsorg/licenses/pddl/10/,,False,False,4.0,1.0,0.0,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
45,datasets/browser-stats,DATA,datasets,browser-stats,7.0,Web browser usage statistics,25.0,0.0,0.0,0.0,4.0,3.0,14.0,0.0,0.0,27.0,Web browser usage statistics over time DataPrimary data source is W3Schools browser statisticshttp://wwww3schoolscom/browsers/browsersstatsasp The data provided comes from the log files of W3Schools serversdatacsv contains usage statistics for both current browsers as well as several now-defunct browsersdata-extantcsv only includes data for current browsersPreparationThis package includes scripts/processpy to scrape the data Currently it is required to manually change the index to match which calendar years table data to act onLicenseNon-commerical use of this data appears to be covered under W3Schools Fair Use in their Terms of Usehttp://wwww3schoolscom/about/aboutcopyrightasp but please review these terms or contact W3Schools yourself to clarify terms for your specific usage,1.0,False,False,15.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46,datasets/cash-surplus-deficit,DATA,datasets,cash-surplus-deficit,1.0,"Cash Surplus/Deficit (% of GDP), from 1990 to 2013",23.0,0.0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,97.0, Cash Surplus/Deficit  of GDPRepository of the data package of the Cash Surplus or Deficit in percentage of GDP from 1990 to 2013 Updating the packageTo update the current package from its source simply run make from your terminal It should update the package automatically unless there were some changes in the source LicenseAll data is licensed under the Open Data Commons Public Domain Dedication and License All code is licensed under the MIT/BSD licenseNote that while no credit is formally required a link back or credit to Rufus Pollock and the Open Knowledge Foundation is much appreciated,0.893984962406,False,False,16.0,1.0,0.0,0.0,,0.106015037594,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
47,datasets/clinical-trials-us,DATA,datasets,clinical-trials-us,11.0,Official US clinical trial outcomes from the FDA,23.0,0.0,0.0,0.0,2.0,0.0,11.0,0.0,0.0,112.0,Data and processing scripts for clinical trials information inhttp://ClinicalTrialsgov a registry and results database of publicly andprivately supported clinical studies of human participants conducted around theworldDeposit in this database has been requiredrequired since September 2007 forall applicable clinical trials as per FDAAA 801required: http://wwwclinicaltrialsgov/ct2/manage-recs/fdaaaWhichTrialsMustBeRegisteredFDAAA 801: http://wwwgpogov/fdsys/pkg/PLAW-110publ85/pdf/PLAW-110publ85pdfpage82 Getting the data1 Go to http://wwwclinicaltrialsgov/2 Search no query to get all results3 Hit download and select all results4 Wait while 542 Mb zip file downloads searchresultszip5 unzip - you now have 23Gb of clinical trials xml6 Use the scripts - see below Data StructureIts XML Heres the XSD: http://clinicaltrialsgov/ct2/html/images/info/publicxsdSample records: data/NCT00000102xml without results data/NCT01101477xml with results Data Stats139848 XML files as of 2013-02-02As of Feb 1st 2013 only 8044 trials included posted-results ScriptsNodejs script in extractjs - still under development,,False,False,1.0,1.0,0.0,0.0,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,
48,datasets/co2-emissions,DATA,datasets,co2-emissions,1.0,Annual info about co2 emissions per nation,23.0,0.0,0.0,0.0,1.0,2.0,0.0,0.0,0.0,423.0,Per Country CO2 Emissions from fossil-fuels annually since 1751 Data comes from the Carbon Dioxide Information Analysis Center CDIACcdiaccdiac: http://cdiacesdornlgov/ CitationPlease cite as: Boden TA G Marland and RJ Andres 2013 Global Regional and National Fossil-Fuel CO2 Emissions Carbon Dioxide Information Analysis Center Oak Ridge National Laboratory US Department of Energy Oak Ridge Tenn USA doi 103334/CDIAC/00001V2013,1.0,False,False,10.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
49,datasets/co2-fossil-global,DATA,datasets,co2-fossil-global,6.0,Global CO2 Emissions from Fossil Fuels since 1751,23.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,100.0,Global CO2 Emissions from fossil-fuels annually since 1751 Data comes from theCarbon Dioxide Information Analysis Center CDIACcdiaccdiac: http://cdiacesdornlgov/ PreparationThe data was prepared in this Tabularum project:http://explorerokfnlabsorg/rgrp/9452691 CitationPlease cite as: Boden TA G Marland and RJ Andres 2013 Global Regional and National Fossil-Fuel CO2 Emissions Carbon Dioxide Information Analysis Center Oak Ridge National Laboratory US Department of Energy Oak Ridge Tenn USA doi 103334/CDIAC/00001V2013,,False,False,1.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
50,datasets/co2-ppm,DATA,datasets,co2-ppm,18.0,CO2 PPM - Trends in Atmospheric Carbon Dioxide,23.0,0.0,0.0,0.0,1.0,7.0,5.0,0.0,0.0,105.0,CO2 PPM - Trends in Atmospheric Carbon Dioxide Data are sourced from the US Governments Earth System Research Laboratory Global Monitoring Division Two main series are provided: the Mauna Loa series which has the longest continuous series since 1958 and a Global Average series a global average over marine surface sites Data Description Data are reported as a dry air mole fraction defined as the number of molecules of carbon dioxide divided by the number of all molecules in air including CO2 itself after water vapor has been removed The mole fraction is expressed as parts per million ppm Example: 0000400 is expressed as 400 ppmccgg-trends Citations1 Trends in Atmospheric Carbon Dioxide Mauna Loa Hawaii Dr Pieter Tans NOAA/ESRL wwwesrlnoaagov/gmd/ccgg/trends/ and Dr Ralph Keeling Scripps Institution of Oceanography scrippsco2ucsdedu/1 Trends in Atmospheric Carbon Dioxide Global Ed Dlugokencky and Pieter Tans NOAA/ESRL wwwesrlnoaagov/gmd/ccgg/trends/ Sources1    Name: Trends in Atmospheric Carbon Dioxide Mauna Loa Hawaii   Web: http://wwwesrlnoaagov/gmd/ccgg/trends/indexhtml1    Name: Trends in Atmospheric Carbon Dioxide Global   Web: http://wwwesrlnoaagov/gmd/ccgg/trends/globalhtml Data Preparation ProcessingRun the following script from this directory to download and process the data:bashmake data ResourcesThe raw data are output to /tmp The processed data are output to /data License ODC-PDDL-10This Data Package is made available under the Public Domain Dedication and License v10 whose full text can be found at: http://wwwopendatacommonsorg/licenses/pddl/10/ NotesThe terms of usegmd of the source dataset list three specific restrictions on public use of these data: The information on government servers are in the public domain unless specifically annotated otherwise and may be used freely by the public so long as you do not 1 claim it is your own eg by claiming copyright for NOAA information  see next paragraph 2 use it in a manner that implies an endorsement or affiliation with NOAA or 3 modify it in content and then present it as official government materialgmdccgg-trends: http://wwwesrlnoaagov/gmd/ccgg/trends/indexhtmlgmd: http://wwwesrlnoaagov/gmd/about/disclaimerhtml,,False,False,41.0,1.0,0.0,0.0,0.960433950223,0.0395660497766,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
51,datasets/cofog,DATA,datasets,cofog,6.0,Classifications of Functions of Government,23.0,0.0,0.0,1.0,1.0,0.0,3.0,0.0,0.0,143.0,Classification of the Functions of Government COFOG is a classification defined by the United Nations Statistics Division Its purpose is to classify the purpose of transactions such as outlays on final consumption expenditure intermediate consumption gross capital formation and capital and current transfers by general government from home pageThese functions are designed to be general enough to apply to the government of different countries The accounts of each country in the United Nations are presented under these categories The value of this is that the accounts of different countries can be compared DataData was sourced from the UN siteun-cofog raw access database from the UNaccessdb and extracted using the scripts found in the scripts directory of the source data package In addition to the UN site versions of COFOG can also be found on Eurostathttp://eceuropaeu/eurostat/ramon/nomenclatures/indexcfmTargetUrlLSTCLSDLDStrNomCLCOFOG99StrLanguageCodeENStrLayoutCodeHIERARCHIC with one advantage of the Eurostat data being the availability of additional languages eg Germanun-cofog: http://unstatsunorg/unsd/cr/registry/regcstaspCl4Lg1accessdb: http://unstatsunorg/unsd/cr/registry/regdntransferaspf186 LicenseNo license specified but factual data and extraction and normalization of the csv file has been done by the Maintainer who places the material in the Public Domain under the PDDL,1.0,False,False,11.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
52,datasets/commodity-prices,DATA,datasets,commodity-prices,1.0,Monthly Prices of 53 commodities and 10 indexes from 1980 to 2016.,23.0,0.0,1.0,2.0,0.0,0.0,2.0,0.0,0.0,675.0,Time series of major commodity prices and indices including iron cooper wheat gold oil Data comes from the International Monetary Fund IMFwwwimforgAll rights are reserved DataDataset contains Monthly prices for 53 commodities and 10 indexes starting from 1980 to 2016 Last updated on march 17 2016 The reference year for indexes are 2005 meaning the value of indexes are 100 and all other values are relative to that year LicenseThe IMF grants permission to visit its Sites and to download and copy informationdocuments and materials from the Sites for personal noncommercial usage onlywithout any right to resell or redistribute or to compile or create derivative workssubject to these Terms and Conditions of Usage and also subject to more specificrestrictions that may apply to particular information within the SitesAny rights not expressly granted herein are reservedFor more information please visit: Copyright and Usagehttp://wwwimforg/external/termshtm,0.947789766794,False,False,47.0,1.0,0.0,0.0,,0.0522102332057,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
53,datasets/continent-codes,DATA,datasets,continent-codes,2.0,List of continents with two letter code,23.0,0.0,0.0,0.0,0.0,0.0,6.0,0.0,0.0,13.0,A list of the seven continents with English names and short unique and permanent identifying codes DataData provides list of continents with their two letter codes Data is made manually according to several sources from internet that use this kind of format for continent two letter codesSeveral sources that use this format: - Country codeshttp://wwwgeonamesorg/countries/ from The GeoNames geographical database - Abbreviationshttp://planetarynameswrusgsgov/Abbreviations from International Astronomical Union IAU Working Group for Planetary System Nomenclature WGPSN - Wikipedia articlehttps://enwikipediaorg/wiki/Listofsovereignstatesanddependentterritoriesbycontinent28datafile29Datafile from Wikipedia the free encyclopedia - PHP functionhttp://phpnet/manual/en/functiongeoip-continent-code-by-namephp from PHP documentation,,False,False,25.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
54,datasets/corruption-perceptions-index,DATA,datasets,corruption-perceptions-index,3.0,Corruption Perceptions Index - CPI,24.0,0.0,0.0,3.0,10.0,1.0,9.0,2.0,0.0,73.0, corruption perceptions index the data is sourced from transparency internationalhttp://wwwtransparencyorg/research/cpi/overview   the corruption perceptions index cpi ranks countries/territories in terms of the degree to which corruption is perceived to exist among public officials and politicians it draws on different assessments and business opinion surveys carried out by independent and reputable institutions it captures information about the administrative and political aspects of corruption broadly speaking the surveys and assessments used to compile the index include questions relating to bribery of public officials kickbacks in public procurement embezzlement of public funds and questions that probe the strength and effectiveness of public sector anti-corruption efforts   more info herehttp://wwwtransparencyorg/cpi2014/indetail  requires: 1 r - rvest xlsx   2 java 8  3 julia - gadfly dataframes  note: the scale of the cpi is 0-10 from 1998 to 2011 and 0-100 from 2012 onwards due to an update to the methodology used to calculate the cpi in 2012  data in data/ generated by: /acquiredataror for the paranoid: torify /acquiredataracquiredatar downloads files from transparency international converts them to csv format and mergesthem in cpicsv file  warning: the files are not at all curated well many countries are spelled different ways in each annual report so the scripts will count them as different countries ,,False,False,40.0,1.0,0.0,0.0,,,,,,,,,,,0.602040816327,0.397959183673,,,,,,,,,,,,,,,,,,,,
55,datasets/country-codes,DATA,datasets,country-codes,16.0,"Comprehensive country code information, including ISO 3166 codes, ITU dialing codes, ISO 4217 currency codes, and many others",28.0,3.0,32.0,5.0,104.0,6.0,236.0,1.0,0.0,268.0,Comprehensive country code information including ISO 3166 codes ITU dialingcodes ISO 4217 currency codes and many others Provided as a Simple DataFormat Data Packagehttp://dataprotocolsreadthedocsio/en/latest/simple-data-formathtml DataData comes from multiple sources as follows:Customary English short names are fromUnicode Common Locale Data Repository CLDR Project https://githubcom/unicode-cldr/cldr-localenames-full/blob/master/main/en/territoriesjsonNote: CLDR shorter names ZZ-alt-short are used when availableISO 3166 official English and French short names are fromUnited Nations Statistics Divisionhttp://unstatsunorg/unsd/methods/m49/m49htmISO 4217 currency codes are fromcurrency-isoorghttp://wwwcurrency-isoorg/en/home/tables/table-a1htmlMany other country codes are fromstatoidscomhttp://wwwstatoidscom/wabhtmlSpecial thanks to Gwillim Law for his excellentstatoidscomhttp://wwwstatoidscom site some of the field descriptionsare excerpted from his site which is more up-to-date than most similarresources and is much easier to scrape than multiple Wikipedia pagesCapital cities languages continents TLDs and geonameid are from geonamesorghttp://downloadgeonamesorg/export/dump/countryInfotxtEDGAR codes are from secgovhttps://wwwsecgov/edgar/searchedgar/edgarstatecodeshtm PreparationThis package includes Python scripts to fetch current country informationand output a JSON document and CSV of combined country code informationCSV output is provided via the in2csv and csvcut utilities from csvkithttp://githubcom/onyxfish/csvkit data/country-codescsvInstall requirements:    pip install -r scripts/requirementspipRun GNU Make to generate data file:    make country-codescsv LicenseThis material is licensed by its maintainers under the Public Domain Dedicationand LicenseNevertheless it should be noted that this material is ultimately sourced fromISO and other standards bodies and their rights and licensing policies are somewhatunclear As this is a short simple database of facts there is a strong argumentthat no rights can subsist in this collection However ISO state on theirsitehttp://wwwisoorg/iso/home/standards/countrycodeshtm: ISO makes the list of alpha-2 country codes available for internal use and non-commercial purposes free of chargeThis carries the implication though not spelled out that other uses are notpermitted and that therefore there may be rights preventing further generaluse and reuseIf you intended to use these data in a public or commercial product pleasecheck the original sources for any specific restrictions,0.935398716774,False,False,74.0,2.0,0.0,0.0,,0.0646012832264,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
56,datasets/country-list,DATA,datasets,country-list,17.0,List of all countries in the world with their ISO 2 digit codes (ISO 3166-2) as CSV and JSON,25.0,0.0,2.0,2.0,24.0,2.0,60.0,1.0,0.0,146.0,ISO 3166-1-alpha-2 English country names and code elements This list statesthe country names official short names in English in alphabetical order asgiven in ISO 3166-1 and the corresponding ISO 3166-1-alpha-2 code elementsISO 3166-1: http://wwwisoorg/iso/home/standards/countrycodeshtmThis list is updated whenever a change to the official code list in ISO 3166-1is effected by the ISO 3166/MAIt lists 250 official short names and code elements as of Dec 2012 LicenseThis material is licensed by its maintainers under the Public Domain Dedicationand LicenseNevertheless it should be noted that this material is ultimately sourced fromISO and their rights and licensing policy is somewhat unclear As this is ashort simple database of facts there is a strong argument that no rights cansubsist in this collection However ISO state on theirsitehttp://wwwisoorg/iso/home/standards/countrycodeshtm:  ISO makes the list of alpha-2 country codes available for internal use and non-commercial purposes free of charge This carries the implication though not spelled out that other uses are notpermitted and that therefore there may be rights preventing further generaluse and reuse,,False,False,16.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
57,datasets/cpi,DATA,datasets,cpi,4.0,Annual consumer price index datapackage for most countries in the world,23.0,0.0,1.0,1.0,4.0,2.0,7.0,0.0,0.0,231.0,Annual Consumer Price Index CPI for most countries in the world when it has been measured The reference year is 2005 meaning the value of CPI for all countries is 100 and all other CPI values are relative to that year DataThe data comes from The World Bankhttp://dataworldbankorg/indicator/FPCPITOTL and is collected from 1960 to 2011 There are some values missing from data so users of the data will have to guess what should be in the empty slotsThe actual download happens via The World Banks API with csv as the requested formathttp://apiworldbankorg/indicator/FPCPITOTLformatcsvIt is parsed via the script cpi2datapackagepy located in scripts Usage of cpi2datapackagepy    usage: cpi2datapackagepy -h -o filename source        convert WorldBank CPI data to a data package resource    positional arguments:      source                source file to generate output from        optional arguments:      -h --help            show this help message and exit      -o filename --output filename                            define output filename,1.0,False,False,15.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
58,datasets/cpi-gb,DATA,datasets,cpi-gb,5.0,Consumer Price Index (and hence inflation) for the UK from 1850 to the present (monthly since June 1947). ,23.0,0.0,0.0,0.0,1.0,0.0,4.0,0.0,0.0,109.0,Consumer Price Index and hence inflation for the UK from 1850 to the present monthly since June 1947 DataKey source files are: Price Index 1800 to Presenthttp://wwwonsgovuk/ons/datasets-and-tables/downloads/csvcsvdatasetmm23cdidCDKO Inflation 1800 to Presenthttp://wwwonsgovuk/ons/datasets-and-tables/downloads/csvcsvdatasetmm23cdidCDSIWe take these and just to a split out of annual from monthly and some tidying of the date format see scripts/processjs ProcessingFirst do:    curl http://wwwonsgovuk/ons/datasets-and-tables/downloads/csvcsvdatasetmm23cdidCDKO  cache/cpi-ukcsvThen run the processing script to split out monthly and annual they put them in the same file :    node scripts/processjs RantWhy is it always so complicated to get data A quick search on the interwebs yields: http://wwwonsgovuk/ons/rel/cpi/consumer-price-indices/october-2012/cpi-time-series-datahtmlBut this turns out to be so big that it does not open in a spreadsheet programme if you take CSV In addition all the series descriptions are mixed in at the bottom of the file so this is not machine processableLets try instead to go for the series selector to try and break it down: http://wwwonsgovuk/ons/datasets-and-tables/data-selectorhtmldatasetmm23But this is about 20 different series - which one do you want Make an educated guess and repeat each time youre wrong,,False,False,3.0,1.0,0.0,0.0,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,
59,datasets/cpi-us,DATA,datasets,cpi-us,11.0,Us Consumer Price Index (DataHub Data Package),26.0,0.0,0.0,2.0,3.0,4.0,6.0,0.0,0.0,31.0,Consumer Price Index for All Urban Consumers CPI-U from US DepartmentOf Labor Bureau of Labor Statistics This is a monthly time series from January 1913 Values are US city averages for all items and1982-84100 Note that there are many price indices and this is only one ofthem albeit the most standard and with the longest set of data DataData is sourced from ftp://ftpblsgov/pub/specialrequests/cpi/cpiaitxt and normalized into a CSV,1.0,False,False,18.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
60,datasets/crime-uk,DATA,datasets,crime-uk,6.0,UK Crime data,23.0,0.0,0.0,0.0,4.0,0.0,11.0,0.0,0.0,126.0,UK Crime data This is consolidation of pointers to and scripts for datafrom various sources primarily the UK Government site athttp://policeuk/data Forces InfoSee data/forcescsv and a GDocs version:https://docsgooglecom/spreadsheet/ccckey0Aon3JiuouxLUdHNQRGFWQzFRS21fWlV1bzhuSjlJSVEgid0 Population DataPolice Force area population numbers from the Home Office:http://wwwhomeofficegovuk/publications/science-research-statistics/research-statistics/crime-research/population-estimates/pfa-la-pop-house-nos-xls Stats formatpreDatePeriodAreaTypeCount2012-04-01MonthAvon and Somerset ConstabularyBurglary51/pre StreetpreMonthReported byFalls withinEastingNorthingLocationCrime typeContext2012-04Avon and Somerset ConstabularyAvon and Somerset Constabulary360667169714On or near Hengrove LaneBurglary2012-04Avon and Somerset ConstabularyAvon and Somerset Constabulary363360174812On or near Mayfield Park SouthBurglary2012-04Avon and Somerset ConstabularyAvon and Somerset Constabulary356417116223On or near Hillside TerraceBurglary2012-04Avon and Somerset ConstabularyAvon and Somerset Constabulary366011173580On or near Brompton CloseBurglary2012-04Avon and Somerset ConstabularyAvon and Somerset Constabulary360070169484On or near Parsons PaddockBurglary2012-04Avon and Somerset ConstabularyAvon and Somerset Constabulary372396164022On or near East WayBurglary2012-04Avon and Somerset ConstabularyAvon and Somerset Constabulary323046124501On or near NightclubBurglary2012-04Avon and Somerset ConstabularyAvon and Somerset Constabulary360099171539On or near Firfield StreetBurglary2012-04Avon and Somerset ConstabularyAvon and Somerset Constabulary374604164984On or near Charlotte StreetBurglary/pre NeighbourhoodMonthForceNeighbourhoodAll crime and ASBBurglaryAnti-social behaviourRobberyVehicle crimeViolent crimePublic disorder and weaponsShopliftingCriminal damage and arsonOther theftDrugsOther crime2012-04Avon and Somerset ConstabularyJN3101100000000002012-04Avon and Somerset ConstabularyFW00411110120121202012-04Avon and Somerset ConstabularyJC2058070000100002012-04Avon and Somerset ConstabularyJW1109240000021002012-04Avon and Somerset ConstabularyJW1122010000001002012-04Avon and Somerset ConstabularyJW10913050200013202012-04Avon and Somerset ConstabularyJW1085141701305107222012-04Avon and Somerset ConstabularyJW107392230180031012012-04Avon and Somerset ConstabularyJW10641513016027313 OutcomespreMonthReported byFalls withinEastingNorthingLocationOutcome type2012-08Avon and Somerset ConstabularyAvon and Somerset ConstabularyNo locationSuspect charged2012-08Avon and Somerset ConstabularyAvon and Somerset ConstabularyNo locationLocal resolution2012-08Avon and Somerset ConstabularyAvon and Somerset ConstabularyNo locationOffender sentenced as part of another case2012-08Avon and Somerset ConstabularyAvon and Somerset ConstabularyNo locationOffender given a caution2012-08Avon and Somerset ConstabularyAvon and Somerset Constabulary358631172503On or near Prince StreetSuspect charged2012-08Avon and Somerset ConstabularyAvon and Somerset Constabulary362083182740On or near Honeysuckle CloseLocal resolution2012-08Avon and Somerset ConstabularyAvon and Somerset ConstabularyNo locationSuspect charged2012-08Avon and Somerset ConstabularyAvon and Somerset ConstabularyNo locationOffender given a caution2012-08Avon and Somerset ConstabularyAvon and Somerset Constabulary375327164974On or near Johnstone StreetOffender given a caution/pre,,False,False,8.0,1.0,0.0,0.0,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,
61,datasets/crunchcrawl,DATA,datasets,crunchcrawl,6.0,"A project to gather, analyze and visualized the data in Crunchbase",23.0,0.0,0.0,0.0,1.0,0.0,2.0,0.0,0.0,39929.0,CrunchcrawlThis module lets you index and download the company information held in CrunchbaseBefore using double-check http://wwwcrunchbasecom/robotstxt and the API conditions to ensure youre obeying the terms-of-serviceIt contains various scripts to index and pull down the latest data about the company as well as a snaphot of the data as it was on Monday August 23rd 2010 This data is CC-BY see http://wwwcrunchbasecom/help/licensing-policy for more informationBy Pete Warden petepetewardencom freely reusable see http://petewardentypepadcom for more,,False,False,2.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
62,datasets/currency-codes,DATA,datasets,currency-codes,9.0,ISO 4217 List of Currencies and Currency Codes,25.0,1.0,3.0,4.0,15.0,2.0,42.0,1.0,0.0,23.0,List of currencies and their 3 digit codes as defined by ISO 4217iso-4217 The dataprovided here is the consolidation of Table A1 Current currency  funds code list andTable A3 Historic denominationsNote that the ISO pageiso-4217 offers pay-for PDFs but also links tohttp://wwwcurrency-isoorg/en/home/tableshtml which does provide them in machinereadable form freelyiso-4217: http://wwwcurrency-isoorg/en/home/tableshtml DataThe data provided see data/codescsv in this data package provides aconsolidated list of currency and funds codes by combining these twoseparate tables: ISO Tables A1 - Current Currencies and Fundsa1 ISO Tables A3 - List of codes for historic denominations of currencies  fundsa3a1: http://wwwcurrency-isoorg/en/home/tables/table-a1htmla3: http://wwwcurrency-isoorg/en/home/tables/table-a3html PreparationRun the following script to download and convert the data from XML toCSV:cd scripts//runallshThe raw XML files are stored in /archive The cleaned data are/data/codes-allcsv VersionThe current tables have a published date of 28 March 2014 as indicatedin the XML files LicensePlacing in the Public Domain under the Public Domain Dedication and LicenseThe original site states no restriction on use and the data is small andcompletely factual,,False,False,12.0,1.0,0.0,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
63,datasets/datacatalogs.org,DATA,datasets,datacatalogs.org,1.0,Data from DataCatalogs.org,24.0,0.0,0.0,1.0,0.0,0.0,3.0,0.0,0.0,108.0,Scrape all datasets from datacatalogsorg geocode them tidy them up a littleand ouput as a JSON list of dictionaries in a single file The output file hasbeen uploaded to thedatahub here:http://thedatahuborg/dataset/datacatalogs-org,1.0,False,False,12.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
64,datasets/datasets.github.com,DATA,datasets,datasets.github.com,6.0,,23.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,60.0,,,False,False,2.0,0.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
65,datasets/edgar,DATA,datasets,edgar,11.0,Securities and Exchange Commission (SEC) EDGAR database which contains regulatory filings from publicly-traded US corporations.,23.0,0.0,0.0,0.0,19.0,0.0,52.0,0.0,0.0,120.0,Securities and Exchange Commission SEC EDGAR database EDGAR containsregulatory filings from publicly-traded US corporations including their annualand quarterly reports:edgar: http://wwwsecgov/edgarshtml All companies foreign and domestic are required to file registration statements periodic reports and other forms electronically through EDGAR Anyone can access and download this information for free from the SEC websiteedgar Human InterfaceSee http://wwwsecgov/edgar/searchedgar/companysearchhtmlimg srchttp://webshotokfnlabsorg/api/generateurlhttp3A2F2Fwwwsecgov2Fedgar2Fsearchedgar2Fcompanysearchhtml / Bulk DataEDGAR provides bulk access via FTP: ftp://ftpsecgov/ - officialdocumentationftp-doc We summarize here the main pointsEach company in EDGAR gets an identifier known as the CIK which is a 10 digitnumber You can find the CIK by searching EDGAR using a name of stock markettickerFor example searching for IBM by tickeribm-search shows us thatthe the CIK is 0000051143Note that leading zeroes are often omitted eg in the ftp access so thiswould become 51143ibm-search: http://wwwsecgov/cgi-bin/browse-edgarCIKibmactiongetcompanyimg srchttp://webshotokfnlabsorg/api/generateurlhttp3A2F2Fwwwsecgov2Fcgi-bin2Fbrowse-edgar3FCIK3Dibm26action3Dgetcompanywidth1024height768 /Next each submission receives an Accession Number acc-no For exampleIBMs quarterly financial filing form 10-Q in October 2013 had accessionnumber: 0000051143-13-000007 FTP File PathsGiven a company with CIK company ID XXX omitting leading zeroes anddocument accession number YYY acc-no on search results the path would be:File paths are of the form:    /edgar/data/XXX/YYYtxtFor example for the IBM data above it would be:ftp://ftpsecgov/edgar/data/51143/0000051143-13-000007txtNote if you are looking for a nice HTML version you can find it at in theArchives section with a similar URL just add -indexhtml:http://wwwsecgov/Archives/edgar/data/51143/000005114313000007/0000051143-13-000007-indexhtm IndicesIf you want to get a list of all filings youll want to grab an Index As the help page explains: The EDGAR indices are a helpful resource for FTP retrieval listing the following information for each filing: Company Name Form Type CIK Date Filed and File Name including folder path  Four types of indexes are available:   company  sorted by company name  form  sorted by form type  master  sorted by CIK number  XBRL  list of submissions containing XBRL financial files sorted by CIK   number these include Voluntary Filer Program submissionsURLs are like:ftp://ftpsecgov/edgar/full-index/2008/QTR4/mastergzThat is they have the following general form:    ftp://ftpsecgov/edgar/full-index/YYYY/QTR1-4/index-namegzzipSo for XBRL in the 3rd quarter of 2010 wed do:ftp://ftpsecgov/edgar/full-index/2010/QTR3/xbrlgzftp-doc: https://wwwsecgov/edgar/searchedgar/ftpusershtm CIK lists and lookupTheres a full list of all companies along with their CIK code here: http://wwwsecgov/edgar/NYU/cikcoleftcIf you want to look up a CIK or company by its ticker you can do the following query against the normal search system:http://wwwsecgov/cgi-bin/browse-edgarCIKibmFindSearchownerexcludeactiongetcompanyoutputatomThen parse the atom to grab the CIK If you prefer HTML output just omit outputatomThere is also a full-text company name to CIK lookup here:http://wwwsecgov/edgar/searchedgar/cikhtmLNote this does a POST to a text API at http://wwwsecgov/cgi-bin/cikplc Parsing XBRL DataSee scripts and README file there References CorpWatch have an excellent API and DB dump covering a lot of EDGAR info - see the CorpWatch DataHub Entrycorpwatchcorpwatch: http://datahubio/dataset/corpwatch,,False,False,3.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
66,datasets/employment-us,DATA,datasets,employment-us,0.0,US Employment and Unemployment rates since 1940 from Bureau of Labor Statistics,23.0,0.0,0.0,4.0,4.0,2.0,4.0,0.0,0.0,141.0,US Employment and Unemployment rates since 1940 Official title: Employmentstatus of the civilian noninstitutional population 1940 to date from USABureau of Labor Statistics DataNumbers are in thousands  License As US Federal Government data can assume Public Domain Maintainer licenses anyadditional rights from processing and structuring under Public DomainDedication and License,1.0,False,False,11.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
67,datasets/eu-emissions-trading-system,DATA,datasets,eu-emissions-trading-system,1.0,Data about the EU emission trading system (ETS),23.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,510.0,Data about the EU emission trading system ETS The EU emission trading system ETS is one of the main measures introduced by the EU to achieve cost-efficient reductions of greenhouse gas emissions and reach its targets under the Kyoto Protocol and other commitments The data mainly comes from the EU Transaction Log EUTL DataAggregated data on greenhouse gas emissions and allowances  Geographic coverageAustria Belgium Bulgaria Croatia Cyprus Czech Republic Denmark Estonia Finland France Germany Greece Hungary Iceland Ireland Italy Latvia Liechtenstein Lithuania Luxembourg Malta Netherlands Norway Poland Portugal Romania Slovakia Slovenia Spain Sweden United Kingdom Temporal coverage2005-2014 Sources1    Name: European Union Emissions Trading System data from EUTL   Web: http://wwweeaeuropaeu/data-and-maps/data/european-union-emissions-trading-scheme-eu-ets-data-from-citl-7 Data Preparation RequirementsPython 2 together with modules urllib and zipfile are required in order to process the data  ProcessingRun the following script from this directory to download and process the data:bashmake ResourcesThe raw data are output to /tmp The processed data are output to /data License DataData are sourced from European Environment Agency and no copyright restrictions are applied More specifically: EEA aspires to promote the sharing of environmental data In agreeing to share data providers need to have assurance that their data are properly handled disseminated and acknowledged following similar principles and rules across countries and stakeholderspermissions Additional workAll the additional work done to build this Data Package is made available under the Public Domain Dedication and License v10 whose full text can be found at: http://wwwopendatacommonsorg/licenses/pddl/10/ Citations1 EEA standard re-use policy: unless otherwise indicated re-use of content on the EEA website for commercial or non-commercial purposes is permitted free of charge provided that the source is acknowledged http://wwweeaeuropaeu/legal/copyright Copyright holder: Directorate-General for Climate Action DG-CLIMApermissions: http://wwweeaeuropaeu/legal/eea-data-policy,0.962302598064,False,False,10.0,1.0,0.0,0.0,,0.0376974019358,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
68,datasets/euribor,DATA,datasets,euribor,10.0,Work in progress to extract Euribor data for https://github.com/datasets/registry/issues/35,23.0,0.0,0.0,1.0,2.0,0.0,2.0,1.0,0.0,244.0,Euribor rates by year and granularity Only monthly granularity is provided  DataData is taken from the Euribor EU websitehttp://wwweuribor-rateseu/euribor-rates-by-yearaspEuribor is defined as below Euribor is short for Euro Interbank Offered Rate The Euribor rates are based on the interest rates at which a a panel of European banks borrow funds from one another In the calculation the highest and lowest 15 of all the quotes collected are eliminated The remaining rates will be averaged and rounded to three decimal places Euribor is determined and published at about 11:00 am each day Central European Time When Euribor is being mentioned it is often referred to as THE Euribor like theres only 1 Euribor interest rate This is not correct since there are in fact 8 different Euribor rates all with different maturities until november 1st 2013 there were 15 maturities data/csv All files in directory data are using the following naming convention pattern:    euribor-maturity-granularitycsvFor instance you can have     euribor-1w-monthlycsv    euribor-1m-monthlycsv    euribor-10m-monthlycsv    w means weeks and m means months for the maturity section The columns are the same for all csv filesThey are three of them : date is the date for the rate value It follows by convention ISO 8601 formatting and is for the first day of the month rate is the Euribor rate It uses pourcentage  maturitylevel express the same information you have in file naming convention Before nov 2013 there was 15 rates and now only 8 are available due to EU banking regulationsThe oldest available data are from 1999In the future we may provide an additionnal column for granularity but at the moment its not useful as we only use monthly granularity PreparationThis package includes a bash script executing two python scripts one scripts/scrapeuriborpy to fetch content the other scripts/concatfilesbymaturitypy to concat files per maturity for each granularity At the moment we only get monthly granularity LicenseThis Data Package is licensed by its maintainers under the Public Domain Dedication and License PDDLhttp://opendatacommonsorg/licenses/pddl/10/Refer to the terms of usehttp://wwweuribor-rateseu/disclaimerasp of the source dataset for any specific restrictions on using these data in a public or commercial product You should also be aware that this data comes indirectly from http://wwwemmi-benchmarkseu/euribor-org/euribor-rateshtmlNote that underlying rights terms and conditions in the data from the source are unclear and may exists,0.966399506782,False,False,13.0,1.0,0.0,0.0,0.0336004932182,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
69,datasets/exchange-rates-usd,DATA,datasets,exchange-rates-usd,1.0,Exchange Rates Data Package,23.0,0.0,0.0,0.0,0.0,0.0,3.0,0.0,0.0,88.0,Code for producing consolidated historical exchange rate data from a variety ofsourcesSee http://thedatahuborg/dataset/exchange-ratesInstructionsGet the exchange-rates data package eg using data package manager:    dpm clone ckan://exchange-rates This will get the source data dumps into the data/ directoryThen do:    python runpyResult will be at data/consolidatedcsv,1.0,False,False,1.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
70,datasets/finance-vix,DATA,datasets,finance-vix,7.0,"CBOE Volatility Index (VIX) time-series dataset including daily open, close, high and low.",23.0,1.0,0.0,1.0,6.0,1.0,10.0,1.0,0.0,186.0,CBOE Volatility Index VIX time-series dataset including daily open closehigh and low The CBOE Volatility Index VIX is a key measure of marketexpectations of near-term volatility conveyed by SP 500 stock index optionprices introduced in 1993 DataFrom the VIX FAQfaq: In 1993 the Chicago Board Options Exchange CBOE introduced the CBOE Volatility Index VIX and it quickly became the benchmark for stock market volatility It is widely followed and has been cited in hundreds of news articles in the Wall Street Journal Barrons and other leading financial publications Since volatility often signifies financial turmoil VIX is often referred to as the investor fear gauge VIX measures market expectation of near term volatility conveyed by stock index option prices The original VIX was constructed using the implied volatilities of eight different OEX option series so that at any given time it represented the implied volatility of a hypothetical at-the-money OEX option with exactly 30 days to expiration  The New VIX still measures the markets expectation of 30-day volatility but in a way that conforms to the latest thinking and research among industry practitioners The New VIX is based on SP 500 index option prices and incorporates information from the volatility skew by using a wider range of strike prices rather than just at-the-money series faq: http://wwwcboecom/micro/vix/faqaspx PreparationRun the shell script:     scripts/processshOutput data is in data/ TODO Incorporate computed historical data 1990-2003 Consider incorporating VOX data LicenseNo obvious statement on historical data pagehistorical Given size andfactual nature of the data and its source from a US company would imagine thiswas public domain and as such have licensed the Data Package under the PublicDomain Dedication and License PDDLhistorical: http://wwwcboecom/micro/vix/historicalaspx,,False,False,32.0,2.0,0.0,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
71,datasets/gdp,DATA,datasets,gdp,3.0,"Country, regional and world GDP in current US Dollars ($)",25.0,1.0,1.0,1.0,9.0,2.0,23.0,0.0,0.0,338.0,Country regional and world GDP in current US Dollars  Regional meanscollections of countries eg Europe  Central Asia Data is sourced from theWorld Bank and turned into a standard normalized CSV code can be found inprocesspy of data package repository SourceThe data is sourced from the World Bank specifically this datasetcurrent whichin turn lists as sources: World Bank national accounts data and OECD NationalAccounts data filesNote that there are a variety of different GDP indicators on offer from theWorld Bank including: GDP in current USDcurrent GDP in constant USD 2000constant GDP PPP constant 2005 international ppp GDP constant LCUlcuconstant: http://dataworldbankorg/indicator/NYGDPMKTPKDcurrent: http://dataworldbankorg/indicator/NYGDPMKTPCDppp: http://dataworldbankorg/indicator/NYGDPMKTPPPKDlcu: http://dataworldbankorg/indicator/NYGDPMKTPKN,1.0,False,False,19.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
72,datasets/gdp-uk,DATA,datasets,gdp-uk,5.0,UK GDP,24.0,0.0,1.0,1.0,0.0,1.0,1.0,0.0,0.0,3.0,UK Real GDP since 1948 from the Office of National Statistics includingpercentage change and index versions DataAnnual data in annualcsv The GDP measure is a chained volume measure and istherefore real not nominal  Amounts are in 2009 mExtracted fromhttp://wwwonsgovuk/ons/datasets-and-tables/downloads/csvcsvdatasetpgdpProcess is recorded and automated in 2 bash scripts:    scripts/downloadsh    scripts/extractsh LicensingSuch small amounts of data that believe there are no underlying rights andhence have provided under the Public Domain Dedication License,,False,False,6.0,1.0,0.0,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
73,datasets/gdp-us,DATA,datasets,gdp-us,6.0,Gross Domestic Product of the United States (US GDP),23.0,0.0,0.0,0.0,3.0,0.0,2.0,0.0,0.0,120.0,Gross Domestic Product GDP of the United States US both nominal and real onan annual and quarterly basis Annual data is provided since 1930 and quarterlydata since 1947 Both total GDP levels and annualized percentage change inGDP are provided Both levels and changes are available both in current dollarsnominal GDP and in chained 2009 dollars real GDP Data is sourced from USGovernments Bureau of Economic Analysis BEA and provided in standardizedCSV DataThe calculation of GDP and in particular chained measures of GDP involvessome complexities You can read more about the benefits and issues of BEAsChain Indexes in the BEAs 1997 Survey of Current Businessbea-1997bea-1997: http://www2econiastateedu/classes/econ302/vandewetering/BEAhtml PreparationRequires Python Install the requirements:    pip install -r scripts/requirementstxtThen run the script to get the data:    python scripts/processpy LicensePublic Domain Dedication and LicenseNote we assume source data is public domain as US Federal Government,1.0,False,False,2.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
74,datasets/genome-sequencing-costs,DATA,datasets,genome-sequencing-costs,1.0,Costs assosiated with DNA sequencing since 2001,23.0,0.0,0.0,0.0,2.0,1.0,0.0,0.0,0.0,21.0,DNA Sequencing Costs Data Description For many years the National Human Genome Research Institute NHGRI has tracked the costs associated with DNA sequencing performed at the sequencing centers funded by the Institute This information has served as an important benchmark for assessing improvements in DNA sequencing technologies and for establishing the DNA sequencing capacity of the NHGRI Genome Sequencing Program GSP Here NHGRI provides an analysis of these data which gives one view of the remarkable improvements in DNA sequencing technologies and data-production pipelines in recent years Temporal coverage 2001-2015 Further Information For further information regarding cost categories DNA Sequencing Technologies Quality and Genome Coverage please visit: http://wwwgenomegov/sequencingcosts/ Citations1 Wetterstrand KA DNA Sequencing Costs: Data from the NHGRI Genome Sequencing Program GSP Available at: wwwgenomegov/sequencingcosts Accessed 21-12-2015 Sources1    Name: National Human Genome Research Institute   Web: http://wwwgenomegov/pages/der/sequencingcostsoct2015xlsx Data Preparation RequirementsPython 2 together with modules urllib and datautil are required in order to process the data  ProcessingRun the following script from this directory to download and process the data:bashmake Resources The raw data are stored on directory /archive/ The processed data are stored on directory /data License ODC-PDDL-10This Data Package is made available under the Public Domain Dedication and License v10 whose full text can be found at: http://wwwopendatacommonsorg/licenses/pddl/10/,0.916846652268,False,False,7.0,1.0,0.0,0.0,,0.0831533477322,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
75,datasets/geo-boundaries-us-110m,DATA,datasets,geo-boundaries-us-110m,6.0,"Internal, first-order administrative boundaries and polygons for the United States in .shp, .geojson, and .topojson.",23.0,0.0,1.0,0.0,0.0,0.0,5.0,0.0,0.0,292.0,geo-boundaries-us-110mInternal first-order administrative boundaries and polygons for the United States shp converted to geojson QGIS and topojson http://mapshaperorg/  reference data here:  http://wwwnaturalearthdatacom/downloads/110m-cultural-vectors/110m-admin-1-states-provinces/  and repo is here:  https://githubcom/nvkelso/natural-earth-vector/tree/master/110mcultural,,False,False,6.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
76,datasets/geo-boundaries-world-110m,DATA,datasets,geo-boundaries-world-110m,9.0,DEPRECATED - replaced by https://github.com/datasets/geo-countries (Map of the world's countries - vector data at 1:110m scale),23.0,0.0,1.0,2.0,9.0,0.0,13.0,0.0,0.0,217.0, DEPRECATEDPlease use the newer and better maintained datapackage https://githubcom/datasets/geo-countries DataGeodata data package providing geojson polygons for all the worlds countriesPerfect for use in apps and visualizations,,False,False,2.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
77,datasets/geo-countries,DATA,datasets,geo-countries,3.0,Country polygons as GeoJSON in a datapackage,23.0,0.0,1.0,3.0,6.0,1.0,31.0,0.0,0.0,7503.0,Geodata data packagedatapackage providing geojson polygons for all the worlds countriesPerfect for use in apps and visualizations DataThe data comes from Natural Earthnaturalearth a community effort to make visually pleasing well-crafted maps with cartography or GIS software at small scaleThe shape of the countries have two fields :  name : the common name for the country ISO3166-1-Alpha-3 : three letters iso code of the countryMore info about countries can be get from datapackage https://githubcom/datasets/country-codes by a join on field ISO3166-1-Alpha-3naturalearth: http://wwwnaturalearthdatacom/datapackage: http://dataprotocolsorg/data-packages/ PreparationTo run the script in order to update the data : see scripts READMEscripts/READMEmd LicenseAll data is licensed under the Open Data Commons Public Domain Dedication and Licensepddl Note that the original data from Natural Earthnaturalearth is public domain While no credit is formally required a link back or credit to Natural Earthnaturalearth Lexmanlexman and the Open Knowledge Foundationokfn is much appreciatedAll source code is licenced under the MIT licencemitmit: https://opensourceorg/licenses/MITnaturalearth: http://wwwnaturalearthdatacom/pddl: http://opendatacommonsorg/licenses/pddl/10/lexman: http://githubcom/lexmanokfn: http://okfnorg/,,False,False,24.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
78,datasets/geo-ne-admin1,DATA,datasets,geo-ne-admin1,1.0,Test of a datapackage for Natural Earth admin1,23.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,10427.0,Geodata data packagedatapackage providing geojson polygons for the largest administrative subdivisions in every countries DataNote : this dataset and its source are still in BETAThe data comes from Natural Earthnaturalearth a community effort to make visually pleasing well-crafted maps with cartography or GIS software at small scaleAdmin1doc is the biggest administrative subdivision of countries Note that it is very heterogeneous among countries : in the United States of America admin1 represents states whereas they dont represent the inner countries in the United Kingdom For more information please see official documentationdoc or https://enwikipediaorg/wiki/TableofadministrativedivisionsbycountryThe shape of the admin1 have four fields :  name : the common name for this admin1 subdivision id : code for the subdivision inside the country Documentationdoc is not clear what this code is but it could be FIPS Note that some countries like Vatican are so small they dont have inner administrative subdivision In that case code could be null and in any way it is irrelevant country : name of the country ISO3166-1-Alpha-3 : three letters iso code of the countrynaturalearth: http://wwwnaturalearthdatacom/datapackage: http://dataprotocolsorg/data-packages/doc: http://wwwnaturalearthdatacom/downloads/10m-cultural-vectors/10m-admin-1-states-provinces/ PreparationTo run the script in order to update the data : see scripts READMEscripts/READMEmd LicenseAll data is licensed under the Open Data Commons Public Domain Dedication and Licensepddl Note that the original data from Natural Earthnaturalearth is public domain While no credit is formally required a link back or credit to Natural Earthnaturalearth Lexmanlexman and the Open Knowledge Foundationokfn is much appreciatedAll source code is licenced under the MIT licencemitmit: https://opensourceorg/licenses/MITnaturalearth: http://wwwnaturalearthdatacom/pddl: http://opendatacommonsorg/licenses/pddl/10/lexman: http://githubcom/lexmanokfn: http://okfnorg/,,False,False,19.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
79,datasets/geo-ne-admin1-us,DATA,datasets,geo-ne-admin1-us,1.0,Natural Earth admin1 in the USA,23.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,38.0,Geodata data packagedatapackage providing geojson polygons for the states in the USA DataThe data comes from Natural Earthnaturalearth a community effort to make visually pleasing well-crafted maps with cartography or GIS software at small scaleThis dataset covers the United States of America admin1 are the biggest administrative area below the country : ie the states See documentationdoc for more informationThe shape of the admin1 have four fields :  name : the common name for this admin1 subdivision id : Natural Earth adm1code for the subdivision inside the country Documentationdoc is not clear what this code is but it could be FIPS code : the well known two letter code for the state country : name of the country ISO3166-1-Alpha-3 : three letters iso code of the countrynaturalearth: http://wwwnaturalearthdatacom/datapackage: http://dataprotocolsorg/data-packages/doc: http://wwwnaturalearthdatacom/downloads/10m-cultural-vectors/10m-admin-1-states-provinces/ LicenseAll data is licensed under the Open Data Commons Public Domain Dedication and Licensepddl Note that the original data from Natural Earthnaturalearth is public domain While no credit is formally required a link back or credit to Natural Earthnaturalearth Lexmanlexman and the Open Knowledge Foundationokfn is much appreciatedAll source code is licenced under the MIT licencemitmit: https://opensourceorg/licenses/MITnaturalearth: http://wwwnaturalearthdatacom/pddl: http://opendatacommonsorg/licenses/pddl/10/lexman: http://githubcom/lexmanokfn: http://okfnorg/,,False,False,8.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
80,datasets/geo-nuts-administrative-boundaries,DATA,datasets,geo-nuts-administrative-boundaries,1.0,"Datapackage for NUTS admin levels 1, 2 and 3 edition 2010",23.0,0.0,0.0,1.0,0.0,0.0,4.0,0.0,0.0,10572.0,Geo Boundaries for NUTS administrative levels 1 2 and 3 edition 2010If you dont know what NUTS Nomenclature of Territorial Units for Statistics are see the related Wikipedia articlehttps://enwikipediaorg/wiki/NomenclatureofTerritorialUnitsforStatistics DataData is taken from the GISCO EU websitehttp://eceuropaeu/eurostat/web/gisco/geodata/reference-dataWe choose to deliver data as Shapefiles SHP and as GeoJSONSHP are in data/shp directoryGeoJSON are in data folderDatasets are provided for NUTS levels 1 2 and 3The columns are NUTSID: String 50 STATLEVL: Integer 90You will also find the original data within data/NUTS201060MSHIf you need other related informations to NUTS you can take a look at PDF file describing relationships between original tables in data/NUTS201060MSH/NUTS201060MSH/metadata/NUTS2010metadatapdf PreparationThis package include the script to automate data retrieving and filtering As we use NodeJs/Iojs you need to install the software Then install dependencies with:    cd scripts  npm installTo launch all the process just do node indexjsWe choose to let a lot of comments and you may encounter some minors job unrelated code for learning purpose if you need to use node-gdal libraryhttps://githubcom/naturalatlas/node-gdal LicenseThis Data Package is licensed by its maintainers under the Public Domain Dedication and License PDDLhttp://opendatacommonsorg/licenses/pddl/10/Refer to the Copyright noticehttp://eceuropaeu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units of the source dataset for any specific restrictions on using these data in a public or commercial product,,False,False,11.0,1.0,0.0,0.0,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,
81,datasets/geodata,DATA,datasets,geodata,8.0,Various spatial data items,23.0,0.0,0.0,1.0,0.0,0.0,5.0,0.0,0.0,147021.0,Public geospatial data sets presented in formats commonly used by open-source tools The greatest effort will be made to make data sets available in GeoJSONhttp://geojsonorg and SpatiaLitehttp://wwwgaia-gisit/gaia-sins/ formats Larger polygon data sets may also be made available as TopoJSONhttps://githubcom/mbostock/topojson/wikiCD113 - 113th Congressional Districts Census Bureaumilbase - US military bases Bureau of Transportation Statisticsbordercrossings - US border crossings Bureau of Transportation Statistics,,False,False,22.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
82,datasets/geoip2,DATA,datasets,geoip2,3.0,GeoIP2 - free IP geolocation database.,23.0,0.0,0.0,2.0,2.0,0.0,3.0,1.0,0.0,1100.0,Database of IPv4 address networks with their respective geographical locationDataBased on GeoLite2 Country Free Downloadable Databases as of Apr 21 2015 http://devmaxmindcom/geoip/geoip2/geolite2/Two files were used to generate this dataset:  GeoLite2-Country-Blocks-IPv4csv  GeoLite2-Country-Locations-encsv  with the following considerations:  - Where geonameid was not available registeredcountrygeonameid was used- Where geonameid and registeredcountrygenonameid where empty geonameid continentcode continentname countryisocode and countryname are emptyPreparationOriginal CSVs were imported into a MySQL database then with a script an additional CSV was created combining Country names locations and IPs LicenseDatapackage: Creative Commons Zero  Original CSV: This dataset includes GeoLite2 data created by MaxMind available from wwwmaxmindcom,,False,False,9.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
83,datasets/gini-index,DATA,datasets,gini-index,1.0,Repository of the GINI index official repository.,23.0,0.0,1.0,0.0,0.0,0.0,4.0,0.0,0.0,87.0,The repository of the data package of the GINI Index DataThe data that is contained in the gini-indexcsv file under /data wasretrieved from the World Bankhttp://dataworldbankorg/indicator/SIPOVGINI LicenseAll data is licensed under the Open Data Commons Public Domain Dedication and License All code is licensed under the MIT/BSD licenseNote that while no credit is formally required a link back or credit to Rufus Pollock and the Open Knowledge Foundation is much appreciated,0.888399412628,False,False,9.0,1.0,0.0,0.0,,0.111600587372,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
84,datasets/glacier-mass-balance,DATA,datasets,glacier-mass-balance,1.0,"Average cumulative mass balance of ""reference"" Glaciers worldwide",23.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,9.0,Average cumulative mass balance of reference Glaciers worldwide from 1945-2014 sourced from US EPAdatahome and the World Glacier Monitoring Service WGMSwgmsThis is cumulative change in mass balance of a set of reference glaciers worldwide beginning in 1945 The values represents the average of all the glaciers that were measured Negative values indicate a net loss of ice and snow compared with the base year of 1945 For consistency measurements are in meters of water equivalent which represent changes in the average thickness of a glacierdatahome: http://www3epagov/climatechange/science/indicators/snow-ice/glaciershtmlwgms: http://wgmsch/datadatabaseversions/ Data Sources1    Name: Climate Change Indicators in the United States   Web: http://www3epagov/climatechange/images/indicatordownloads/glaciersfig-1csv1    Name: World Glacier Monitoring Service WGMS   Web: http://wgmsch/downloads/wgms2013gmbb12pdf Related publications:WGMS 2015: Global Glacier Change Bulletin No 1 2012-2013 Zemp M Grtner-Roer I Nussbaumer SU Hsler F Machguth H Mlg N Paul F and Hoelzle M eds ICSUWDS/IUGGIACS/UNEP/UNESCO/WMO World Glacier Monitoring Service Zurich Switzerland 230 pp Based on database version: doi: 105904/wgms-fog-2015-11WGMS 2013: Glacier Mass Balance Bulletin No 12 2010-2011 Zemp M Nussbaumer SU Naegeli K Grtner-Roer I Paul F Hoelzle M and Haeberli W eds ICSU WDS / IUGG IACS / UNEP / UNESCO / WMO World Glacier Monitoring Service Zurich Switzerland: 106 pp publication based on database version:doi:105904/wgms-fog-2013-11WGMS 2012: Fluctuations of Glaciers 2005-2010 Vol X: Zemp M Frey H Grtner-Roer I Nussbaumer SU Hoelzle M Paul F  W Haeberli eds ICSU WDS/ IUGG IACS/ UNEP/ UNESCO/ WMO World Glacier Monitoring Service Zurich Switzerland Based on database version doi: 105904/wgms-fog-2012-11WGMS World Glacier Monitoring Service 2015 update to data originally published in: WGMS 2013 Glacier mass balance bulletin no 12 20102011 Zemp M SU Nussbaumer K Naegeli I Grtner-Roer F Paul M Hoelzle and W Haeberli eds ICSU WDS/IUGG IACS/UNEP/UNESCO/WMO Zurich Switzerland: World Glacier Monitoring Service http://wgmsch/downloads/wgms2013gmbb12pdf WGMS World Glacier Monitoring Service Zurich Switzerland License DataEPA is Federal Government so public domain we would assumeWGMS make their data available as Open access for scientific and educational purposes under requirement of correct citation: WGMS 2015: Fluctuations of Glaciers Database World Glacier Monitoring Service Zurich Switzerland DOI:105904/wgms-fog-2015-11 Additional work All the additional work made to build this Data Package is made available under the Public Domain Dedication and License v10 whose full text can be found at: http://wwwopendatacommonsorg/licenses/pddl/10/ Citations WGMS World Glacier Monitoring Service 2015 update to data originally published in: WGMS 2013 Glacier mass balance bulletin no 12 20102011 Zemp M SU Nussbaumer K Naegeli I Grtner-Roer F Paul M Hoelzle and W Haeberli eds ICSU WDS/IUGG IACS/UNEP/UNESCO/WMO Zurich Switzerland: World Glacier Monitoring Service http://wgmsch/downloads/wgms2013gmbb12pdf Useful infoThere does seem to be more recent data because there are graphs with more recent eg graphs like this on Climategovhttps://wwwclimategov/news-features/understanding-climate/2012-state-climate-glaciers or PDF data like this from World Glacier monitoring servicehttp://wgmsch/productsfog/ and this PDF from WGMShttp://wgmsch/downloads/wgms2012fogXpdf  Data from World Glacier Monitoring Service WGMS: http://wgmsch/datadatabaseversions/Here is zip file with datasets: http://wgmsch/downloads/DOI-WGMS-FoG-2015-11zipInternationally collected standardized dataset on changes in glaciers length area volume mass based on in-situ and remotely sensed observations as well as on reconstructions GLIMS Glacier databasehttp://wwwglimsorg From the site: GLIMS Global Land Ice Measurements from Space is a project designed to monitor the worlds glaciers primarily using data from optical satellite instruments such as ASTER Advanced Spaceborne Thermal Emission and reflection Radiometer Data can be found at http://glimscoloradoedu/glacierdata/ which links to http://wwwglimsorg/download/ Data is large tgz files - probably containing geodata on individual glacier outlines Stats on data contents at http://glimscoloradoedu/glacierdata/dbsummarystatsphp - these show coverage from 1870 to 2011 and thousands of glaciers worldwide   Relationship to WGMS World Glacier Inventory: The GLIMS database is designed to be a logical extension of the World Glacier Inventory WGI of the World Glacier Monitoring Service WGMS and stores the full complement of the WGMS-defined glacier characteristics sourcehttps://nsidcorg/glims/ The US EPA also have this Graph: Average cumulative mass balance of reference Glaciers worldwide from 1945-2014http://www3epagov/climatechange/science/indicators/snow-ice/glaciershtml You can get the CSV Data for the graph here: http://www3epagov/climatechange/images/indicatordownloads/glaciersfig-1csv According to the footnote for the graph the original source is:    WGMS World Glacier Monitoring Service 2015 update to data originally published in: WGMS 2013 Glacier mass balance bulletin no 12 20102011 Zemp M SU Nussbaumer K Naegeli I Grtner-Roer F Paul M Hoelzle and W Haeberli eds ICSU WDS/IUGG IACS/UNEP/UNESCO/WMO Zurich Switzerland: World Glacier Monitoring Service http://wgmsch/downloads/wgms2013gmbb12pdf NOAA Glacier Mass Balance and Regime Measurements and Analysis 1945-2003 Version 1Data can be found herehttp://nsidcorg/data/g10002 but Im not sure if this link will lead you directly it requires registration but here is the link for datasets: ftp://sidadscoloradoedu/pub/DATASETS/NOAA/G10002/Supplement2005/,0.91159586682,False,False,9.0,1.0,0.0,0.0,,0.0884041331803,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
85,datasets/global-temp,DATA,datasets,global-temp,1.0,Global Temperature Time Series,23.0,0.0,1.0,0.0,3.0,0.0,6.0,0.0,0.0,116.0,Global Temperature Time Series Data are included from the GISS Surface Temperature GISTEMP analysis and the global component of Climate at a Glance GCAG Two datasets are provided: 1 global monthly mean and 2 annual mean temperature anomalies in degrees Celsius from 1880 to the present Data Description1 GISTEMP Global Land-Ocean Temperature Indexgistemp:   Combined Land-Surface Air and Sea-Surface Water Temperature Anomalies ie deviations from the corresponding 1951-1980 means Global-mean monthly  and annual means 1880-present updated through most recent month1 Global component of Climate at a Glance GCAGgcag:   Global temperature anomaly data come from the Global Historical Climatology Network-Monthly GHCN-M data set and International Comprehensive Ocean-Atmosphere Data Set ICOADS which have data from 1880 to the present These two datasets are blended into a single product to produce the combined global land and ocean temperature anomalies The available timeseries of global-scale temperature anomalies are calculated with respect to the 20th century average  Citations1 GISTEMP: NASA Goddard Institute for Space Studies GISS Surface Temperature Analysis Global Land-Ocean Temperature Index1 NOAA National Climatic Data Center NCDC global component of Climate at a Glance GCAG Sources1    Name: GISTEMP Global Land-Ocean Temperature Index   Web: http://datagissnasagov/gistemp1    Name: Global component of Climate at a Glance GCAG   Web: http://wwwncdcnoaagov/cag/data-info/global Additional Data Upstream datasets:   GHCN-Mghcn-m   ERSSTersst   ICOADSicoads Other:   HadCRUT4hadcrut4 time series data are not included in the published Data Package at this time because of the datasets restrictive terms and conditionshadcrut4-terms However the data preparation script supports processing the dataset Data Preparation RequirementsData preparation requires Python 2 ProcessingRun the following script from this directory to download and process the data:bashmake dataHundredths of degrees Celsius in the GISTEMP Global Land-Ocean Temperature Index data are converted to degrees CelsiusA HadCRUT4 processing script is available but not run by default ResourcesThe raw data are output to /tmp The processed data are output to /data License ODC-PDDL-10This Data Package and these datasets are made available under the Public Domain Dedication and License v10 whose full text can be found at: http://wwwopendatacommonsorg/licenses/pddl/10/ NotesThe upstream datasets do not impose any specific restrictions on using these data in a public or commercial product: GHCN-Nhttp://wwwesrlnoaagov/psd/data/gridded/dataghcncamshtml ERSSThttp://wwwesrlnoaagov/psd/data/gridded/datanoaaerssthtml ICOADShttp://icoadsnoaagov/dataicoadshtmlgistemp: http://datagissnasagov/gistemp/gcag: http://wwwncdcnoaagov/cag/data-info/globalhadcrut4: http://wwwmetofficegovuk/hadobs/hadcrut4/data/current/downloadhtmlregionalserieshadcrut4-terms: http://wwwmetofficegovuk/hadobs/hadcrut4/termsandconditionshtmlghcn-m: http://wwwncdcnoaagov/ghcnm/v3phpersst: http://wwwncdcnoaagov/data-access/marineocean-data/extended-reconstructed-sea-surface-temperature-ersst-v3bicoads: http://icoadsnoaagov/,0.995347484734,False,False,25.0,1.0,0.0,0.0,,0.00465251526607,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
86,datasets/global-temp-anomalies,DATA,datasets,global-temp-anomalies,1.0,Data about global annual anomalies,23.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,26.0,Nasa GISS Surface Temperature GISTEMP Analysis Four different series are provided: Global Annual Temperature Anomalies Land 1880-2014 Global Annual Temperature Anomalies Land and Ocean 1880-2014 Hemispheric Temperature Anomalies Land Ocean 1880-2014 and Annual Temperature anomalies Land  Ocean for three latitude bands that cover 30 40 and 30 of the global area respectively 1900-2014 Data Period of Record 1880-2014 Anomalies are relative to the 1951-80 base period means Description The NASA GISS Surface Temperature GISTEMP analysis provides a measure of the changing global surface temperature with monthly resolution for the period since 1880 when a reasonably global distribution of meteorological stations was established The input data Ruedy et al use for the analysis collected by many national meteorological services around the world are the adjusted data of the Global Historical Climatology Network GHCN Vs 3http://wwwncdcnoaagov/ghcnm/ this represents a change from prior use of unadjusted Vs 2 data Peterson and Vose 1997 and 1998 United States Historical Climatology Network USHCNhttp://wwwncdcnoaagov/oa/climate/research/ushcn/ data and SCAR Scientific Committee on Antarctic Researchhttp://wwwantarcticaacuk/met/READER/ data from Antarctic stations Documentation of the basic analysis method is provided by Hansen et al 1999 with several modifications described by Hansen et al 2001 The GISS analysis is updated monthly however CDIACs presentation of the data here is updated annually Key finding The global mean temperature for 2014 was the warmest on record see Trends sectionhttp://cdiacornlgov/trends/temp/hansen/hansenhtmltrends for further details Sources1    Name: Global Annual Temperature Anomalies Land 1880-2014   Web: http://cdiacornlgov/ftp/trends/temp/hansen/gllandtxt1    Name: Global Annual Temperature Anomalies LandOcean 1880-2014   Web: http://cdiacornlgov/ftp/trends/temp/hansen/gllandoceantxt1    Name: Hemispheric Temperature Anomalies LandOcean 1880-2014   Web: http://cdiacornlgov/ftp/trends/temp/hansen/nhshtxt1    Name: Global Annual Temperature Anomalies LandOcean for three latitude bands 1900-2014   Web: http://cdiacornlgov/ftp/trends/temp/hansen/norlowsoutxt Data Preparation RequirementsPython 2 together with modules urllib and csv are required in order to process the data  ProcessingRun the following script from this directory to download and process the data:bashmake ResourcesThe raw data are stored in /archive/ The processed data can be found in /data License DataData are sourced from US Federal government funded agency and no copyright restrictions are applied More specifically: If you wish to use a diagram image graph table or other materials from the CDIAC website and are concerned with obtaining permission and possible copyright restrictions there should be no concerns All of the reports graphics data and other information on the CDIAC website are freely and publicly available without copyright restrictionspermissions Additional work All the additional work made to build this Data Package is made available under the Public Domain Dedication and License v10 whose full text can be found at: http://wwwopendatacommonsorg/licenses/pddl/10/ Citations Ruedy R M Sato and K Lo 2015 NASA GISS Surface Temperature GISTEMP Analysis In Trends: A Compendium of Data on Global Change Carbon Dioxide Information Analysis Center Oak Ridge National Laboratory US Department of Energy Oak Ridge Tenn USA doi: 103334/CDIAC/cli001 permissions: http://cdiacornlgov/permissionhtml,0.977917981073,False,False,13.0,1.0,0.0,0.0,,0.0220820189274,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
87,datasets/glwd,DATA,datasets,glwd,5.0,Global Lakes and Wetlands Database Levels 1 and 2 Polygons as GeoJSON (.geojson/.topojson) with original format (.shp),23.0,0.0,0.0,0.0,0.0,0.0,4.0,0.0,0.0,148140.0,GLWD - Global Lakes and Wetlands DatabaseGlobal Lakes and Wetlands Database Levels 1 and 2 Polygons as GeoJSON geojson/topojson with original format shp via WWF https://worldwildlifeorg/pages/global-lakes-and-wetlands-database ,,False,False,5.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
88,datasets/gold-prices,DATA,datasets,gold-prices,0.0,Gold prices data package,23.0,0.0,0.0,0.0,9.0,0.0,12.0,0.0,0.0,169.0,Monthly gold prices since 1950 in USD London market Data is sourced from the Bundesbank Data Bundesbank statistic pagehttp://wwwbundesbankde/Navigation/EN/Statistics/Timeseriesdatabases/Macroeconomictimeseries/macroeconomictimeseriesnodehtmlankerAUSSENWIRTSCHAFTDEV Notes from the SourceGeneral: 1 ounce of fine gold  311034768g Method of calculation: Since 1 April 1968 calculated from the daily morning fixing From January 1950 to 21 March 1954 calculated using the Bank of Englands gold purchasing price 1 ounce of fine  pound 1240 in connection with the average exchange rate for the pound in New York up to the end of 1952 source: Federal Reserve Bulletin and from January 1953 midpoint exchange rates for the US dollar in London source: Financial Times FT From 22 March 1954 to December 1959 calculated using the fixing price for gold bars of approx 12 1/2 kg and 995/1000 fineness and over so-called standard bars according to data from Metallgesellschaft AG Frankfurt am Main in connection with the average midpoint exchange rates for the US dollar in London source: FT From January 1960 to 14 March 1968 average fixing price for standard bars as specified in the Bank of Englands Quarterly Bulletin On 15 March 1968 fixing price suspended Gold market split into an official reserved for central banks and a free market as a result of the Washington Communique of 17 March 1968 Gold trading suspended from 18 to 29 March 1968 Sources for daily prices: April 1968 - March 1974: FT April 1974 - December 1980: Samuel Montagu  Co Ltd January 1981 - December 2005: FT January 2006 - present: Reuters Comment on 1968-03: Average from 1 to 14 March 1968 LicenseThe maintainers have licensed under the Public Domain Dedication and License The source at the Bundesbank indicates no obvious restrictions on the data and the amount means that database rights are doubtful,1.0,False,False,14.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
89,datasets/house-prices-uk,DATA,datasets,house-prices-uk,5.0,UK house prices dataset,24.0,0.0,1.0,3.0,4.0,1.0,1.0,0.0,0.0,226.0,UK house prices since 1953 as monthly time-series Data comes from the NationwideSource: http://wwwnationwidecouk/hpi/historicalhtm DataData can be found in the data/datacsv file See datapackagejson forsource info NotesFrom the source XLS file notes tab: The Nationwide house price methodology has developed over time and this  needs to be considered when interpreting the long run series of house  prices  Maintenance in terms of updating weights for the mix-adjustment  process is carried out at regular intervals  Significant developments  include:  1952 - 1959 Q4 Simple average of purchase price  1960 Q1 - 1973 Q4  - weighted average using floor area thus allowing   for the influence of house size  1974 Q1 - 1982 Q4 - weighted averages using floor area region and   property type  1983 Q1 -  Development of new house price methodology  A statistical   regression technique was introduced under guidance of Fleming and   Nellis Loughborough University and Cranfield Institute of Technology   This was introduced in 1989 but data was revised back to 1983 Q1  1993 - Information about neighbourhood classification ACORN used in   the model were significantly updated following Census 1991 publication -   regular updates since but typically for new postcodes PreparationRun:    python scripts/datapy process,1.0,False,False,14.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
90,datasets/house-prices-us,DATA,datasets,house-prices-us,5.0,US House Price Indices (Case-Shiller),24.0,1.0,2.0,4.0,9.0,2.0,14.0,0.0,0.0,769.0,Case-Shiller Index of US residential house prices Data comes from SPCase-Shiller data and includes both the national index and the indices for 20metropolitan regions The indices are created using a repeat-sales methodology DataAs per the home page for Indices on SP websitesp-home: The SP/Case-Shiller US National Home Price Index is a composite of single-family home price indices for the nine US Census divisions and is calculated monthly It is included in the SP/Case-Shiller Home Price Index Series which seeks to measure changes in the total value of all existing single-family housing stockDocumentation of the methodology can be found at:http://wwwspindicescom/documents/methodologies/methodology-sp-cs-home-price-indicespdfKey points are excerpted from methodology: The indices use the repeat sales method of index calculation which uses  data on properties that have sold at least twice in order to capture the  true appreciated value of each specific sales unit The quarterly SP/Case-Shiller US National Home Price Index aggregates nine  quarterly US Census division repeat sales indices using a base period a nd  estimates of the aggregate value of single family housing stock for those periods The SP/Case - Shiller Home Price Indices originated in the 1980s by Case  Shiller Weisss research principals Karl E Case and Robert J Shiller At  the time Case and Shiller developed the repeat sales pricing technique This  methodology is recognized as the most reliable means to measure housing price  movements and is used by other home price ind ex publishers including the  Office of Federal Housing Enterprise Oversight OFHEOsp-home: http://wwwspindicescom/index-family/real-estate/sp-case-shiller PreparationTo download and process the data do:    python scripts/processpyUpdated data files will then be in data directoryNote: the URLs and structure of the source data have evolved over time with thesource data URLs changing on every releaseOriginally 2013 the site provided a table of links but these are not directfile URLs and you have dig around in SPs javascript to find the actualdownload locations As of mid-2014 the data is consolidated in one primary XLSbut the HTML you see in your browser and the source HTML are different Inaddition the actual location of the XLS file continues to change on eachrelease LicenseAny rights of the maintainer are licensed under the PDDL Exact legal status ofsource data and hence of resulting processe data is unclear but could have apresumption of public domain given its factual nature and US provenanceHowever the current application of PDDL is indicative of maintainersbest-guess and comes with no warranty,1.0,False,False,25.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
91,datasets/ICC-Incoterms,DATA,datasets,ICC-Incoterms,3.0,International Commercial Terms (‘Incoterms’) are internationally recognised standard trade terms used in sales contracts. ,23.0,0.0,0.0,0.0,2.0,0.0,0.0,0.0,0.0,4.0, ICC-IncotermsInternational Commercial Terms Incoterms are internationally recognised standard trade terms used in sales contracts Theyre used to make sure buyer and seller know: who is responsible for the cost of transporting the goods including insurance taxes and duties where the goods should be picked up from and transported towho is responsible for the goods at each step during transportationThe current set of Incoterms is Incoterms 2010 A copy of the full terms is available from http://wwwiccwboorg/products-and-services/trade-facilitation/incoterms-2010/This data is made available under the Public Domain Dedication and License version v10 whose full text can be found at http://opendatacommonsorg/licenses/pddl/ - See more at: http://opendatacommonsorg/guide/sthash97PSVxmhdpuf,,False,False,6.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
92,datasets/imf-weo,DATA,datasets,imf-weo,10.0,IMF World Economic Outlook Database Data,25.0,3.0,2.0,0.0,5.0,2.0,12.0,0.0,0.0,7259.0,IMF World Economic Outlook WEO database The IMF World EconomicOutlookweo is a twice-yearly survey by IMF staff that presents IMF staffeconomists analyses of global economic developments during the near and mediumterm Associated with the report is the World Economic OutlookDatabaseweo-db a country-level dataset of major macro-economic variablesGDP Unemployment Debt etc It is the data from that database which isprovided hereweo: http://wwwimforg/external/ns/csaspxid29weo-db: http://wwwimforg/external/ns/csaspxid28 DataThe source database is made of annual values for each country on 45 indicatorssince 1980 In addition the database includes the IMF projects approximately 6years into the futureWe extract this data and normalize into 2 files: Indicators - data/indicatorscsv - the list of indicators Values - data/valuescsv - set of values for each indicator country year tuple Country - data/countrycsv - set of value for mapping each ISO country code WEO country code and CLDR English Name SourcesNote the XLS files actual turn out to be tsv files Listing page for WEO Databaseweo-db 2015 - http://wwwimforg/external/pubs/ft/weo/2015/01/weodata/indexaspx   http://wwwimforg/external/pubs/ft/weo/2015/01/weodata/WEOApr2015allxls 2014 - http://wwwimforg/external/pubs/ft/weo/2014/01/weodata/indexaspx   http://wwwimforg/external/pubs/ft/weo/2014/01/weodata/WEOApr2014allxls 2011 - http://wwwimforg/external/pubs/ft/weo/2011/02/weodata/indexaspx   http://wwwimforg/external/pubs/ft/weo/2011/02/weodata/WEOSep2011allxls PreparationCode to extract the data from the source WEO Database is in the scriptsdirectory,1.0,False,False,5.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
93,datasets/IMO-IMDG-Codes,DATA,datasets,IMO-IMDG-Codes,4.0,Official IMDG Codes for use in transport of dangerous goods as described by the IMO,23.0,0.0,0.0,0.0,3.0,0.0,2.0,0.0,0.0,9.0, IMO-IMDG-CodesOfficial IMDG Codes for use in transport of dangerous goods as described by the IMOSource of the information is from the IMO and Govuk:http://wwwimoorg/blast/mainframeasptopicid158https://wwwgovuk/guidance/moving-dangerous-goodsthe-classification-of-dangerous-goodsRequests for addition to the codes should be made to the IMO directlyThis data is made available under the Public Domain Dedication and License version v10 whose full text can be found at http://opendatacommonsorg/licenses/pddl/ - See more at: http://opendatacommonsorg/guide/sthash97PSVxmhdpuf,,False,False,22.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
94,datasets/inflation,DATA,datasets,inflation,1.0,"Annual Inflation, GDP deflator and consumer prices",23.0,0.0,2.0,2.0,0.0,0.0,5.0,1.0,0.0,384.0,Inflation GDP deflator annual  and Inflation consumer prices annual  for most countries in the world when it has been measured  DataThe data comes from The World Bank CPIhttp://apiworldbankorg/indicator/NYGDPDEFLKDZGformatcsv The World Bank GDPhttp://apiworldbankorg/indicator/FPCPITOTLZGformatcsv  and is collected from 1973 to 2014 There are some values missing from data so users of the data will have to guess what should be in the empty slotsThe actual download happens via The World Banks API with csv as the requested format CPIhttp://apiworldbankorg/indicator/FPCPITOTLZGformatcsv The World Banks API with csv as the requested format GDPhttp://apiworldbankorg/indicator/NYGDPDEFLKDZGformatcsvThey are parsed via the script processpy located in scripts,0.95,False,False,19.0,2.0,0.0,0.0,,0.05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
95,datasets/investor-flow-of-funds-us,DATA,datasets,investor-flow-of-funds-us,7.0,"Monthly net new cash flow into various mutual fund investment classes (equities, bonds etc).",24.0,0.0,0.0,3.0,4.0,1.0,8.0,1.0,0.0,238.0,Monthly net new cash flow by US investors into various mutual fund investmentclasses equities bonds etc Statistics come from the Investment CompanyInstitute ICI DataData comes from the data provided on the ICI Statistics pagesici inparticular: Summary: Estimated Long-Term Mutual Fund Flows Data xlsici: http://wwwiciorg/research/statsNotes for Long-Term Mutual Fund Flows Data: All figures are nominal millions of US dollars USD Weekly cash flows are estimates based on reporting covering 98 percent of  industry assets while monthly flows are actual numbers as reported in ICIs  Trends in Mutual Fund Investing PreparationRun the python script:Install the requirements           pip install -r scripts/requirementstxtNow run the script        python scripts/processpy    ,1.0,False,False,18.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
96,datasets/ISO-Container-Codes,DATA,datasets,ISO-Container-Codes,4.0,"Coded list of ISO 6346 shipping containers, used in international trade and electronic shipping messages.",23.0,0.0,1.0,0.0,2.0,1.0,3.0,0.0,0.0,11.0, ISO-Container-CodesCoded list of ISO 6346 shipping containers used in international trade and electronic shipping messagesSource of information is from Container Container website http://wwwcontainercontainercom/ISO6346aspx but multiple other sources of information exist on the web: https://enwikipediaorg/wiki/ISO6346 http://wwwshippingcontainers24com/general/iso-6346-codes/ http://wwwisoorg/iso/cataloguedetailcsnumber20453 Paid For,,False,False,11.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
97,datasets/land-matrix,DATA,datasets,land-matrix,1.0,land-matrix,23.0,0.0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,128.0,The Land Matrix dataset is a public database of large-scale land deals It provides records documenting land deals since 2000As of April 2012 the data available represents about 50 of the entire data base The remaining deals are being crosschecked and added together with new data provided on an on-going basis Openness and LicensingThe Disclaimer and License pagehttp://landportalinfo/landmatrix/indexphppages-disclaimer links to terms and conditionshttp://landportalinfo/page/terms-and-conditions-use The only specific reference to a license therein which seems to be for entire website and not just database is within No contract section where it states:  Furthermore the coordinators of the Land Portal may add change improve or update the information of the website without notice and may in its sole discretion alter limit or discontinue part of this site or deny at its sole discretion any user access to this site or any portion thereof  For more information see Creative Commons Attribution-NonCommercial-ShareAlike 30 Unported LicenseThis license is of course not open as per the http://OpenDefinitionorg/ due to its non-commercial restriction,,False,False,4.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
98,datasets/language-codes,DATA,datasets,language-codes,12.0,ISO Language Codes (639-1 and 639-2),25.0,0.0,2.0,0.0,8.0,4.0,27.0,0.0,0.0,243.0,Comprehensive language code information consisting of ISO 639-1 ISO 639-2 and IETF language types DataData is taken from the Library of Congresshttp://wwwlocgov/standards/iso639-2/iso639-2rahtml as the ISO 639-2 Registration Authority and from the Unicode Common Locale Data Repositoryhttp://cldrunicodeorg/ data/language-codescsv This file contains the 184 languages with ISO 639-1 alpha 2 / two letter codes and their English names data/language-codes-3b2csv This file contains the 184 languages with both ISO 639-2 alpha 3 / three letter bibliographic codes and ISO 639-1 codes and their English names data/language-codes-fullcsvThis file is more exhaustiveIt contains all languages with ISO 639-2 alpha 3 / three letter codes the respective ISO 639-1 codes if present as well as the English and French name of each languageThere are two versions of the three letter codes: bibliographic and terminologic Each language has a bibliographic code but only a few languages have terminologic codes Terminologic codes are chosen to be similar to the corresponding ISO 639-1 two letter codesExample from Wikipediahttps://enwikipediaorg/wiki/ISO639Relationsbetweentheparts:  the German language Part 1: de has two codes in Part 2: ger T code and deu B code whereas there is only one code in Part 2 eng for the English languageThere are four special codes: mul und mis zxx and a reserved range qaa-qtz data/ietf-language-tagscsvThis file lists all IETF language tags of the official resource indicated by http://wwwianaorg/assignments/language-tag-extensions-registry that into the /main folder of http://wwwunicodeorg/Public/cldr/latest/corezip project cldrunicodeorghttp://cldrunicodeorg PreparationThis package includes a bash script to fetch current language code information and adjust the formattingThe file ietf-language-tagscsv is obtained with ietf-lanGenphp LicenseThis material is licensed by its maintainers under the Public Domain Dedication and License PDDLhttp://opendatacommonsorg/licenses/pddl/10/Nevertheless it should be noted that this material is ultimately sourced from the Library of Congress as a Registration Authority for ISO and their licensing policies are somewhat unclear As this is a short simple database of facts there is a strong argument that no rights can subsist in this collectionHowever if you intended to use these data in a public or commercial product please check the original sources for any specific restrictions,,False,False,28.0,1.0,0.0,0.0,0.703225806452,,,,,,,0.296774193548,,,,,,,,,,,,,,,,,,,,,,,,
99,datasets/lme-large-marine-ecosystems,DATA,datasets,lme-large-marine-ecosystems,7.0,"LME (Large Marine Ecosystems) global dataset; originally .kml (.kmz), and .shp formats, converted to .geojson/.topojson",24.0,0.0,0.0,0.0,1.0,1.0,3.0,0.0,0.0,31253.0,LME Large Marine EcosystemsLME global dataset originally kml kmz and shp formats converted to geojson/topojson  originally found:  http://wwwlmenoaagov/indexphpoptioncomcontentviewarticleid177Itemid75,,False,False,7.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
100,datasets/media-types,DATA,datasets,media-types,10.0,"List of MIME types, subtypes, and file name extensions. ",24.0,0.0,0.0,0.0,1.0,3.0,9.0,0.0,0.0,299.0,This dataset lists all the Media Types MIME types Media Subtypes and their file extensions SourceThe details of the Media Types and Media Subtypes are taken from the official registry of Media Typeshttp://wwwianaorg/assignments/media-types/media-typesxhtml maintained by IANA The extension details are taken   the websitehttp://svnapacheorg/viewvc/httpd/httpd/branches/22x/docs/conf/mimetypesviewannotate of the Apache Software Foundation PreparationThe Type Subtype and Template name were copied from IANAs websites into a Google Sheets document The link to the Template was generated in a fourth column in the same sheet by concatenating the Template name with a reference to the Template folder on IANAs websiteThe extensions were copied from Apaches website into a separate sheet in the same Google Sheets document The data was cleaned to place the extensions on their own in a single column without the Type and SubtypeThe extensions were finally added to the original sheet using VLOOKUP LicenseThese data are made available under the Public Domain Dedication and License v10 whose full text can be found at: http://wwwopendatacommonsorg/licenses/pddl/10/,,False,False,12.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
101,datasets/membership-to-copyright-treaties,DATA,datasets,membership-to-copyright-treaties,10.0,Membership to Copyright Treaties,24.0,0.0,0.0,1.0,2.0,4.0,1.0,1.0,0.0,348.0,This data provides the details of the membership by states to WIPO administered treaties on the subject matter of copyright namely:  Beijing Treaty on Audiovisual Performances  Berne Convention for the Protection of Literary and Artistic Works  Brussels Convention Relating to the Distribution of Programme-Carrying Signals Transmitted by Satellite  Marrakesh Treaty to Facilitate Access to Published Works for Persons Who Are Blind Visually Impaired or Otherwise Print Disabled  Convention for the Protection of Producers of Phonograms Against Unauthorized Duplication of Their Phonograms  WIPO Copyright Treaty  WIPO Performances and Phonograms Treaty SourceThe data is taken from the tables found on WIPOs website its free and can be viewed for each treaty individually from this linkwipoint/treaties/en/Note that WIPO administers other intellectual property treaties that cover subject matter outside copyright eg trademarks which are not included in this data package LicenseThese data are made available under the Public Domain Dedication and License v10 whose full text can be found at: http://wwwopendatacommonsorg/licenses/pddl/10/,,False,False,27.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
102,datasets/nasdaq-listings,DATA,datasets,nasdaq-listings,2.0,Data package for Nasdaq listings,24.0,0.0,0.0,0.0,2.0,0.0,8.0,0.0,0.0,366.0,List of companies in the NASDAQ exchanges DataData and documentation are available on NASDAQs official webpagehttp://wwwnasdaqtradercom/traderaspxidsymboldirdefs Data is updated regularly on the FTP siteThe file used in this repository: NASDAQ Listed Securitiesftp://ftpnasdaqtradercom/symboldirectory/nasdaqlistedtxtNotes: Company Name is a parsed field using the Security Name field Test Listings are excluded in the final dataset PreparationYou need python plus pandas library tool installed to run thescripts You also probably need to be on Linux/Unix or Mac for the shellscripts to work all datasetsCreates all csv files and datapackagejsonRun python script:      python scripts/processpy LicenseThis Data Package is licensed by its maintainers under the Public Domain Dedication and License PDDLhttp://opendatacommonsorg/licenses/pddl/10/Refer to the Copyright noticehttp://wwwnasdaqtradercom/TraderaspxidCopyDisclaimMain of the source dataset for any specific restrictions on using these data in a public or commercial product Copyright  2010 The NASDAQ OMX Group Inc All rights reserved,1.0,False,False,7.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
103,datasets/natural-gas-prices,DATA,datasets,natural-gas-prices,7.0,Natural Gas Prices including Henry Hub,23.0,0.0,0.0,0.0,1.0,1.0,3.0,0.0,0.0,94.0,Time series of major Natural Gas Prices including US Henry Hub Data comes from US Energy Information Administration EIAhttp://wwweiagov/DataDataset contains Monthly and Daily prices of Natural gas starting from January 1997 including April 2016 Prices are in nominal dollars License Public domain and use of EIA contentUS government publications are in the public domain and are not subject to copyright protection One may use and/or distribute any of data files databases reports graphs charts and other information products that are on website For more information please visit: Copyrights and Reusehttp://wwweiagov/about/copyrightsreusecfm,0.948566610455,False,False,15.0,1.0,0.0,0.0,,0.0514333895447,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
104,datasets/nyse-listings,DATA,datasets,nyse-listings,1.0,Data package for NYSE listings,24.0,0.0,0.0,0.0,2.0,0.0,5.0,0.0,0.0,272.0,List of companies in the NYSE and other exchanges DataData and documentation are available on NASDAQs official webpagehttp://wwwnasdaqtradercom/traderaspxidsymboldirdefs Data is updated regularly on the FTP siteThe file used in this repository: Other Exchanges Listed Securitiesftp://ftpnasdaqtradercom/symboldirectory/otherlistedtxtNotes: Company Name is a parsed field using the Security Name field Test Listings are excluded in the final dataset PreparationYou need python plus pandas library tool installed to run thescripts You also probably need to be on Linux/Unix or Mac for the shellscripts to work all datasetsCreates all csv files and datapackagejsonRun python script:      python scripts/processpy LicenseThis Data Package is licensed by its maintainers under the Public Domain Dedication and License PDDLhttp://opendatacommonsorg/licenses/pddl/10/Refer to the Copyright noticehttp://wwwnasdaqtradercom/TraderaspxidCopyDisclaimMain of the source dataset for any specific restrictions on using these data in a public or commercial product Copyright  2010 The NASDAQ OMX Group Inc All rights reserved,1.0,False,False,4.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
105,datasets/oil-prices,DATA,datasets,oil-prices,1.0,Brent crude and WTI oil prices from US EIA,23.0,0.0,0.0,0.0,0.0,0.0,3.0,0.0,0.0,281.0,Europe Brent and WTI Western Texas Intermediate Spot Prices Annual/ Monthly/ Weekly/ Daily from EIA US Energy Information Administration Data Sources1    Name: Daily Europe Brent Spot Price   Web: https://wwweiagov/dnav/pet/histxls/RBRTEdxls1    Name: Weekly Europe Brent Spot Price   Web: https://wwweiagov/dnav/pet/histxls/RBRTEwxls1    Name: Monthly Europe Brent Spot Price   Web: https://wwweiagov/dnav/pet/histxls/RBRTEmxls1    Name: Annual Europe Brent Spot Price   Web: https://wwweiagov/dnav/pet/histxls/RBRTEaxls1    Name: Daily Cushing OK WTI Spot Price   Web: http://wwweiagov/dnav/pet/histxls/RWTCdxls1    Name: Weekly Cushing OK WTI Spot Price   Web: http://wwweiagov/dnav/pet/histxls/RWTCwxls1    Name: Monthly Cushing OK WTI Spot Price   Web: http://wwweiagov/dnav/pet/histxls/RWTCmxls1    Name: Annual Cushing OK WTI Spot Price   Web: http://wwweiagov/dnav/pet/histxls/RWTCaxls Data Series History Europe Brent20 May 1987 - Today Cushing OK WTI01 February 1986 - Today Definitions Brent A blended crude stream produced in the North Sea region which serves as a reference or marker for pricing a number of other crude streams sourcehttps://wwweiagov/dnav/pet/TblDefs/petprispttbldef2asp  West Texas Intermediate WTI - Cushing A crude stream produced in Texas and southern Oklahoma which serves as a reference or marker for pricing a number of other crude streams and which is traded in the domestic spot market at Cushing Oklahomasourcehttps://wwweiagov/dnav/pet/TblDefs/petprispttbldef2asp  License Data US government publications are in the public domain and are not subject to copyright protection You may use and/or distribute any of our data files databases reports graphs charts and other information products that are on our website or that you receive through our email distribution service However if you use or reproduce any of our information products you should use an acknowledgment which includes the publication date such as: Source: US Energy Information Administration Oct 2008You may find further information herehttps://wwweiagov/about/copyrightsreusecfm Additional work All the additional work made to build this Data Package is made available under the Public Domain Dedication and License v10 whose full text can be found at: http://wwwopendatacommonsorg/licenses/pddl/10/,0.955030916245,False,False,8.0,3.0,0.0,0.0,,0.0449690837549,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
106,datasets/opented,DATA,datasets,opented,15.0,Tenders Electronic Daily (TED) - OpenTED,24.0,0.0,0.0,1.0,5.0,0.0,4.0,0.0,0.0,132.0,Processing code and information related to OpenTED Tenders Electronic Daily Data Processing PipelineStructured data is in a MongoDB at opentedorg/opentedUnstructured cached HTML pages are also in the that DB in a collection called dumps in future this data should probably go direct to s3 1 Get dumps onto s3 Get data out of mongodb    mongoexport --host opentedorg --db opented --username iacc --password gohack --collection dumps --csv --fields zhtmldocidtimestamp  head -n 5000  cache/dumpscsv Decompress the HTML    python scripts/extractpyThis will produce a whole bunch of files in cache/dumps Upload the decompressed HTML to S3    s3cmd sync --acl-public cache/dumps/ s3://filesopentedorg/scraped/You will find the index of files at: http://filesopentedorgs3amazonawscom/scraped/indexjson 2 Scraping contentNow its time to scrape some contentWeve written a nodejs scraper You will need to install the dependencies first:    npm install cheerio requestThen do:    node scripts/scrapejsData will be written to cache/dumps/docid/extractedjson WishlistExtra fields to scrape: VAT inclusion string eg Including VAT Excluding VAT Including 10 VAT etc Award criteria string often multi-line outlining criteria for choosing this bidderWe also need to cover the scenario of one contract having multiple winnersThis probably means were aiming for three content tables in the end possibly not with these names: contracts need a better name - info about a specific  companies - info about a company wins - the relation table ie a record in this table has a contractid and a companyid Also we can add extra info here that applies to a contractcompany relation eg the proportion of the total contract fee won by this company UPDATE from CallumI attempted to get the entire database by running mongoexport overnight piping through pv so I could see the progress and this morning its only at 43 after running for 125 hours I think its stuck it doesnt seem to be moving Ive cancelled this now in case its DOSing the database I could still run the Python decompression script on the dumps Ive got and upload straight to S3 could leave this running while Im out today but it might take ages Let me know if you want me to try that or something else - callumlocke at gmail ,0.380447941889,False,False,13.0,1.0,0.0,0.0,,,,0.619552058111,,,,,,,,,,,,,,,,,,,,,,,,,,,,
107,datasets/population,DATA,datasets,population,6.0,"Population figures for countries, regions (e.g. Asia) and the world.",25.0,0.0,0.0,0.0,13.0,3.0,23.0,0.0,0.0,199.0,Population figures for countries regions eg Asia and the world Data comesoriginally from World Bank and has been converted into standard CSV SourceThe data is sourced from this World Bank datasetwb which in turn lists assources: 1 United Nations Population Division World Population Prospects2 United Nations Statistical Division Population and Vital Statistics Reprotvarious years 3 Census reports and other statistical publications fromnational statistical offices 4 Eurostat: Demographic Statistics 5Secretariat of the Pacific Community: Statistics and Demography Programme and6 US Census Bureau: International Databasewb: http://dataworldbankorg/indicator/SPPOPTOTL,1.0,False,False,14.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
108,datasets/population-city,DATA,datasets,population-city,1.0,"City population yearly timeseries for female and male, and for both sexes, collected by the United Nations Statistics Division and published by UNData.",24.0,0.0,1.0,2.0,3.0,0.0,6.0,1.0,0.0,490.0,UNSD Demographic Statistics: City population by sex city and city type DataSource: UNData UNSD Demographic Statisticshttp://dataunorg/DataaspxdPOPftableCode:240Contains two CSV datasets:  1 unsd-citypopulation-year-bothcsv Size: 24 MB  2 unsd-citypopulation-year-fmcsv Size: 37 MBFinal 222 lines in both datasets contain original notes UpdatesLast update in UNdata: 22 Dec 2014Next update in UNdata: Jun 2015 est About the United Nations Statistics DivisionThe United Nations Statistics Division collects compiles and disseminates official demographic and social statistics on a wide range of topics Data have been collected since 1948 through a set of questionnaires dispatched annually to over 230 national statistical offices and have been published in the Demographic Yearbook collection The Demographic Yearbook disseminates statistics on population size and composition births deaths marriage and divorce as well as respective rates on an annual basis The Demographic Yearbook census datasets cover a wide range of additional topics including economic activity educational attainment household characteristics housing characteristics ethnicity language foreign-born and foreign population The available Population and Housing Censuses datasets reported to UNSD for the censuses conducted worldwide since 1995 are now available in UNdata PreparationNo special preparation needed LicenseThis data package is licensed under a ODC Public Domain Dedication and Licence PDDLhttp://opendatacommonsorg/licenses/pddl/10/,,False,False,21.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
109,datasets/ppp,DATA,datasets,ppp,7.0,Purchasing power parity (PPP),24.0,0.0,0.0,0.0,3.0,1.0,5.0,0.0,0.0,168.0,Purchasing power parity PPP Data are sourced from the World Bank International Comparison Program database One dataset is provided: PPP conversion factor GDP LCU per international  Data Description Purchasing power parity conversion factor is the number of units of a countrys currency required to buy the same amounts of goods and services in the domestic market as US dollar would buy in the United Statespa-nus-ppp Citations1 PPP conversion factor GDP LCU per international  World Bank International Comparison Program database Sources1      Name: PPP conversion factor GDP LCU per international  World Bank International Comparison Program database     Web: http://dataworldbankorg/indicator/PANUSPPP Data Preparation RequirementsData preparation requires Python 2 Required external Python modules are listed in the requirementstxt file in this directory ProcessingRun the following script from this directory to download and process the data:bashmake data ResourcesThe raw data are output to /tmp The processed data are output to /data License ODC-PDDL-10This Data Package is made available under the Public Domain Dedication and License v10 whose full text can be found at: http://wwwopendatacommonsorg/licenses/pddl/10/ NotesRefer to the terms of useworldbank of the source dataset for any specific restrictions on using these data in a public or commercial productpa-nus-ppp: http://dataworldbankorg/indicator/PANUSPPP worldbank: http://webworldbankorg/WBSITE/EXTERNAL/0contentMDK:22547097pagePK:50016803piPK:50016805theSitePK:1300html,0.826290266713,False,False,9.0,1.0,0.0,0.0,,0.0110841704191,,,,,,,,,,,,,,,,,,0.162625562868,,,,,,,,,,,,
110,datasets/reference-staging,DATA,datasets,reference-staging,5.0,Staging space for reference datasets,24.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,7200.0,Staging AreaThis repository contains candidates for reference datasets to beincluded in referenceokfnlabsorg Pull requests are welcome ,,False,False,8.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
111,datasets/registry,DATA,datasets,registry,28.0,"Registry of published datasets in the Datasets Project, as a datapackage",29.0,4.0,64.0,110.0,25.0,21.0,65.0,0.0,0.0,991.0,A Tabular Data Packagehttp://frictionlessdataio/guides/tabular-data-package/ of Data Packages including the core datasets in theFrictionless Datahttp://frictionlessdataio/ ProjectCurrently two registers maintained here: catalog-listcsv - catalog of all the community data packages we can find at  the moment largely those found on github via automatic search core-listcsv - Core Datasetscore hand-maintainedcore: http://dataokfnorg/roadmap/core-datasets Preparation Catalog ListThe main Catalog list is scraped using the python script scripts/scrapepy:     install deps    pip install -r scripts/requirementstxt     scrape data    python scripts/scrapepyNote wed prefer not to scrape and use the API but we cant do the relevantquery via the API - seehttp://developergithubcom/changes/2013-10-18-new-code-search-requirements/ Core ListTo add a dataset please add it to the core-listcsv - we recommendfork and pullDiscussion of proposals for new datasets and for incorporation of prepareddatasets takes place in the issuesTo propose a new dataset for inclusion please create a newissuehttps://githubcom/datasets/registry/issues/newissues: https://githubcom/datasets/registry/issues,1.0,False,False,170.0,7.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
112,datasets/s-and-p-500,DATA,datasets,s-and-p-500,7.0,S&P 500 index data (aka Standard and Poor's index of 500 major US stocks),24.0,0.0,0.0,3.0,24.0,1.0,153.0,1.0,0.0,1952.0,SP 500 index data including level dividend earnings and P/E ratio on amonthly basis since 1870 The SP 500 Standard and Poors 500 is afree-float capitalization-weighted index of the top 500 publicly listed stocksin the US top 500 by market cap DataThe data provided here is a tidied and CSVd version of that collected andprepared by the Economist Robert Shiller and made available on hiswebsiteshillershiller: http://wwweconyaleedu/shiller/datahtm Source Data ConstructionDetails of the data construction as described on Shillers website andslightly reformatted: Stock market data used in my book Irrational Exuberance Princeton University Press 2000 Broadway Books 2001 2nd ed 2005 are available for download Excel file xls This data set consists of monthly stock price dividends and earnings data and the consumer price index to allow conversion to real values all starting January 1871  The price dividend and earnings series are from the same sources as described in Chapter 26 of my earlier book Market Volatility Cambridge MA: MIT Press 1989 although now I use monthly data rather than annual data Monthly dividend and earnings data are computed from the SP four-quarter totals for the quarter since 1926 with linear interpolation to monthly figures Dividend and earnings data before 1926 are from Cowles and associates Common Stock Indexes 2nd ed Bloomington Ind: Principia Press 1939 interpolated from annual data Stock price data are monthly averages of daily closing prices through January 2000 the last month available as this book goes to press The CPI-U Consumer Price Index-All Urban Consumers published by the US Bureau of Labor Statistics begins in 1913 for years before 1913 1 spliced to the CPI Warren and Pearsons price index by multiplying it by the ratio of the indexes in January 1913 December 1999 and January 2000 values for the CPI-U are extrapolated See George F Warren and Frank A Pearson Gold and Prices New York: John Wiley and Sons 1935 Data are from their Table 1 pp 1114 For the Plots I have multiplied the inflation-corrected series by a constant so that their value in january 2000 equals their nominal value ie so that all prices are effectively in January 2000 dollars LicenseNo exact statement on license of original data but given size and factualnature believe one can assume these are public domain and I the maintainerexplicitly license under the ODC Public Domain Dedication and License PDDLThat said it would be natural to credit Robert Shiller for preparing thisdataset and kindly making it publicly available,0.866923232732,False,False,53.0,1.0,0.0,0.0,,0.133076767268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
113,datasets/s-and-p-500-companies,DATA,datasets,s-and-p-500-companies,22.0,List of companies in the S&P 500 together with associated financials,26.0,2.0,7.0,2.0,72.0,5.0,101.0,0.0,0.0,1406.0,List of companies in the SP 500 Standard and Poors 500 The SP 500 is afree-float capitalization-weighted index of the top 500 publicly listed stocksin the US top 500 by market cap The dataset includes a list of all thestocks contained therein and associated key financials such as price marketcapitalization earnings price/earnings ratio price to book etc DataInformation on SP 500 index used to be available on the official webpage on the Standard and Poors websitesp-homebut until they publish it back Wikipedia is the best up-to-date and open data source Index listing - see data/constituentscsv extracted from wikipedias SP500 list of companiessp-list Constituent financials - see data/constituents-financialscsv source via Yahoo FinanceDetailed information on the SP 500 primarily in xls format used to be obtainedfrom its official webpage on the Standard and Poors websitesp-home - it wasfree but registration was required Index listing - see data/constituentscsv used to be extracted from source Excel file on SP websitesp-listing-dec-2014 Note this Excel is actually SP 500 EPS    estimates but on sheet 4 it has list of members - previous filesp-lsting   was just members but that 404s as of Dec 2014 Note: delbut note you have   to register and login to access/del - no longer true as of August 2013 Historical performance source xls on SP websitesp-historicalNotes: Market Capitalization and EBIDTA are in Billionssp-home: http://wwwspindicescom/indices/equity/sp-500sp-list: http://enwikipediaorg/wiki/ListofS26P500companiessp-listing-dec-2014: http://wwwspindicescom/documents/additional-material/sp-500-eps-estxlsxforcedownloadtruesp-listing: http://usspindicescom/idsexport/filexlshostIdentifier48190c8c-42c4-46af-8d1a-0cd5db894797selectedModuleConstituentsselectedSubModuleConstituentsFullListindexId340sp-historical: http://wwwstandardandpoorscom/prot/spf/docs/indices/SPUSA-500-USDUF--P-US-L--HistoricalDataxlsNote: for aggregate information on the SP dividends earnings etc seeStandard and Poors 500 Datasetshillershiller: http://dataokfnorg/data/s-and-p-500 PreparationYou can run the script yourself to update the data and publish them to github : see scripts READMEscripts/READMEmd General Financial NotesPublicly listed US companies are obliged various reports on a regular basiswith the SEC Of these 2 types are of especial interest to investors and othersinterested in their finances and business These are: 10-K  Annual Report 10-Q  Quarterly report LicenseAll data is licensed under the Open Data Commons Public Domain Dedication andLicensepddl All code is licensed under the MIT/BSD licenseNote that while no credit is formally required a link back or credit to RufusPollockrp and the Open Knowledge Foundationokfn is much appreciatedpddl: http://opendatacommonsorg/licenses/pddl/10/rp: http://devrufuspollockorg/okfn: http://okfnorg/,0.857960282733,False,False,741.0,1.0,0.0,0.0,,0.142039717267,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
114,datasets/sea-level-rise,DATA,datasets,sea-level-rise,1.0,Global Mean Sea Level Rise,23.0,0.0,0.0,0.0,1.0,1.0,1.0,0.0,0.0,409.0,Global Average Absolute Sea Level Change 1880-2014 from the US Environmental Protection Agency using data from CSIRO 2015 NOAA 2015This data contains cumulative changes in sea level for the worlds oceans since 1880 based on a combination of long-term tide gauge measurements and recent satellite measurements It shows average absolute sea level change which refers to the height of the ocean surface regardless of whether nearby land is rising or falling Satellite data are based solely on measured sea level while the long-term tide gauge data include a small correction factor because the size and shape of the oceans are changing slowly over time On average the ocean floor has been gradually sinking since the last Ice Age peak 20000 years ago Data Sources1    Name: EPA United States Environmental Protection Agency   Web: http://www3epagov/climatechange/images/indicatordownloads/sea-levelfig-1csv1    Name: CSIRO Commonwealth Scientific and Industrial Research Organization   Web: http://wwwcmarcsiroau/sealevel/GMSLSG2011uphtml Key Findings:We estimate the rise in global average sea level from satellite altimeter data for 19932009 and from coastal and island sea-level measurements from 1880 to 2009 For 19932009 and after correcting for glacial isostatic adjustment the estimated rate of rise is 32  04 mm year1 from the satellite data and 28  08 mm year1 from the in situ data The global average sea-level rise from 1880 to 2009 is about 210 mm The linear trend from 1900 to 2009 is 17  02 mm year1 and since 1961 is 19  04 mm year1 There is considerable variability in the rate of rise during the twentieth century but there has been a statistically significant acceleration since 1880 and 1900 of 0009  0003 mm year2 and 0009  0004 mm year2 respectively Since the start of the altimeter record in 1993 global average sea level rose at a rate near the upper end of the sea level projections of the Intergovernmental Panel on Climate Changes Third and Fourth Assessment Reports However the reconstruction indicates there was little net change in sea level from 1990 to 1993 most likely as a result of the volcanic eruption of Mount Pinatubo in 1991 Further InformationFor further information you may visit the following websites: EPAhttp://www3epagov/climatechange/science/indicators/oceans/sea-levelhtml CSIROhttp://wwwcmarcsiroau/sealevel/sldatacmarhtml Acknowledgments  Funding and other support   CSIRO Marine and Atmospheric Research through the Wealth from Oceans National Research Flagship   Australian Government Cooperative Research Centre Program   Antarctic Climate and Ecosystems Cooperative Research Centre ACE CRC   Centre for Australian Weather and Climate Research CAWCR - a partnership between CSIRO and the Bureau of Meteorology   Department of Climate Change Australian Government   Pacific Climate Change Science Program PCCSP and follow-up Pacific-Australia Climate Change Science Adaptation Planning program PACCSAP administered by the Australian Department of Climate Change and Energy Efficiency DCCEE in collaboration with AusAID Provision of data   National Tidal Centre Bureau of Meteorology Australia   NASA/JPL - satellite altimeter data particularly TOPEX/Poseidon   CNES France and Aviso - satellite altimeter data particularly Jason-1   Permanent Service for Mean Sea Level PSMSL UK - tide gauge data License Data EPAEPA is Federal Government so public domain we would assume CSIROFigures marked CSIRO are copyright CSIRO but please feel free to use them conditional on the figures not being altered and their source being acknowledged and with a link to this site where possibleAll other figures are copyright Please do not copy without the owners permission Additional work All the additional work made to build this Data Package is made available under the Public Domain Dedication and License v10 whose full text can be found at: http://wwwopendatacommonsorg/licenses/pddl/10/ Citations CSIRO  The paper describing this data reconstruction is: Church J A and NJ White 2011 Sea-level rise from the late 19th to the early 21st Century Surveys in Geophysics doi:101007/s10712-011-9119-1 This paper is published Open Access and is available as a pdf from herehttp://wwwspringerlinkcom/content/h2575k28311g5146/,0.969639468691,False,False,9.0,2.0,0.0,0.0,,0.0303605313093,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
115,datasets/smdg-master-terminal-facilities-list,DATA,datasets,smdg-master-terminal-facilities-list,2.0,,23.0,0.0,0.0,0.0,2.0,1.0,0.0,0.0,0.0,56.0,List mantained by the SMDG Secretariathttp://smdgorg/ to specify the port terminal facilities in UN/EDIFACT messages The list is directly linked with the UN/LOCODE codelist see data packagehttp://dataokfnorg/data/core/un-locode DataExample segment where the main location is RULED UN/LOCODE for Saint Petersburg Russia and the facility is PLP SMDG code for PetrolesportLOC11RULED:139:6PLP:72:306 LicenseAll data is licensed under the Creative Commons 40 Attribution Licensehttps://creativecommonsorg/licenses/by/40/ You may need to attribute the specific code to the SMDG Secretariat,,False,False,12.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
116,datasets/top-level-domain-names,DATA,datasets,top-level-domain-names,6.0,,24.0,0.0,0.0,1.0,5.0,1.0,10.0,1.0,0.0,294.0,This Data Package contains the delegation details of top-level domainsDataThe data is available on :http://wwwianaorg/domains/root/dbPreparationThe data were copied manually from The Internet Assigned Numbers Authority IANA site and then posted to Excel file and saved as CSV fileLicenseThese data are made available under the Public Domain Dedication and License v10 whose full text can be found at: http://wwwopendatacommonsorg/licenses/pddl/10/,,False,False,34.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
117,datasets/uk-sic-2007-condensed,DATA,datasets,uk-sic-2007-condensed,1.0,UK condensed standard industrial classification of economic activities (SIC) 2007 codes,24.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,152.0,UK condensed standard industrial classification of economic activities SIC 2007 codesData-----------List of the Office of National Statistics ONS codes for classifying economic activity of business establishments and other standard units Only codes in the condensed list can be used on a companys annual return SIC 2007 was adopted from 1st January 2008Preparation-----------The Condensed SIC listhttps://wwwgovuk/government/uploads/system/uploads/attachmentdata/file/376462/condensedSICListpdf was downloaded and converted using PDFMinerhttp://wwwunixuserorg/euske/python/pdfminer/ pdf2txtpy -c UTF-8 -o condensedSICListtxt condensedSICListpdf The text file was edited programmitically find /v /c  condensedSICListtxt and manually then sanity checked against Nathan Pitmans Sic-Codes CSVhttps://githubcom/nathanpitman/sic-codes/blob/master/2007/siccodescsv An error with code 14200 appended code 14190 was correctedLicensing-----------Adapted from datahttps://wwwgovuk/government/publications/standard-industrial-classification-of-economic-activities-sic from the Office for National Statistics licensed under the Open Government Licence v30Notes-----------UK condensed SIC 2007 codes issued by Companies Househttps://wwwgovuk/government/organisations/companies-house are a subset of the codes published by the ONShttp://wwwonsgovuk/ whose copyright pagehttp://wwwonsgovuk/ons/site-information/information/creative-commons-license/indexhtml supports an assumption of open data ,,False,False,5.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
118,datasets/un-locode,DATA,datasets,un-locode,10.0,United Nations Codes for Trade and Transport Locations (UN/LOCODE) and Country Codes,23.0,2.0,3.0,0.0,16.0,6.0,25.0,0.0,0.0,9514.0,The United Nations Code for Trade and Transport Locations is a code list mantained by UNECE United Nations agency to facilitate trade DataData comes from the UNECE pagehttp://wwwuneceorg/cefact/locode/welcomehtml released at least once a year The files released in this package are extracted from the mdb archive to preserve UTF-8 encoding LicenseAll data is licensed under the ODC Public Domain Dedication and Licence PDDLhttp://opendatacommonsorg/licenses/pddl/1-0/,,False,False,24.0,1.0,0.0,0.0,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,
119,datasets/unece-package-codes,DATA,datasets,unece-package-codes,10.0,Coded representations of the package type names used in International Trade (UNECE/CEFACT Trade Facilitation Recommendation No.21),23.0,0.0,0.0,2.0,4.0,1.0,0.0,2.0,0.0,24.0, unece-package-codesCoded representations of the package type names used in International Trade UNECE/CEFACT Trade Facilitation Recommendation No21Source of information is from the UNECE website: http://wwwuneceorg/tradewelcome/areas-of-work/un-centre-for-trade-facilitation-and-e-business-uncefact/outputs/cefactrecommendationsrec-index/list-of-trade-facilitation-recommendations-n-21-to-24htmlAll data from UNECE has to be available in an easily distributable format in this case it is an xls file to process I simply removed any lines with a status of X and removed the numeric code column as its of little useable valueMeaning of status codes:A plus sign  Added New unit added in this release of the code listA hash sign  Changed name Changes to the unit name in this release of the code listA vertical bar  Changed characteristics Changes other than to the unit name in this release of the code list eg a change to the numeric codeA letter X X Marked as deleted Code entries marked as deleted will be retained indefinitely in the code lists When appropriate these entries may subsequently be reinstated via the maintenance processAn equals Reinstated Code entries previously sign  Marked as deleted and reinstated in this release of the code listRequests for addition to the codes should be made to the Information Content Management Group ICG at cefactuneceorgThis data is made available under the Public Domain Dedication and License version v10 whose full text can be found at http://opendatacommonsorg/licenses/pddl/ - See more at: http://opendatacommonsorg/guide/sthash97PSVxmhdpuf,,False,False,14.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
120,datasets/world-cities,DATA,datasets,world-cities,4.0,List of major cities of the world as a datapackage,26.0,0.0,1.0,4.0,9.0,4.0,35.0,0.0,0.0,303.0,List of major cities in the world DataThe data is extracted from geonamesgeonames a very exhaustive list of worldwide toponymsThis datapackagedatapackage only list cities above 15000 inhabitants Each city is associated with its country and subcountry to reduce the number of ambiguities Subcountry can be the name of a state eg in United Kingdom or the United States of America or the major administrative section eg region in France See admin1 field on geonames websitegeonames for further info about subcountryNotice that : some cities like Vatican city or Singapore are a whole state so they dont belong to any subcountry Therefore subcountry is N/A There is no guaranty that a city has a unique name in a country and subcountry At the time of writing there are about 60 ambiguities But for each city the source data primary key geonameid is providedgeonames: http://wwwgeonamesorg/datapackage: http://dataprotocolsorg/data-packages/ PreparationYou can run the script yourself to update the data and publish them to github : see scripts READMEscripts/READMEmd LicenseAll data is licensed under the Creative Common Attribution LicenseCC as is the original data from geonamesgeonames This means you have to credit geonamesgeonames when using the data And while no credit is formally required a link back or credit to Lexmanlexman and the Open Knowledge Foundationokfn is much appreciatedAll source code is licensed under the MIT licencemitCC: http://creativecommonsorg/licenses/by/30/mit: https://opensourceorg/licenses/MITgeonames: http://wwwgeonamesorg/pddl: http://opendatacommonsorg/licenses/pddl/10/lexman: http://githubcom/lexmanokfn: http://okfnorg/,,False,False,37.0,2.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
121,datasets/zopa,DATA,datasets,zopa,6.0,"Data on interest rate and risk (default rates) at ZOPA, the peer-to-peer marketplace for money.",23.0,0.0,0.0,0.0,1.0,0.0,2.0,0.0,0.0,204.0,Data on interest rate and risk default rates at ZOPA the peer-to-peer marketplace for money DataDownloaded directly from ZOPAs website see home page url Expected Lifetime Bad Debt Rate - the prediction for bad debt in the lifetime of the loan per market Expected Annual Bad Debt Rate - the prediction for bad debt annualised to determine impact on annual return Loan Value in Market - the total value of loans within each market Loans in Arrears - the value of loans currently going through the arrears collections process - these may reduce with borrower payments Defaults and arrears: assumes 50 of arrears are recovered Defaulted Loans - the value of loans that have gone through the arrears collection process and have now been purchased by our collections agencyBad debt rates for all time are estimated expected Openness: Open Data is publicly available on their website and no explicit restrictions are stated but there is also no explicit license,1.0,False,False,1.0,1.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
122,scipy-lectures/scipy-lecture-notes,EDU,scipy-lectures,scipy-lecture-notes,127.0,Tutorial material on the scientific Python ecosystem,64.0,23.0,48.0,32.0,491.0,171.0,1183.0,6.0,0.0,23819.0, image:: https://zenodoorg/badge/doi/105281/zenodo31521svg    :target: http://dxdoiorg/105281/zenodo31521 image:: https://travis-ciorg/scipy-lectures/scipy-lecture-notessvgbranchmaster    :target: https://travis-ciorg/scipy-lectures/scipy-lecture-notesScipy-Lecture-NotesThis repository gathers some lecture notes on the scientific Pythonecosystem that can be used for a full course of scientific computing withPythonThese documents are written with the rest markup language rstextension and built using Sphinx: http://sphinxpocooorg/You can view the online version at: http://scipy-lecturesorgReusing and distributing-------------------------As stated in the LICENSEtxt file this material comes with no stringsattached Feel free to reuse and modify for your own teaching purposesHowever we would like this reference material to be improved over timethus we encourage people to contribute back changes These will bereviewed and edited by the original authors and the editorsBuilding and contributing --------------------------The file CONTRIBUTINGrst contains instructions to build from sourceand to contribute,0.802943930165,False,False,1451.0,1.0,15.0,3.0,0.0125664865253,0.0112934477796,,0.00629783718126,0.155813655866,,0.0106558057976,,,,,,,,0.00042883668507,,,,,,,,,,,,,,,,,
123,jrjohansson/scientific-python-lectures,EDU,jrjohansson,scientific-python-lectures,215.0,"Lectures on scientific computing with python, as IPython notebooks.",16.0,4.0,12.0,10.0,835.0,19.0,1460.0,1.0,0.0,27681.0,Lectures on scientific computing with PythonA set of lectures on scientific computing with Python using IPython notebooksTo open these notebooks in IPython download the files to a directory on your computer and from that directory run:     ipython notebookThis will open a new page in your browser with a list of the available notebooksShould this error TerminalIPythonApp WARNING  File not found: unotebook pop up please install Jupyter by following the instructionshttp://jupyterreadthedocsio/en/latest/installhtml and execute the following command to run the notebook:     jupyter notebookOnline read-only versionsUse the following links: Lecture-0 Scientific Computing with Pythonhttp://nbvieweripythonorg/urls/rawgithubcom/jrjohansson/scientific-python-lectures/master/Lecture-0-Scientific-Computing-with-Pythonipynb Lecture-1 Introduction to Python Programminghttp://nbvieweripythonorg/urls/rawgithubcom/jrjohansson/scientific-python-lectures/master/Lecture-1-Introduction-to-Python-Programmingipynb Lecture-2 Numpy - multidimensional data arrayshttp://nbvieweripythonorg/urls/rawgithubcom/jrjohansson/scientific-python-lectures/master/Lecture-2-Numpyipynb Lecture-3 Scipy - Library of scientific algorithmshttp://nbvieweripythonorg/urls/rawgithubcom/jrjohansson/scientific-python-lectures/master/Lecture-3-Scipyipynb Lecture-4 Matplotlib - 2D and 3D plottinghttp://nbvieweripythonorg/urls/rawgithubcom/jrjohansson/scientific-python-lectures/master/Lecture-4-Matplotlibipynb Lecture-5 Sympy - Symbolic algebrahttp://nbvieweripythonorg/urls/rawgithubcom/jrjohansson/scientific-python-lectures/master/Lecture-5-Sympyipynb Lecture-6A C and Fortran integrationhttp://nbvieweripythonorg/urls/rawgithubcom/jrjohansson/scientific-python-lectures/master/Lecture-6A-Fortran-and-Cipynb Lecture-6B HPChttp://nbvieweripythonorg/urls/rawgithubcom/jrjohansson/scientific-python-lectures/master/Lecture-6B-HPCipynb Lecture-7 Revision Control Softwarehttp://nbvieweripythonorg/urls/rawgithubcom/jrjohansson/scientific-python-lectures/master/Lecture-7-Revision-Control-SoftwareipynbA PDF file containing all the lectures is available here: Scientific Computing with Pythonhttp://rawgithubcom/jrjohansson/scientific-python-lectures/master/Scientific-Computing-with-PythonpdfLicenseThis work is licensed under a Creative Commons Attribution 30 Unported Licensehttp://creativecommonsorg/licenses/by/30/,3.51932291899e-05,False,False,156.0,1.0,0.0,0.0,,0.000228602975695,,,,,,,,,,,0.00421002829536,,,,,,,,,,,,,,,,,0.9955261755,,
